{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tsfresh (Time Series Feature Extraction Based on Scalable Hypothesis Tests)**"
      ],
      "metadata": {
        "id": "cJB0IRptpHkx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Python package under consideration constitutes an automatic tool that computes and removes multiple time series characteristics that are utilized for undertaking classification and regression assignments. Consequently, the library under consideration is primarily utilized for the purpose of facilitating feature engineering in time series quandaries alongside the employment of supplementary packages such as sklearn for the purpose of scrutinizing time series. \n",
        "\n",
        "The present study will utilize a conventional dataset encompassing air travelers over an 11-year period, from 1949 through 1960. The present dataset consists of monthly aggregate figures of passengers utilizing airlines based in the United States."
      ],
      "metadata": {
        "id": "M9ay_L7MNJfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly"
      ],
      "metadata": {
        "id": "Yw4xkKS6EmAX",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:46.458902Z",
          "iopub.execute_input": "2022-05-05T08:33:46.459295Z",
          "iopub.status.idle": "2022-05-05T08:33:46.999445Z",
          "shell.execute_reply.started": "2022-05-05T08:33:46.459189Z",
          "shell.execute_reply": "2022-05-05T08:33:46.998568Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tsfresh import extract_features, extract_relevant_features, select_features\n",
        "from tsfresh.utilities.dataframe_functions import impute, make_forecasting_frame\n",
        "from tsfresh.feature_extraction import ComprehensiveFCParameters, settings"
      ],
      "metadata": {
        "id": "vx02dtihpHk1",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:47.001008Z",
          "iopub.execute_input": "2022-05-05T08:33:47.001241Z",
          "iopub.status.idle": "2022-05-05T08:33:47.941967Z",
          "shell.execute_reply.started": "2022-05-05T08:33:47.001214Z",
          "shell.execute_reply": "2022-05-05T08:33:47.940994Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
        "# Reading the data\n",
        "data = pd.read_csv('airline-passengers.csv')"
      ],
      "metadata": {
        "id": "IEM3AlQRumMG",
        "outputId": "157d5d6b-0f3b-48d4-eabc-b9a6a0a3a8a3",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:47.943373Z",
          "iopub.execute_input": "2022-05-05T08:33:47.943715Z",
          "iopub.status.idle": "2022-05-05T08:33:49.147764Z",
          "shell.execute_reply.started": "2022-05-05T08:33:47.943674Z",
          "shell.execute_reply": "2022-05-05T08:33:49.146760Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-10 13:00:55--  https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2180 (2.1K) [text/plain]\n",
            "Saving to: ‘airline-passengers.csv’\n",
            "\n",
            "\rairline-passengers.   0%[                    ]       0  --.-KB/s               \rairline-passengers. 100%[===================>]   2.13K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-10 13:00:56 (46.6 MB/s) - ‘airline-passengers.csv’ saved [2180/2180]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "3c_tlVKWsWqV",
        "outputId": "8b8e074b-1102-43c8-ba90-107c7523b4f2",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:49.150299Z",
          "iopub.execute_input": "2022-05-05T08:33:49.151234Z",
          "iopub.status.idle": "2022-05-05T08:33:49.161976Z",
          "shell.execute_reply.started": "2022-05-05T08:33:49.151188Z",
          "shell.execute_reply": "2022-05-05T08:33:49.161249Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "-jztSBSlpHk8",
        "outputId": "53755824-4a4e-4a14-87f9-14e463e6e34f",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:49.163265Z",
          "iopub.execute_input": "2022-05-05T08:33:49.163768Z",
          "iopub.status.idle": "2022-05-05T08:33:49.185774Z",
          "shell.execute_reply.started": "2022-05-05T08:33:49.163725Z",
          "shell.execute_reply": "2022-05-05T08:33:49.184208Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Month  Passengers\n",
              "0  1949-01         112\n",
              "1  1949-02         118\n",
              "2  1949-03         132\n",
              "3  1949-04         129\n",
              "4  1949-05         121"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6766ab0e-755e-4938-9847-7e5639f61741\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Month</th>\n",
              "      <th>Passengers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1949-01</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1949-02</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1949-03</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1949-04</td>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1949-05</td>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6766ab0e-755e-4938-9847-7e5639f61741')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6766ab0e-755e-4938-9847-7e5639f61741 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6766ab0e-755e-4938-9847-7e5639f61741');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "0o7N6Vp4pHk9",
        "outputId": "b285c729-dc28-49a9-c7fc-3222c47d8753",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:49.187553Z",
          "iopub.execute_input": "2022-05-05T08:33:49.188233Z",
          "iopub.status.idle": "2022-05-05T08:33:49.195849Z",
          "shell.execute_reply.started": "2022-05-05T08:33:49.188186Z",
          "shell.execute_reply": "2022-05-05T08:33:49.195156Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Month         object\n",
              "Passengers     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns = ['month','#Passengers']\n",
        "data['month'] = pd.to_datetime(data['month'],infer_datetime_format=True,format='%y%m')\n",
        "\n",
        "df_pass, y_air = make_forecasting_frame(data[\"#Passengers\"], kind=\"#Passengers\", max_timeshift=12, rolling_direction=1)\n",
        "print(df_pass)"
      ],
      "metadata": {
        "id": "fFYg9-oOpHlA",
        "outputId": "5c4a8ed9-f70c-45fc-9ff4-5967f272dae4",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:49.197530Z",
          "iopub.execute_input": "2022-05-05T08:33:49.198177Z",
          "iopub.status.idle": "2022-05-05T08:33:49.877073Z",
          "shell.execute_reply.started": "2022-05-05T08:33:49.198133Z",
          "shell.execute_reply": "2022-05-05T08:33:49.875873Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Rolling: 100%|██████████| 144/144 [00:00<00:00, 433.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             id  time  value         kind\n",
            "1       (id, 1)     0    112  #Passengers\n",
            "3       (id, 2)     0    112  #Passengers\n",
            "4       (id, 2)     1    118  #Passengers\n",
            "6       (id, 3)     0    112  #Passengers\n",
            "7       (id, 3)     1    118  #Passengers\n",
            "...         ...   ...    ...          ...\n",
            "1788  (id, 143)   138    622  #Passengers\n",
            "1789  (id, 143)   139    606  #Passengers\n",
            "1790  (id, 143)   140    508  #Passengers\n",
            "1791  (id, 143)   141    461  #Passengers\n",
            "1792  (id, 143)   142    390  #Passengers\n",
            "\n",
            "[1650 rows x 4 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extraction_settings = ComprehensiveFCParameters()\n",
        "features = extract_features(df_pass, column_id=\"id\", column_sort=\"time\", column_value=\"value\", impute_function=impute,\n",
        "                     show_warnings=False,\n",
        "                     default_fc_parameters=extraction_settings\n",
        "                     )"
      ],
      "metadata": {
        "id": "tYcUT1t5pHlB",
        "outputId": "46500f58-a2d6-4a9a-c66e-01851d6c6574",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:49.878847Z",
          "iopub.execute_input": "2022-05-05T08:33:49.879206Z",
          "iopub.status.idle": "2022-05-05T08:33:54.987656Z",
          "shell.execute_reply.started": "2022-05-05T08:33:49.879157Z",
          "shell.execute_reply": "2022-05-05T08:33:54.986713Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tsfresh.feature_extraction.settings:Dependency not available for matrix_profile, this feature will be disabled!\n",
            "Feature Extraction: 100%|██████████| 143/143 [00:07<00:00, 19.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "84OCjStXzH_G",
        "outputId": "b40c8373-bf25-43f3-9404-0eba537bdc41",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:54.990598Z",
          "iopub.execute_input": "2022-05-05T08:33:54.990841Z",
          "iopub.status.idle": "2022-05-05T08:33:55.047173Z",
          "shell.execute_reply.started": "2022-05-05T08:33:54.990813Z",
          "shell.execute_reply": "2022-05-05T08:33:55.046272Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        value__variance_larger_than_standard_deviation  \\\n",
              "id 1                                               0.0   \n",
              "   2                                               1.0   \n",
              "   3                                               1.0   \n",
              "   4                                               1.0   \n",
              "   5                                               1.0   \n",
              "...                                                ...   \n",
              "   139                                             1.0   \n",
              "   140                                             1.0   \n",
              "   141                                             1.0   \n",
              "   142                                             1.0   \n",
              "   143                                             1.0   \n",
              "\n",
              "        value__has_duplicate_max  value__has_duplicate_min  \\\n",
              "id 1                         0.0                       0.0   \n",
              "   2                         0.0                       0.0   \n",
              "   3                         0.0                       0.0   \n",
              "   4                         0.0                       0.0   \n",
              "   5                         0.0                       0.0   \n",
              "...                          ...                       ...   \n",
              "   139                       0.0                       0.0   \n",
              "   140                       0.0                       0.0   \n",
              "   141                       0.0                       0.0   \n",
              "   142                       0.0                       0.0   \n",
              "   143                       0.0                       0.0   \n",
              "\n",
              "        value__has_duplicate  value__sum_values  value__abs_energy  \\\n",
              "id 1                     0.0              112.0            12544.0   \n",
              "   2                     0.0              230.0            26468.0   \n",
              "   3                     0.0              362.0            43892.0   \n",
              "   4                     0.0              491.0            60533.0   \n",
              "   5                     0.0              612.0            75174.0   \n",
              "...                      ...                ...                ...   \n",
              "   139                   0.0             5513.0          2598313.0   \n",
              "   140                   0.0             5560.0          2653068.0   \n",
              "   141                   0.0             5605.0          2696763.0   \n",
              "   142                   1.0             5659.0          2743635.0   \n",
              "   143                   1.0             5687.0          2764691.0   \n",
              "\n",
              "        value__mean_abs_change  value__mean_change  \\\n",
              "id 1                 22.363636            2.272727   \n",
              "   2                  6.000000            6.000000   \n",
              "   3                 10.000000           10.000000   \n",
              "   4                  7.666667            5.666667   \n",
              "   5                  7.750000            2.250000   \n",
              "...                        ...                 ...   \n",
              "   139               46.272727            5.727273   \n",
              "   140               39.000000           13.000000   \n",
              "   141               42.818182            9.181818   \n",
              "   142               43.000000            9.000000   \n",
              "   143               45.545455           -1.363636   \n",
              "\n",
              "        value__mean_second_derivative_central  value__median  ...  \\\n",
              "id 1                                -0.500000          112.0  ...   \n",
              "   2                                -0.500000          115.0  ...   \n",
              "   3                                 4.000000          118.0  ...   \n",
              "   4                                -2.250000          123.5  ...   \n",
              "   5                                -2.333333          121.0  ...   \n",
              "...                                       ...            ...  ...   \n",
              "   139                               9.150000          440.0  ...   \n",
              "   140                               2.000000          440.0  ...   \n",
              "   141                              -2.650000          440.0  ...   \n",
              "   142                              -4.500000          461.0  ...   \n",
              "   143                              -4.150000          461.0  ...   \n",
              "\n",
              "        value__fourier_entropy__bins_5  value__fourier_entropy__bins_10  \\\n",
              "id 1                          0.796312                         1.277034   \n",
              "   2                         -0.000000                        -0.000000   \n",
              "   3                          0.693147                         0.693147   \n",
              "   4                          0.636514                         1.098612   \n",
              "   5                          1.098612                         1.098612   \n",
              "...                                ...                              ...   \n",
              "   139                        0.796312                         0.796312   \n",
              "   140                        0.410116                         0.955700   \n",
              "   141                        0.410116                         0.796312   \n",
              "   142                        0.796312                         1.153742   \n",
              "   143                        1.153742                         1.475076   \n",
              "\n",
              "        value__fourier_entropy__bins_100  \\\n",
              "id 1                            1.747868   \n",
              "   2                           -0.000000   \n",
              "   3                            0.693147   \n",
              "   4                            1.098612   \n",
              "   5                            1.098612   \n",
              "...                                  ...   \n",
              "   139                          1.747868   \n",
              "   140                          1.277034   \n",
              "   141                          1.475076   \n",
              "   142                          1.747868   \n",
              "   143                          1.747868   \n",
              "\n",
              "        value__permutation_entropy__dimension_3__tau_1  \\\n",
              "id 1                                          1.504788   \n",
              "   2                                          1.504788   \n",
              "   3                                         -0.000000   \n",
              "   4                                          0.693147   \n",
              "   5                                          1.098612   \n",
              "...                                                ...   \n",
              "   139                                        1.359237   \n",
              "   140                                        1.497866   \n",
              "   141                                        1.497866   \n",
              "   142                                        1.359237   \n",
              "   143                                        1.418484   \n",
              "\n",
              "        value__permutation_entropy__dimension_4__tau_1  \\\n",
              "id 1                                          2.043192   \n",
              "   2                                          2.043192   \n",
              "   3                                          2.043192   \n",
              "   4                                         -0.000000   \n",
              "   5                                          0.693147   \n",
              "...                                                ...   \n",
              "   139                                        1.831020   \n",
              "   140                                        1.831020   \n",
              "   141                                        1.831020   \n",
              "   142                                        1.831020   \n",
              "   143                                        1.676988   \n",
              "\n",
              "        value__permutation_entropy__dimension_5__tau_1  \\\n",
              "id 1                                          2.079442   \n",
              "   2                                          2.079442   \n",
              "   3                                          2.079442   \n",
              "   4                                          2.079442   \n",
              "   5                                         -0.000000   \n",
              "...                                                ...   \n",
              "   139                                        1.906155   \n",
              "   140                                        1.906155   \n",
              "   141                                        1.906155   \n",
              "   142                                        1.906155   \n",
              "   143                                        1.906155   \n",
              "\n",
              "        value__permutation_entropy__dimension_6__tau_1  \\\n",
              "id 1                                           1.94591   \n",
              "   2                                           1.94591   \n",
              "   3                                           1.94591   \n",
              "   4                                           1.94591   \n",
              "   5                                           1.94591   \n",
              "...                                                ...   \n",
              "   139                                         1.94591   \n",
              "   140                                         1.94591   \n",
              "   141                                         1.94591   \n",
              "   142                                         1.94591   \n",
              "   143                                         1.94591   \n",
              "\n",
              "        value__permutation_entropy__dimension_7__tau_1  \\\n",
              "id 1                                          1.791759   \n",
              "   2                                          1.791759   \n",
              "   3                                          1.791759   \n",
              "   4                                          1.791759   \n",
              "   5                                          1.791759   \n",
              "...                                                ...   \n",
              "   139                                        1.791759   \n",
              "   140                                        1.791759   \n",
              "   141                                        1.791759   \n",
              "   142                                        1.791759   \n",
              "   143                                        1.791759   \n",
              "\n",
              "        value__query_similarity_count__query_None__threshold_0.0  \\\n",
              "id 1                                                  0.0          \n",
              "   2                                                  0.0          \n",
              "   3                                                  0.0          \n",
              "   4                                                  0.0          \n",
              "   5                                                  0.0          \n",
              "...                                                   ...          \n",
              "   139                                                0.0          \n",
              "   140                                                0.0          \n",
              "   141                                                0.0          \n",
              "   142                                                0.0          \n",
              "   143                                                0.0          \n",
              "\n",
              "        value__mean_n_absolute_max__number_of_maxima_7  \n",
              "id 1                                        268.357143  \n",
              "   2                                        268.357143  \n",
              "   3                                        268.357143  \n",
              "   4                                        268.357143  \n",
              "   5                                        268.357143  \n",
              "...                                                ...  \n",
              "   139                                      504.428571  \n",
              "   140                                      511.142857  \n",
              "   141                                      517.571429  \n",
              "   142                                      523.571429  \n",
              "   143                                      523.571429  \n",
              "\n",
              "[143 rows x 783 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92601670-1557-4808-b2f7-000d9da4e7da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>value__variance_larger_than_standard_deviation</th>\n",
              "      <th>value__has_duplicate_max</th>\n",
              "      <th>value__has_duplicate_min</th>\n",
              "      <th>value__has_duplicate</th>\n",
              "      <th>value__sum_values</th>\n",
              "      <th>value__abs_energy</th>\n",
              "      <th>value__mean_abs_change</th>\n",
              "      <th>value__mean_change</th>\n",
              "      <th>value__mean_second_derivative_central</th>\n",
              "      <th>value__median</th>\n",
              "      <th>...</th>\n",
              "      <th>value__fourier_entropy__bins_5</th>\n",
              "      <th>value__fourier_entropy__bins_10</th>\n",
              "      <th>value__fourier_entropy__bins_100</th>\n",
              "      <th>value__permutation_entropy__dimension_3__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_4__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_5__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
              "      <th>value__query_similarity_count__query_None__threshold_0.0</th>\n",
              "      <th>value__mean_n_absolute_max__number_of_maxima_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">id</th>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>12544.0</td>\n",
              "      <td>22.363636</td>\n",
              "      <td>2.272727</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.277034</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.504788</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>26468.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.504788</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>43892.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>118.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>491.0</td>\n",
              "      <td>60533.0</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>123.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.636514</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>75174.0</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>-2.333333</td>\n",
              "      <td>121.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5513.0</td>\n",
              "      <td>2598313.0</td>\n",
              "      <td>46.272727</td>\n",
              "      <td>5.727273</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.359237</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5560.0</td>\n",
              "      <td>2653068.0</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.410116</td>\n",
              "      <td>0.955700</td>\n",
              "      <td>1.277034</td>\n",
              "      <td>1.497866</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>511.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5605.0</td>\n",
              "      <td>2696763.0</td>\n",
              "      <td>42.818182</td>\n",
              "      <td>9.181818</td>\n",
              "      <td>-2.650000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.410116</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.475076</td>\n",
              "      <td>1.497866</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5659.0</td>\n",
              "      <td>2743635.0</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>-4.500000</td>\n",
              "      <td>461.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.153742</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.359237</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5687.0</td>\n",
              "      <td>2764691.0</td>\n",
              "      <td>45.545455</td>\n",
              "      <td>-1.363636</td>\n",
              "      <td>-4.150000</td>\n",
              "      <td>461.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153742</td>\n",
              "      <td>1.475076</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.418484</td>\n",
              "      <td>1.676988</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.571429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 783 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92601670-1557-4808-b2f7-000d9da4e7da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-92601670-1557-4808-b2f7-000d9da4e7da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-92601670-1557-4808-b2f7-000d9da4e7da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tsfresh was utilized to extract a total of 143 rows that encompassed a comprehensive set of 789 features. This highlights the expeditiousness with which tsfresh appraised the characteristics of the sequential input data. It is viable to further curtail the resulted feature set through the elimination of any missing values in the derived features via the utilization of the \"impute\" directive. Subsequently, it is possible to conduct the .fit() and .train() procedures on the imputed dataset, followed by a comparison of the outcomes with those of the model utilizing the original data."
      ],
      "metadata": {
        "id": "co2PBcy5Ngig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tsfresh.utilities.dataframe_functions import impute\n",
        "impute(features)"
      ],
      "metadata": {
        "id": "oeegO4B3zehC",
        "outputId": "a004c812-980f-4498-b5c6-527b3159c19b",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:55.050189Z",
          "iopub.execute_input": "2022-05-05T08:33:55.050408Z",
          "iopub.status.idle": "2022-05-05T08:33:55.360464Z",
          "shell.execute_reply.started": "2022-05-05T08:33:55.050382Z",
          "shell.execute_reply": "2022-05-05T08:33:55.359853Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        value__variance_larger_than_standard_deviation  \\\n",
              "id 1                                               0.0   \n",
              "   2                                               1.0   \n",
              "   3                                               1.0   \n",
              "   4                                               1.0   \n",
              "   5                                               1.0   \n",
              "...                                                ...   \n",
              "   139                                             1.0   \n",
              "   140                                             1.0   \n",
              "   141                                             1.0   \n",
              "   142                                             1.0   \n",
              "   143                                             1.0   \n",
              "\n",
              "        value__has_duplicate_max  value__has_duplicate_min  \\\n",
              "id 1                         0.0                       0.0   \n",
              "   2                         0.0                       0.0   \n",
              "   3                         0.0                       0.0   \n",
              "   4                         0.0                       0.0   \n",
              "   5                         0.0                       0.0   \n",
              "...                          ...                       ...   \n",
              "   139                       0.0                       0.0   \n",
              "   140                       0.0                       0.0   \n",
              "   141                       0.0                       0.0   \n",
              "   142                       0.0                       0.0   \n",
              "   143                       0.0                       0.0   \n",
              "\n",
              "        value__has_duplicate  value__sum_values  value__abs_energy  \\\n",
              "id 1                     0.0              112.0            12544.0   \n",
              "   2                     0.0              230.0            26468.0   \n",
              "   3                     0.0              362.0            43892.0   \n",
              "   4                     0.0              491.0            60533.0   \n",
              "   5                     0.0              612.0            75174.0   \n",
              "...                      ...                ...                ...   \n",
              "   139                   0.0             5513.0          2598313.0   \n",
              "   140                   0.0             5560.0          2653068.0   \n",
              "   141                   0.0             5605.0          2696763.0   \n",
              "   142                   1.0             5659.0          2743635.0   \n",
              "   143                   1.0             5687.0          2764691.0   \n",
              "\n",
              "        value__mean_abs_change  value__mean_change  \\\n",
              "id 1                 22.363636            2.272727   \n",
              "   2                  6.000000            6.000000   \n",
              "   3                 10.000000           10.000000   \n",
              "   4                  7.666667            5.666667   \n",
              "   5                  7.750000            2.250000   \n",
              "...                        ...                 ...   \n",
              "   139               46.272727            5.727273   \n",
              "   140               39.000000           13.000000   \n",
              "   141               42.818182            9.181818   \n",
              "   142               43.000000            9.000000   \n",
              "   143               45.545455           -1.363636   \n",
              "\n",
              "        value__mean_second_derivative_central  value__median  ...  \\\n",
              "id 1                                -0.500000          112.0  ...   \n",
              "   2                                -0.500000          115.0  ...   \n",
              "   3                                 4.000000          118.0  ...   \n",
              "   4                                -2.250000          123.5  ...   \n",
              "   5                                -2.333333          121.0  ...   \n",
              "...                                       ...            ...  ...   \n",
              "   139                               9.150000          440.0  ...   \n",
              "   140                               2.000000          440.0  ...   \n",
              "   141                              -2.650000          440.0  ...   \n",
              "   142                              -4.500000          461.0  ...   \n",
              "   143                              -4.150000          461.0  ...   \n",
              "\n",
              "        value__fourier_entropy__bins_5  value__fourier_entropy__bins_10  \\\n",
              "id 1                          0.796312                         1.277034   \n",
              "   2                         -0.000000                        -0.000000   \n",
              "   3                          0.693147                         0.693147   \n",
              "   4                          0.636514                         1.098612   \n",
              "   5                          1.098612                         1.098612   \n",
              "...                                ...                              ...   \n",
              "   139                        0.796312                         0.796312   \n",
              "   140                        0.410116                         0.955700   \n",
              "   141                        0.410116                         0.796312   \n",
              "   142                        0.796312                         1.153742   \n",
              "   143                        1.153742                         1.475076   \n",
              "\n",
              "        value__fourier_entropy__bins_100  \\\n",
              "id 1                            1.747868   \n",
              "   2                           -0.000000   \n",
              "   3                            0.693147   \n",
              "   4                            1.098612   \n",
              "   5                            1.098612   \n",
              "...                                  ...   \n",
              "   139                          1.747868   \n",
              "   140                          1.277034   \n",
              "   141                          1.475076   \n",
              "   142                          1.747868   \n",
              "   143                          1.747868   \n",
              "\n",
              "        value__permutation_entropy__dimension_3__tau_1  \\\n",
              "id 1                                          1.504788   \n",
              "   2                                          1.504788   \n",
              "   3                                         -0.000000   \n",
              "   4                                          0.693147   \n",
              "   5                                          1.098612   \n",
              "...                                                ...   \n",
              "   139                                        1.359237   \n",
              "   140                                        1.497866   \n",
              "   141                                        1.497866   \n",
              "   142                                        1.359237   \n",
              "   143                                        1.418484   \n",
              "\n",
              "        value__permutation_entropy__dimension_4__tau_1  \\\n",
              "id 1                                          2.043192   \n",
              "   2                                          2.043192   \n",
              "   3                                          2.043192   \n",
              "   4                                         -0.000000   \n",
              "   5                                          0.693147   \n",
              "...                                                ...   \n",
              "   139                                        1.831020   \n",
              "   140                                        1.831020   \n",
              "   141                                        1.831020   \n",
              "   142                                        1.831020   \n",
              "   143                                        1.676988   \n",
              "\n",
              "        value__permutation_entropy__dimension_5__tau_1  \\\n",
              "id 1                                          2.079442   \n",
              "   2                                          2.079442   \n",
              "   3                                          2.079442   \n",
              "   4                                          2.079442   \n",
              "   5                                         -0.000000   \n",
              "...                                                ...   \n",
              "   139                                        1.906155   \n",
              "   140                                        1.906155   \n",
              "   141                                        1.906155   \n",
              "   142                                        1.906155   \n",
              "   143                                        1.906155   \n",
              "\n",
              "        value__permutation_entropy__dimension_6__tau_1  \\\n",
              "id 1                                           1.94591   \n",
              "   2                                           1.94591   \n",
              "   3                                           1.94591   \n",
              "   4                                           1.94591   \n",
              "   5                                           1.94591   \n",
              "...                                                ...   \n",
              "   139                                         1.94591   \n",
              "   140                                         1.94591   \n",
              "   141                                         1.94591   \n",
              "   142                                         1.94591   \n",
              "   143                                         1.94591   \n",
              "\n",
              "        value__permutation_entropy__dimension_7__tau_1  \\\n",
              "id 1                                          1.791759   \n",
              "   2                                          1.791759   \n",
              "   3                                          1.791759   \n",
              "   4                                          1.791759   \n",
              "   5                                          1.791759   \n",
              "...                                                ...   \n",
              "   139                                        1.791759   \n",
              "   140                                        1.791759   \n",
              "   141                                        1.791759   \n",
              "   142                                        1.791759   \n",
              "   143                                        1.791759   \n",
              "\n",
              "        value__query_similarity_count__query_None__threshold_0.0  \\\n",
              "id 1                                                  0.0          \n",
              "   2                                                  0.0          \n",
              "   3                                                  0.0          \n",
              "   4                                                  0.0          \n",
              "   5                                                  0.0          \n",
              "...                                                   ...          \n",
              "   139                                                0.0          \n",
              "   140                                                0.0          \n",
              "   141                                                0.0          \n",
              "   142                                                0.0          \n",
              "   143                                                0.0          \n",
              "\n",
              "        value__mean_n_absolute_max__number_of_maxima_7  \n",
              "id 1                                        268.357143  \n",
              "   2                                        268.357143  \n",
              "   3                                        268.357143  \n",
              "   4                                        268.357143  \n",
              "   5                                        268.357143  \n",
              "...                                                ...  \n",
              "   139                                      504.428571  \n",
              "   140                                      511.142857  \n",
              "   141                                      517.571429  \n",
              "   142                                      523.571429  \n",
              "   143                                      523.571429  \n",
              "\n",
              "[143 rows x 783 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ae4838e-2966-42be-a032-e898d3ef65df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>value__variance_larger_than_standard_deviation</th>\n",
              "      <th>value__has_duplicate_max</th>\n",
              "      <th>value__has_duplicate_min</th>\n",
              "      <th>value__has_duplicate</th>\n",
              "      <th>value__sum_values</th>\n",
              "      <th>value__abs_energy</th>\n",
              "      <th>value__mean_abs_change</th>\n",
              "      <th>value__mean_change</th>\n",
              "      <th>value__mean_second_derivative_central</th>\n",
              "      <th>value__median</th>\n",
              "      <th>...</th>\n",
              "      <th>value__fourier_entropy__bins_5</th>\n",
              "      <th>value__fourier_entropy__bins_10</th>\n",
              "      <th>value__fourier_entropy__bins_100</th>\n",
              "      <th>value__permutation_entropy__dimension_3__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_4__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_5__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
              "      <th>value__query_similarity_count__query_None__threshold_0.0</th>\n",
              "      <th>value__mean_n_absolute_max__number_of_maxima_7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">id</th>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>12544.0</td>\n",
              "      <td>22.363636</td>\n",
              "      <td>2.272727</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>112.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.277034</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.504788</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>230.0</td>\n",
              "      <td>26468.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>115.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.504788</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>43892.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>118.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>2.043192</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>491.0</td>\n",
              "      <td>60533.0</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>5.666667</td>\n",
              "      <td>-2.250000</td>\n",
              "      <td>123.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0.636514</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>612.0</td>\n",
              "      <td>75174.0</td>\n",
              "      <td>7.750000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>-2.333333</td>\n",
              "      <td>121.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>1.098612</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>268.357143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5513.0</td>\n",
              "      <td>2598313.0</td>\n",
              "      <td>46.272727</td>\n",
              "      <td>5.727273</td>\n",
              "      <td>9.150000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.359237</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>504.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5560.0</td>\n",
              "      <td>2653068.0</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.410116</td>\n",
              "      <td>0.955700</td>\n",
              "      <td>1.277034</td>\n",
              "      <td>1.497866</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>511.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5605.0</td>\n",
              "      <td>2696763.0</td>\n",
              "      <td>42.818182</td>\n",
              "      <td>9.181818</td>\n",
              "      <td>-2.650000</td>\n",
              "      <td>440.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.410116</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.475076</td>\n",
              "      <td>1.497866</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>517.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5659.0</td>\n",
              "      <td>2743635.0</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>-4.500000</td>\n",
              "      <td>461.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.796312</td>\n",
              "      <td>1.153742</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.359237</td>\n",
              "      <td>1.831020</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.571429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5687.0</td>\n",
              "      <td>2764691.0</td>\n",
              "      <td>45.545455</td>\n",
              "      <td>-1.363636</td>\n",
              "      <td>-4.150000</td>\n",
              "      <td>461.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.153742</td>\n",
              "      <td>1.475076</td>\n",
              "      <td>1.747868</td>\n",
              "      <td>1.418484</td>\n",
              "      <td>1.676988</td>\n",
              "      <td>1.906155</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>523.571429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 783 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ae4838e-2966-42be-a032-e898d3ef65df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ae4838e-2966-42be-a032-e898d3ef65df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ae4838e-2966-42be-a032-e898d3ef65df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tsfresh import select_features\n",
        "filtered_features = select_features(features, y_air)\n",
        "filtered_features"
      ],
      "metadata": {
        "id": "H8TSRTRYzh6l",
        "outputId": "ea496666-f1ec-4956-cc00-328c651ee456",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:33:55.361672Z",
          "iopub.execute_input": "2022-05-05T08:33:55.361865Z",
          "iopub.status.idle": "2022-05-05T08:34:50.890778Z",
          "shell.execute_reply.started": "2022-05-05T08:33:55.361842Z",
          "shell.execute_reply": "2022-05-05T08:34:50.889909Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.4  \\\n",
              "id 1                                                  0.0                   \n",
              "   2                                                  0.0                   \n",
              "   3                                                  0.0                   \n",
              "   4                                                  0.0                   \n",
              "   5                                                  0.0                   \n",
              "...                                                   ...                   \n",
              "   139                                                0.0                   \n",
              "   140                                                0.0                   \n",
              "   141                                                0.0                   \n",
              "   142                                                0.0                   \n",
              "   143                                                0.0                   \n",
              "\n",
              "        value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4  \\\n",
              "id 1                                                  0.0                  \n",
              "   2                                                  0.0                  \n",
              "   3                                                  0.0                  \n",
              "   4                                                  0.0                  \n",
              "   5                                                  0.0                  \n",
              "...                                                   ...                  \n",
              "   139                                                0.0                  \n",
              "   140                                                0.0                  \n",
              "   141                                                0.0                  \n",
              "   142                                                0.0                  \n",
              "   143                                                0.0                  \n",
              "\n",
              "        value__length  value__range_count__max_1000000000000.0__min_0  \\\n",
              "id 1              1.0                                             1.0   \n",
              "   2              2.0                                             2.0   \n",
              "   3              3.0                                             3.0   \n",
              "   4              4.0                                             4.0   \n",
              "   5              5.0                                             5.0   \n",
              "...               ...                                             ...   \n",
              "   139           12.0                                            12.0   \n",
              "   140           12.0                                            12.0   \n",
              "   141           12.0                                            12.0   \n",
              "   142           12.0                                            12.0   \n",
              "   143           12.0                                            12.0   \n",
              "\n",
              "        value__index_mass_quantile__q_0.2  value__index_mass_quantile__q_0.1  \\\n",
              "id 1                             1.000000                           1.000000   \n",
              "   2                             0.500000                           0.500000   \n",
              "   3                             0.333333                           0.333333   \n",
              "   4                             0.250000                           0.250000   \n",
              "   5                             0.400000                           0.200000   \n",
              "...                                   ...                                ...   \n",
              "   139                           0.250000                           0.083333   \n",
              "   140                           0.250000                           0.166667   \n",
              "   141                           0.250000                           0.166667   \n",
              "   142                           0.250000                           0.166667   \n",
              "   143                           0.250000                           0.166667   \n",
              "\n",
              "        value__permutation_entropy__dimension_7__tau_1  \\\n",
              "id 1                                          1.791759   \n",
              "   2                                          1.791759   \n",
              "   3                                          1.791759   \n",
              "   4                                          1.791759   \n",
              "   5                                          1.791759   \n",
              "...                                                ...   \n",
              "   139                                        1.791759   \n",
              "   140                                        1.791759   \n",
              "   141                                        1.791759   \n",
              "   142                                        1.791759   \n",
              "   143                                        1.791759   \n",
              "\n",
              "        value__permutation_entropy__dimension_6__tau_1  \\\n",
              "id 1                                           1.94591   \n",
              "   2                                           1.94591   \n",
              "   3                                           1.94591   \n",
              "   4                                           1.94591   \n",
              "   5                                           1.94591   \n",
              "...                                                ...   \n",
              "   139                                         1.94591   \n",
              "   140                                         1.94591   \n",
              "   141                                         1.94591   \n",
              "   142                                         1.94591   \n",
              "   143                                         1.94591   \n",
              "\n",
              "        value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.6  \\\n",
              "id 1                                                  0.0                   \n",
              "   2                                                  0.0                   \n",
              "   3                                                  0.0                   \n",
              "   4                                                  0.0                   \n",
              "   5                                                  0.0                   \n",
              "...                                                   ...                   \n",
              "   139                                                0.0                   \n",
              "   140                                                0.0                   \n",
              "   141                                                0.0                   \n",
              "   142                                                0.0                   \n",
              "   143                                                0.0                   \n",
              "\n",
              "        value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.6  \n",
              "id 1                                                  0.0                   \n",
              "   2                                                  0.0                   \n",
              "   3                                                  0.0                   \n",
              "   4                                                  0.0                   \n",
              "   5                                                  0.0                   \n",
              "...                                                   ...                   \n",
              "   139                                                0.0                   \n",
              "   140                                                0.0                   \n",
              "   141                                                0.0                   \n",
              "   142                                                0.0                   \n",
              "   143                                                0.0                   \n",
              "\n",
              "[143 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55d39a70-355f-423f-bd32-f6becf87920a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_False__qh_0.6__ql_0.4</th>\n",
              "      <th>value__change_quantiles__f_agg_\"var\"__isabs_True__qh_0.6__ql_0.4</th>\n",
              "      <th>value__length</th>\n",
              "      <th>value__range_count__max_1000000000000.0__min_0</th>\n",
              "      <th>value__index_mass_quantile__q_0.2</th>\n",
              "      <th>value__index_mass_quantile__q_0.1</th>\n",
              "      <th>value__permutation_entropy__dimension_7__tau_1</th>\n",
              "      <th>value__permutation_entropy__dimension_6__tau_1</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.8__ql_0.6</th>\n",
              "      <th>value__change_quantiles__f_agg_\"mean\"__isabs_False__qh_0.8__ql_0.6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"11\" valign=\"top\">id</th>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.791759</td>\n",
              "      <td>1.94591</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55d39a70-355f-423f-bd32-f6becf87920a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55d39a70-355f-423f-bd32-f6becf87920a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55d39a70-355f-423f-bd32-f6becf87920a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AutoTS (Automatic Time Series)**"
      ],
      "metadata": {
        "id": "kpUEaaBNpHlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoTS furnishes forecasts with a high degree of precision on a grandiose scale. The platform provides a plethora of diverse prognostic models and functionalities that are seamlessly compatible with pandas'data frames. The models contained within this library exhibit suitability for deployment purposes. Several discernible characteristics are apparent within this particular library:\n",
        "\n",
        "- This methodology is suitable for effectively analyzing both univariate and multivariate time series data.\n",
        "\n",
        "- The ability to proficiently manage data that is either incomplete or disordered due to the presence of outliers is a crucial skill.\n",
        "\n",
        "- The identification of the optimal time series forecasting model pertinent to the input data type is facilitated.\n",
        "\n",
        "We intend to investigate the possibility of implementing the aforementioned library to foresee the temperature trends for the upcoming month."
      ],
      "metadata": {
        "id": "4Wjv39HvRCcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the package\n",
        "from autots import AutoTS"
      ],
      "metadata": {
        "id": "AHqW7DWvpHlG",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:34:50.892287Z",
          "iopub.execute_input": "2022-05-05T08:34:50.893227Z",
          "iopub.status.idle": "2022-05-05T08:34:51.067782Z",
          "shell.execute_reply.started": "2022-05-05T08:34:50.893183Z",
          "shell.execute_reply": "2022-05-05T08:34:51.066994Z"
        },
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_air=data.set_index('month')\n",
        "data_air"
      ],
      "metadata": {
        "id": "a-85OXp6ZfAP",
        "outputId": "45a7c53e-00b3-4861-8cc1-3236f1ffcfb8",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:34:51.069185Z",
          "iopub.execute_input": "2022-05-05T08:34:51.069755Z",
          "iopub.status.idle": "2022-05-05T08:34:51.083865Z",
          "shell.execute_reply.started": "2022-05-05T08:34:51.069706Z",
          "shell.execute_reply": "2022-05-05T08:34:51.083095Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            #Passengers\n",
              "month                  \n",
              "1949-01-01          112\n",
              "1949-02-01          118\n",
              "1949-03-01          132\n",
              "1949-04-01          129\n",
              "1949-05-01          121\n",
              "...                 ...\n",
              "1960-08-01          606\n",
              "1960-09-01          508\n",
              "1960-10-01          461\n",
              "1960-11-01          390\n",
              "1960-12-01          432\n",
              "\n",
              "[144 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85f9eee8-4306-48d5-82ee-61dd863e09f7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#Passengers</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>month</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1949-01-01</th>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949-02-01</th>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949-03-01</th>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949-04-01</th>\n",
              "      <td>129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1949-05-01</th>\n",
              "      <td>121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960-08-01</th>\n",
              "      <td>606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960-09-01</th>\n",
              "      <td>508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960-10-01</th>\n",
              "      <td>461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960-11-01</th>\n",
              "      <td>390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960-12-01</th>\n",
              "      <td>432</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85f9eee8-4306-48d5-82ee-61dd863e09f7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-85f9eee8-4306-48d5-82ee-61dd863e09f7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-85f9eee8-4306-48d5-82ee-61dd863e09f7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[[\"month\", \"#Passengers\"]]\n",
        "data[\"#Passengers\"].plot(figsize=(12, 8), title=\"Predictions for passengeres\", fontsize=20, label=\"Passengers\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SNmutVxCYiju",
        "outputId": "96ca11c5-b7b7-44ae-8eae-21abaca577f4",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:34:51.085167Z",
          "iopub.execute_input": "2022-05-05T08:34:51.085846Z",
          "iopub.status.idle": "2022-05-05T08:34:51.343274Z",
          "shell.execute_reply.started": "2022-05-05T08:34:51.085808Z",
          "shell.execute_reply": "2022-05-05T08:34:51.342703Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoTS(forecast_length=12, frequency='infer', \n",
        "               ensemble='simple')\n",
        "model = model.fit(data, date_col='month', value_col='#Passengers', id_col=None)"
      ],
      "metadata": {
        "id": "cN0v1BLiYiew",
        "outputId": "310f2f72-21bf-49be-8b5f-53f6c9534b96",
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2022-05-05T08:34:51.344188Z",
          "iopub.execute_input": "2022-05-05T08:34:51.344849Z",
          "iopub.status.idle": "2022-05-05T08:41:10.811545Z",
          "shell.execute_reply.started": "2022-05-05T08:34:51.344816Z",
          "shell.execute_reply": "2022-05-05T08:41:10.810783Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inferred frequency is: MS\n",
            "Model Number: 1 with model ARIMA in generation 0 of 10\n",
            "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 4 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 6 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 7 with model DatepartRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 8 with model DatepartRegression in generation 0 of 10\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 11s 8ms/step - loss: 0.3802\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3766\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3783\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.3802\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3776\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3776\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3781\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3761\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3735\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3776\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3775\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3774\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3738\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3741\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3745\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3766\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3750\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3762\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3778\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3765\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3740\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3755\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3743\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3704\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3706\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3745\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3698\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3702\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3728\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3734\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3748\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3755\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3763\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3748\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3724\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3699\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3717\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3673\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3746\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3713\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3726\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3670\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3699\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3706\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3657\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3705\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3691\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3685\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3645\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3725\n",
            "1/1 [==============================] - 1s 792ms/step\n",
            "Model Number: 9 with model ETS in generation 0 of 10\n",
            "Model Number: 10 with model ETS in generation 0 of 10\n",
            "Model Number: 11 with model GLM in generation 0 of 10\n",
            "Model Number: 12 with model GLM in generation 0 of 10\n",
            "Model Number: 13 with model GLS in generation 0 of 10\n",
            "Model Number: 14 with model GLS in generation 0 of 10\n",
            "Model Number: 15 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 15 in generation 0: GluonTS\n",
            "Model Number: 16 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 16 in generation 0: GluonTS\n",
            "Model Number: 17 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 17 in generation 0: GluonTS\n",
            "Model Number: 18 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 18 in generation 0: GluonTS\n",
            "Model Number: 19 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 19 in generation 0: GluonTS\n",
            "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 27 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 30 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 30 in generation 0: VAR\n",
            "Model Number: 31 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31 in generation 0: VAR\n",
            "Model Number: 32 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 32 in generation 0: VECM\n",
            "Model Number: 33 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 33 in generation 0: VECM\n",
            "Model Number: 34 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 35 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 36 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/1x3oivss.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/5rip8xl4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=171', 'data', 'file=/tmp/tmp2xi3y8fj/1x3oivss.json', 'init=/tmp/tmp2xi3y8fj/5rip8xl4.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelbdg2yx7s/prophet_model-20230410130334.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:03:34 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:03:34 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 37 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 37 in generation 0: GluonTS\n",
            "Model Number: 38 with model MultivariateRegression in generation 0 of 10\n",
            "Model Number: 39 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 39 in generation 0: MultivariateRegression\n",
            "Model Number: 40 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 40 in generation 0: DatepartRegression\n",
            "Model Number: 41 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 42 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 43 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 44 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 45 with model ETS in generation 0 of 10\n",
            "Model Number: 46 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 46 in generation 0: VECM\n",
            "Model Number: 47 with model ARDL in generation 0 of 10\n",
            "Model Number: 48 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 49 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 50 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 51 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 52 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 53 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 54 with model MultivariateRegression in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/i338usw_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/fl9puenm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=14803', 'data', 'file=/tmp/tmp2xi3y8fj/i338usw_.json', 'init=/tmp/tmp2xi3y8fj/fl9puenm.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelbcjhyfgt/prophet_model-20230410130336.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:03:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 55 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:03:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 56 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 57 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 58 with model NVAR in generation 0 of 10\n",
            "Model Number: 59 with model Theta in generation 0 of 10\n",
            "Model Number: 60 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 60 in generation 0: UnivariateRegression\n",
            "Model Number: 61 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 61 in generation 0: ARCH\n",
            "Model Number: 62 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 63 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 64 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 65 with model GLS in generation 0 of 10\n",
            "Model Number: 66 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 67 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 67 in generation 0: GLM\n",
            "Model Number: 68 with model ETS in generation 0 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 69 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/i7rjvtu7.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/wvn91xw_.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=88196', 'data', 'file=/tmp/tmp2xi3y8fj/i7rjvtu7.json', 'init=/tmp/tmp2xi3y8fj/wvn91xw_.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelcbjnrll2/prophet_model-20230410130338.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:03:38 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:03:38 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 70 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 70 in generation 0: GluonTS\n",
            "Model Number: 71 with model UnobservedComponents in generation 0 of 10\n",
            "Model Number: 72 with model VAR in generation 0 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 72 in generation 0: VAR\n",
            "Model Number: 73 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 73 in generation 0: VECM\n",
            "Model Number: 74 with model ARIMA in generation 0 of 10\n",
            "Model Number: 75 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 76 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 76 in generation 0: DatepartRegression\n",
            "Model Number: 77 with model UnivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nDecisionTreeRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 77 in generation 0: UnivariateRegression\n",
            "Model Number: 78 with model MultivariateRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Some value(s) of y are out of the valid range of the loss 'HalfPoissonLoss'.\") in model 78 in generation 0: MultivariateRegression\n",
            "Model Number: 79 with model UnivariateMotif in generation 0 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 80 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 81 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 82 with model NVAR in generation 0 of 10\n",
            "Model Number: 83 with model Theta in generation 0 of 10\n",
            "Model Number: 84 with model ARDL in generation 0 of 10\n",
            "Model Number: 85 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 85 in generation 0: ARCH\n",
            "Model Number: 86 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 87 with model ETS in generation 0 of 10\n",
            "Model Number: 88 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 89 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 90 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 91 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 91 in generation 0: DatepartRegression\n",
            "Model Number: 92 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 92 in generation 0: VAR\n",
            "Model Number: 93 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 94 with model ETS in generation 0 of 10\n",
            "Model Number: 95 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 96 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 96 in generation 0: VAR\n",
            "Model Number: 97 with model GLS in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 98 with model ARDL in generation 0 of 10\n",
            "Model Number: 99 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 100 with model ARDL in generation 0 of 10\n",
            "Model Number: 101 with model ETS in generation 0 of 10\n",
            "Model Number: 102 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 103 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 104 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 105 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 105 in generation 0: UnobservedComponents\n",
            "Model Number: 106 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 107 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 108 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 108 in generation 0: VAR\n",
            "Model Number: 109 with model UnobservedComponents in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 109 in generation 0: UnobservedComponents\n",
            "Model Number: 110 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 111 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 112 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 113 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 114 with model ARDL in generation 0 of 10\n",
            "Model Number: 115 with model ARDL in generation 0 of 10\n",
            "Model Number: 116 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 117 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 118 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 118 in generation 0: ARDL\n",
            "Model Number: 119 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 120 with model ARIMA in generation 0 of 10\n",
            "Model Number: 121 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 121 in generation 0: ARCH\n",
            "Model Number: 122 with model Theta in generation 0 of 10\n",
            "Model Number: 123 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 124 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 125 with model DatepartRegression in generation 0 of 10\n",
            "Model Number: 126 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 126 in generation 0: GLM\n",
            "Model Number: 127 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 128 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 129 with model ConstantNaive in generation 0 of 10\n",
            "Model Number: 130 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 131 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 132 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 132 in generation 0: VAR\n",
            "Model Number: 133 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 134 with model SeasonalNaive in generation 0 of 10\n",
            "Model Number: 135 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 135 in generation 0: ARCH\n",
            "Model Number: 136 with model LastValueNaive in generation 0 of 10\n",
            "Model Number: 137 with model WindowRegression in generation 0 of 10\n",
            "Model Number: 138 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 138 in generation 0: GLM\n",
            "Model Number: 139 with model Theta in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 140 with model ARDL in generation 0 of 10\n",
            "Model Number: 141 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 141 in generation 0: ARCH\n",
            "Model Number: 142 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 143 with model NVAR in generation 0 of 10\n",
            "Model Number: 144 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 144 in generation 0: ARCH\n",
            "Model Number: 145 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 146 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 146 in generation 0: ARCH\n",
            "Model Number: 147 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 147 in generation 0: VAR\n",
            "Model Number: 148 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 148 in generation 0: GluonTS\n",
            "Model Number: 149 with model DatepartRegression in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 149 in generation 0: DatepartRegression\n",
            "Model Number: 150 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 150 in generation 0: VAR\n",
            "Model Number: 151 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 151 in generation 0: VECM\n",
            "Model Number: 152 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 153 with model Theta in generation 0 of 10\n",
            "Model Number: 154 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 154 in generation 0: GLM\n",
            "Model Number: 155 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 156 with model VAR in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VAR') in model 156 in generation 0: VAR\n",
            "Model Number: 157 with model LastValueNaive in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'rolling_mean_24', 'transformations': {'0': 'ScipyFilter', '1': 'SeasonalDifference', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'method': 'savgol_filter', 'method_args': {'window_length': 7, 'polyorder': 3, 'deriv': 1, 'mode': 'nearest'}}, '1': {'lag_1': 7, 'method': 'LastValue'}, '2': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 1.0, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 157 in generation 0: LastValueNaive\n",
            "Model Number: 158 with model GluonTS in generation 0 of 10\n",
            "Template Eval Error: ImportError('GluonTS installation is incompatible with AutoTS. The numpy version is sometimes the issue.') in model 158 in generation 0: GluonTS\n",
            "Model Number: 159 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 160 with model MetricMotif in generation 0 of 10\n",
            "Model Number: 161 with model ConstantNaive in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.24806e-25): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 162 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 163 with model Theta in generation 0 of 10\n",
            "Model Number: 164 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 165 with model Theta in generation 0 of 10\n",
            "Model Number: 166 with model ETS in generation 0 of 10\n",
            "Model Number: 167 with model GLM in generation 0 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 167 in generation 0: GLM\n",
            "Model Number: 168 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 169 with model ConstantNaive in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 169 in generation 0: ConstantNaive\n",
            "Model Number: 170 with model ARCH in generation 0 of 10\n",
            "Template Eval Error: ImportError('`arch` package must be installed from pip') in model 170 in generation 0: ARCH\n",
            "Model Number: 171 with model FBProphet in generation 0 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/w7g54c78.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/efges2w3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=54265', 'data', 'file=/tmp/tmp2xi3y8fj/w7g54c78.json', 'init=/tmp/tmp2xi3y8fj/efges2w3.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelvfjrjym2/prophet_model-20230410130357.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:03:57 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:03:57 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 172 with model AverageValueNaive in generation 0 of 10\n",
            "Model Number: 173 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 174 with model Theta in generation 0 of 10\n",
            "Model Number: 175 with model GLM in generation 0 of 10\n",
            "Model Number: 176 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 177 with model ARDL in generation 0 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 177 in generation 0: ARDL\n",
            "Model Number: 178 with model MultivariateMotif in generation 0 of 10\n",
            "Model Number: 179 with model NVAR in generation 0 of 10\n",
            "Model Number: 180 with model UnivariateMotif in generation 0 of 10\n",
            "Model Number: 181 with model Theta in generation 0 of 10\n",
            "Model Number: 182 with model SectionalMotif in generation 0 of 10\n",
            "Model Number: 183 with model ARIMA in generation 0 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 183 in generation 0: ARIMA\n",
            "Model Number: 184 with model VECM in generation 0 of 10\n",
            "Template Eval Error: ValueError('Only gave one variable to VECM') in model 184 in generation 0: VECM\n",
            "Model Number: 185 with model NVAR in generation 0 of 10\n",
            "Model Number: 186 with model SeasonalNaive in generation 0 of 10\n",
            "New Generation: 1 of 10\n",
            "Model Number: 187 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 188 with model ETS in generation 1 of 10\n",
            "Model Number: 189 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 190 with model MultivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 191 with model WindowRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 191 in generation 1: WindowRegression\n",
            "Model Number: 192 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 193 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 194 with model ARDL in generation 1 of 10\n",
            "Model Number: 195 with model GLS in generation 1 of 10\n",
            "Model Number: 196 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 197 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 198 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 198 in generation 1: ARDL\n",
            "Model Number: 199 with model Theta in generation 1 of 10\n",
            "Model Number: 200 with model UnivariateMotif in generation 1 of 10\n",
            "HolidayTransformer: no anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/r6hfpfu4.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/uzc163zu.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=62578', 'data', 'file=/tmp/tmp2xi3y8fj/r6hfpfu4.json', 'init=/tmp/tmp2xi3y8fj/uzc163zu.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelik7knnnk/prophet_model-20230410130359.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:03:59 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 201 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:03:59 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 202 with model ETS in generation 1 of 10\n",
            "Model Number: 203 with model WindowRegression in generation 1 of 10\n",
            "Model Number: 204 with model ARDL in generation 1 of 10\n",
            "Model Number: 205 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 206 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 207 with model Theta in generation 1 of 10\n",
            "Model Number: 208 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 209 with model NVAR in generation 1 of 10\n",
            "Model Number: 210 with model GLM in generation 1 of 10\n",
            "Model Number: 211 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 212 with model MetricMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/ca3jm36x.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 213 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/85bwni7r.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84794', 'data', 'file=/tmp/tmp2xi3y8fj/ca3jm36x.json', 'init=/tmp/tmp2xi3y8fj/85bwni7r.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelf8k8r9je/prophet_model-20230410130400.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:04:00 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:04:00 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 214 with model GLM in generation 1 of 10\n",
            "Model Number: 215 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 216 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 216 in generation 1: ARIMA\n",
            "Model Number: 217 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 218 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 219 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 220 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 221 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 222 with model FBProphet in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 222 in generation 1: FBProphet\n",
            "Model Number: 223 with model ARIMA in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 223 in generation 1: ARIMA\n",
            "Model Number: 224 with model ARDL in generation 1 of 10\n",
            "Model Number: 225 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 226 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 227 with model ETS in generation 1 of 10\n",
            "Model Number: 228 with model UnivariateMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 229 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 230 with model Theta in generation 1 of 10\n",
            "Model Number: 231 with model ARDL in generation 1 of 10\n",
            "Model Number: 232 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 233 with model GLS in generation 1 of 10\n",
            "Model Number: 234 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 235 with model MetricMotif in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/tgfb0te3.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/61pty1kf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=2373', 'data', 'file=/tmp/tmp2xi3y8fj/tgfb0te3.json', 'init=/tmp/tmp2xi3y8fj/61pty1kf.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model9nblsyv2/prophet_model-20230410130402.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:04:02 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:04:02 - cmdstanpy - INFO - Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 236 with model FBProphet in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 237 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 238 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 239 with model ARIMA in generation 1 of 10\n",
            "Model Number: 240 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 241 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 242 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 243 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 244 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 245 with model Theta in generation 1 of 10\n",
            "Model Number: 246 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 247 with model Theta in generation 1 of 10\n",
            "Model Number: 248 with model Theta in generation 1 of 10\n",
            "Model Number: 249 with model MultivariateRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 249 in generation 1: MultivariateRegression\n",
            "Model Number: 250 with model ARDL in generation 1 of 10\n",
            "Model Number: 251 with model ARDL in generation 1 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 252 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 253 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 254 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 255 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 256 with model GLS in generation 1 of 10\n",
            "Model Number: 257 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 258 with model DatepartRegression in generation 1 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 258 in generation 1: DatepartRegression\n",
            "Model Number: 259 with model Theta in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 260 with model ETS in generation 1 of 10\n",
            "Model Number: 261 with model Theta in generation 1 of 10\n",
            "Model Number: 262 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 263 with model Theta in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 264 with model ARIMA in generation 1 of 10\n",
            "Model Number: 265 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 266 with model ARDL in generation 1 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 266 in generation 1: ARDL\n",
            "Model Number: 267 with model UnivariateMotif in generation 1 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 268 with model Theta in generation 1 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 0.000e+00, tolerance: 0.000e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 269 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 270 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 271 with model DatepartRegression in generation 1 of 10\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - 6s 19ms/step - loss: 0.0710\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0445\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0336\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0357\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0372\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.0345\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0330\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0321\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0329\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0333\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0323\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0321\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0316\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0329\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0317\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0316\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0314\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0318\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0329\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0324\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0305\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0302\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0327\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0319\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0317\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0325\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0321\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0318\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.0309\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0318\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 0.0310\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.0314\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0314\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.0305\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0305\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0314\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0300\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0316\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0307\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0314\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0310\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0307\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0303\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0304\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0298\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.0304\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0304\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.0307\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 0.0306\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 0.0311\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Model Number: 272 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 273 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 274 with model GLS in generation 1 of 10\n",
            "Model Number: 275 with model MultivariateRegression in generation 1 of 10\n",
            "Model Number: 276 with model ARIMA in generation 1 of 10\n",
            "Model Number: 277 with model ETS in generation 1 of 10\n",
            "Model Number: 278 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 279 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 280 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 281 with model UnivariateMotif in generation 1 of 10\n",
            "Model Number: 282 with model NVAR in generation 1 of 10\n",
            "Model Number: 283 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 284 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 285 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 286 with model WindowRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 286 in generation 1: WindowRegression\n",
            "Model Number: 287 with model SectionalMotif in generation 1 of 10\n",
            "Model Number: 288 with model DatepartRegression in generation 1 of 10\n",
            "Model Number: 289 with model NVAR in generation 1 of 10\n",
            "Model Number: 290 with model ARIMA in generation 1 of 10\n",
            "Model Number: 291 with model ETS in generation 1 of 10\n",
            "Model Number: 292 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 293 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 294 with model WindowRegression in generation 1 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 294 in generation 1: WindowRegression\n",
            "Model Number: 295 with model UnobservedComponents in generation 1 of 10\n",
            "Model Number: 296 with model Theta in generation 1 of 10\n",
            "Model Number: 297 with model Theta in generation 1 of 10\n",
            "Model Number: 298 with model MultivariateMotif in generation 1 of 10\n",
            "Model Number: 299 with model Theta in generation 1 of 10\n",
            "Model Number: 300 with model ARDL in generation 1 of 10\n",
            "Model Number: 301 with model Theta in generation 1 of 10\n",
            "Model Number: 302 with model LastValueNaive in generation 1 of 10\n",
            "Model Number: 303 with model ARIMA in generation 1 of 10\n",
            "Model Number: 304 with model AverageValueNaive in generation 1 of 10\n",
            "Model Number: 305 with model SeasonalNaive in generation 1 of 10\n",
            "Model Number: 306 with model ETS in generation 1 of 10\n",
            "Model Number: 307 with model MetricMotif in generation 1 of 10\n",
            "Model Number: 308 with model ETS in generation 1 of 10\n",
            "Model Number: 309 with model ARDL in generation 1 of 10\n",
            "Model Number: 310 with model ConstantNaive in generation 1 of 10\n",
            "Model Number: 311 with model AverageValueNaive in generation 1 of 10\n",
            "New Generation: 2 of 10\n",
            "Model Number: 312 with model Theta in generation 2 of 10\n",
            "Model Number: 313 with model GLM in generation 2 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 313 in generation 2: GLM\n",
            "Model Number: 314 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 315 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 316 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 316 in generation 2: UnobservedComponents\n",
            "Model Number: 317 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 318 with model UnivariateMotif in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1342: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1346: RuntimeWarning: invalid value encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1346: RuntimeWarning: divide by zero encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 319 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 320 with model Theta in generation 2 of 10\n",
            "Model Number: 321 with model ARIMA in generation 2 of 10\n",
            "Model Number: 322 with model UnobservedComponents in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 322 in generation 2: UnobservedComponents\n",
            "Model Number: 323 with model ETS in generation 2 of 10\n",
            "Model Number: 324 with model NVAR in generation 2 of 10\n",
            "Model Number: 325 with model SectionalMotif in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 325 in generation 2: SectionalMotif\n",
            "Model Number: 326 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 327 with model NVAR in generation 2 of 10\n",
            "Model Number: 328 with model GLM in generation 2 of 10\n",
            "Model Number: 329 with model Theta in generation 2 of 10\n",
            "Model Number: 330 with model MultivariateRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 331 with model FBProphet in generation 2 of 10\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/swqeuqho.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/zo7mira6.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=81891', 'data', 'file=/tmp/tmp2xi3y8fj/swqeuqho.json', 'init=/tmp/tmp2xi3y8fj/zo7mira6.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelz7fy7056/prophet_model-20230410130454.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:04:54 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:04:54 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 332 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 333 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 334 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 335 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 336 with model ARIMA in generation 2 of 10\n",
            "Model Number: 337 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 338 with model ETS in generation 2 of 10\n",
            "Model Number: 339 with model MultivariateRegression in generation 2 of 10\n",
            "Model Number: 340 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 341 with model ARDL in generation 2 of 10\n",
            "Model Number: 342 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 343 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 344 with model AverageValueNaive in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 344 in generation 2: AverageValueNaive\n",
            "Model Number: 345 with model ARIMA in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 345 in generation 2: ARIMA\n",
            "Model Number: 346 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 347 with model MetricMotif in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 347 in generation 2: MetricMotif\n",
            "Model Number: 348 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 349 with model GLS in generation 2 of 10\n",
            "Model Number: 350 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 351 with model ARDL in generation 2 of 10\n",
            "Model Number: 352 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 352 in generation 2: DatepartRegression\n",
            "Model Number: 353 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 354 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 355 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 356 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 357 with model GLM in generation 2 of 10\n",
            "Model Number: 358 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 359 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 360 with model ARIMA in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 360 in generation 2: ARIMA\n",
            "Model Number: 361 with model ETS in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 361 in generation 2: ETS\n",
            "Model Number: 362 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 363 with model Theta in generation 2 of 10\n",
            "Model Number: 364 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 365 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 366 with model UnivariateMotif in generation 2 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 367 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 368 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 369 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 370 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 371 with model ARDL in generation 2 of 10\n",
            "Model Number: 372 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/el3dkhhe.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/vpwac0oz.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=37724', 'data', 'file=/tmp/tmp2xi3y8fj/el3dkhhe.json', 'init=/tmp/tmp2xi3y8fj/vpwac0oz.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelgtm8a9g_/prophet_model-20230410130500.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:05:00 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:05:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 373 with model ETS in generation 2 of 10\n",
            "Model Number: 374 with model MetricMotif in generation 2 of 10\n",
            "Model Number: 375 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 376 with model UnivariateMotif in generation 2 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 377 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 378 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 379 with model ETS in generation 2 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 380 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 381 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 382 with model NVAR in generation 2 of 10\n",
            "Model Number: 383 with model ARDL in generation 2 of 10\n",
            "Model Number: 384 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 385 with model SeasonalNaive in generation 2 of 10\n",
            "Model Number: 386 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 387 with model Theta in generation 2 of 10\n",
            "Model Number: 388 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 389 with model GLM in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 389 in generation 2: GLM\n",
            "Model Number: 390 with model ARIMA in generation 2 of 10\n",
            "Model Number: 391 with model Theta in generation 2 of 10\n",
            "Model Number: 392 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 393 with model ARIMA in generation 2 of 10\n",
            "Model Number: 394 with model ARDL in generation 2 of 10\n",
            "Model Number: 395 with model GLS in generation 2 of 10\n",
            "Model Number: 396 with model Theta in generation 2 of 10\n",
            "Model Number: 397 with model ARDL in generation 2 of 10\n",
            "Model Number: 398 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 399 with model ARDL in generation 2 of 10\n",
            "Model Number: 400 with model SectionalMotif in generation 2 of 10\n",
            "Model Number: 401 with model ConstantNaive in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (250) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/3756257i.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/ftf8nut1.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=94374', 'data', 'file=/tmp/tmp2xi3y8fj/3756257i.json', 'init=/tmp/tmp2xi3y8fj/ftf8nut1.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelfav4tk7k/prophet_model-20230410130514.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:05:14 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 402 with model FBProphet in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:05:15 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 403 with model ARIMA in generation 2 of 10\n",
            "Model Number: 404 with model Theta in generation 2 of 10\n",
            "Model Number: 405 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 406 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 407 with model ARIMA in generation 2 of 10\n",
            "Model Number: 408 with model NVAR in generation 2 of 10\n",
            "Model Number: 409 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 410 with model ARIMA in generation 2 of 10\n",
            "Model Number: 411 with model DatepartRegression in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 411 in generation 2: DatepartRegression\n",
            "Model Number: 412 with model MultivariateRegression in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/xfzg6qv0.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/ff0m6l_v.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=77336', 'data', 'file=/tmp/tmp2xi3y8fj/xfzg6qv0.json', 'init=/tmp/tmp2xi3y8fj/ff0m6l_v.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelf17e69qx/prophet_model-20230410130525.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:05:25 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:05:25 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 413 with model FBProphet in generation 2 of 10\n",
            "Model Number: 414 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 415 with model ARIMA in generation 2 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 415 in generation 2: ARIMA\n",
            "Model Number: 416 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 417 with model ETS in generation 2 of 10\n",
            "Model Number: 418 with model UnobservedComponents in generation 2 of 10\n",
            "Model Number: 419 with model ConstantNaive in generation 2 of 10\n",
            "Model Number: 420 with model WindowRegression in generation 2 of 10\n",
            "Model Number: 421 with model DatepartRegression in generation 2 of 10\n",
            "Model Number: 422 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 423 with model ARDL in generation 2 of 10\n",
            "Model Number: 424 with model ETS in generation 2 of 10\n",
            "Model Number: 425 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 426 with model Theta in generation 2 of 10\n",
            "Model Number: 427 with model Theta in generation 2 of 10\n",
            "Model Number: 428 with model MetricMotif in generation 2 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 428 in generation 2: MetricMotif\n",
            "Model Number: 429 with model ARIMA in generation 2 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 430 with model UnivariateMotif in generation 2 of 10\n",
            "Model Number: 431 with model Theta in generation 2 of 10\n",
            "Model Number: 432 with model MultivariateMotif in generation 2 of 10\n",
            "Model Number: 433 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 434 with model LastValueNaive in generation 2 of 10\n",
            "Model Number: 435 with model AverageValueNaive in generation 2 of 10\n",
            "Model Number: 436 with model MetricMotif in generation 2 of 10\n",
            "New Generation: 3 of 10\n",
            "Model Number: 437 with model GLS in generation 3 of 10\n",
            "Model Number: 438 with model NVAR in generation 3 of 10\n",
            "Model Number: 439 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 440 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 441 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 442 with model ARDL in generation 3 of 10\n",
            "Model Number: 443 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 444 with model ETS in generation 3 of 10\n",
            "Model Number: 445 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 446 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 447 with model ARIMA in generation 3 of 10\n",
            "Model Number: 448 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 449 with model WindowRegression in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer FastICA failed on fit') in model 449 in generation 3: WindowRegression\n",
            "Model Number: 450 with model UnivariateMotif in generation 3 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 451 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 452 with model ARDL in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:620: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  K = (u / d).T[:n_components]  # see (6.33) p.140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 453 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 454 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 455 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 456 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 457 with model NVAR in generation 3 of 10\n",
            "Model Number: 458 with model ETS in generation 3 of 10\n",
            "Model Number: 459 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 460 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 461 with model UnivariateMotif in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 461 in generation 3: UnivariateMotif\n",
            "Model Number: 462 with model LastValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/awh7zd2_.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/sgwqtdbd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=75671', 'data', 'file=/tmp/tmp2xi3y8fj/awh7zd2_.json', 'init=/tmp/tmp2xi3y8fj/sgwqtdbd.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model2rfx9zre/prophet_model-20230410130603.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:06:03 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 463 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:06:03 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 464 with model NVAR in generation 3 of 10\n",
            "Model Number: 465 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 466 with model UnivariateMotif in generation 3 of 10\n",
            "Template Eval Error: ValueError('Model UnivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 466 in generation 3: UnivariateMotif\n",
            "Model Number: 467 with model ARDL in generation 3 of 10\n",
            "Model Number: 468 with model ETS in generation 3 of 10\n",
            "Model Number: 469 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 470 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 471 with model NVAR in generation 3 of 10\n",
            "Model Number: 472 with model ETS in generation 3 of 10\n",
            "Model Number: 473 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 474 with model ARDL in generation 3 of 10\n",
            "Model Number: 475 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 476 with model ARDL in generation 3 of 10\n",
            "Model Number: 477 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 478 with model ARDL in generation 3 of 10\n",
            "Model Number: 479 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 480 with model ARDL in generation 3 of 10\n",
            "Model Number: 481 with model Theta in generation 3 of 10\n",
            "Model Number: 482 with model ARIMA in generation 3 of 10\n",
            "Model Number: 483 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 484 with model Theta in generation 3 of 10\n",
            "Model Number: 485 with model GLS in generation 3 of 10\n",
            "Model Number: 486 with model Theta in generation 3 of 10\n",
            "Model Number: 487 with model GLM in generation 3 of 10\n",
            "Model Number: 488 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 489 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 490 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 491 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 492 with model ARIMA in generation 3 of 10\n",
            "Model Number: 493 with model ARIMA in generation 3 of 10\n",
            "Model Number: 494 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 495 with model ARDL in generation 3 of 10\n",
            "Model Number: 496 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 497 with model ARIMA in generation 3 of 10\n",
            "Model Number: 498 with model AverageValueNaive in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/tdd97nj5.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/x3cmfhom.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=2609', 'data', 'file=/tmp/tmp2xi3y8fj/tdd97nj5.json', 'init=/tmp/tmp2xi3y8fj/x3cmfhom.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelh9msewdg/prophet_model-20230410130650.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:06:50 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 499 with model FBProphet in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:06:51 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 500 with model ARIMA in generation 3 of 10\n",
            "Model Number: 501 with model UnivariateMotif in generation 3 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 502 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 503 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 504 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 505 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 506 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 507 with model ARIMA in generation 3 of 10\n",
            "Model Number: 508 with model ETS in generation 3 of 10\n",
            "Model Number: 509 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 510 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 511 with model GLM in generation 3 of 10\n",
            "Model Number: 512 with model WindowRegression in generation 3 of 10\n",
            "Model Number: 513 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 514 with model GLM in generation 3 of 10\n",
            "Model Number: 515 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 515 in generation 3: DatepartRegression\n",
            "Model Number: 516 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 517 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 518 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 519 with model ARDL in generation 3 of 10\n",
            "Model Number: 520 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 521 with model GLS in generation 3 of 10\n",
            "Model Number: 522 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 523 with model ARIMA in generation 3 of 10\n",
            "Model Number: 524 with model WindowRegression in generation 3 of 10\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000037 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000033 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000036 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Model Number: 525 with model MultivariateRegression in generation 3 of 10\n",
            "Model Number: 526 with model ARDL in generation 3 of 10\n",
            "Model Number: 527 with model ConstantNaive in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'akima', 'transformations': {'0': 'HPFilter', '1': 'STLFilter', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'part': 'trend', 'lamb': 129600}, '1': {'decomp_type': 'STL', 'part': 'trend', 'seasonal': 7}, '2': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 0.7, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 527 in generation 3: ConstantNaive\n",
            "Model Number: 528 with model SeasonalNaive in generation 3 of 10\n",
            "Model Number: 529 with model DatepartRegression in generation 3 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 13s 183ms/step - loss: 81375.3438 - val_loss: 36387.2070\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 83436.7031 - val_loss: 33198.0078\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 71331.0469 - val_loss: 30012.2461\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 75016.1562 - val_loss: 26800.2090\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 71974.3984 - val_loss: 23573.1797\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 58664.1289 - val_loss: 20394.8418\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 63490.2578 - val_loss: 17462.5215\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 62120.1562 - val_loss: 14646.3496\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 57546.8438 - val_loss: 12050.7432\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 57340.8906 - val_loss: 9557.9883\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 52096.7852 - val_loss: 7238.1978\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 57982.4961 - val_loss: 5160.5854\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 53361.1289 - val_loss: 3540.2253\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 56069.3711 - val_loss: 2277.4683\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 50600.0430 - val_loss: 1164.9622\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 56171.2812 - val_loss: 449.6500\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 43102.6680 - val_loss: 19.2922\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 60652.3516 - val_loss: 227.7708\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 56244.2148 - val_loss: 153.1195\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 48976.1797 - val_loss: 32.0577\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 57318.5352 - val_loss: 94.4442\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 52676.6680 - val_loss: 15.4966\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 52514.6172 - val_loss: 568.8513\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 57353.9180 - val_loss: 1206.7661\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 52596.9922 - val_loss: 1581.4138\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 51662.4336 - val_loss: 1648.9669\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 55621.5000 - val_loss: 1485.9650\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 52994.4922 - val_loss: 1845.3436\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 45387.7109 - val_loss: 2155.1658\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 50132.9141 - val_loss: 2318.1631\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 51990.7969 - val_loss: 2372.4604\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 52456.2188 - val_loss: 2684.4780\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 529 in generation 3: DatepartRegression\n",
            "Model Number: 530 with model Theta in generation 3 of 10\n",
            "Model Number: 531 with model LastValueNaive in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 531 in generation 3: LastValueNaive\n",
            "Model Number: 532 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 533 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 534 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 535 with model ARIMA in generation 3 of 10\n",
            "Model Number: 536 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 537 with model Theta in generation 3 of 10\n",
            "Model Number: 538 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 539 with model Theta in generation 3 of 10\n",
            "Model Number: 540 with model LastValueNaive in generation 3 of 10\n",
            "Model Number: 541 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 542 with model GLM in generation 3 of 10\n",
            "Model Number: 543 with model DatepartRegression in generation 3 of 10\n",
            "Model Number: 544 with model MultivariateMotif in generation 3 of 10\n",
            "Model Number: 545 with model WindowRegression in generation 3 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 546 with model ETS in generation 3 of 10\n",
            "Model Number: 547 with model DatepartRegression in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 547 in generation 3: DatepartRegression\n",
            "Model Number: 548 with model UnobservedComponents in generation 3 of 10\n",
            "Model Number: 549 with model UnobservedComponents in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 549 in generation 3: UnobservedComponents\n",
            "Model Number: 550 with model NVAR in generation 3 of 10\n",
            "Model Number: 551 with model AverageValueNaive in generation 3 of 10\n",
            "Model Number: 552 with model SectionalMotif in generation 3 of 10\n",
            "Model Number: 553 with model ETS in generation 3 of 10\n",
            "Model Number: 554 with model ARIMA in generation 3 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 554 in generation 3: ARIMA\n",
            "Model Number: 555 with model UnivariateMotif in generation 3 of 10\n",
            "Model Number: 556 with model ETS in generation 3 of 10\n",
            "Model Number: 557 with model ConstantNaive in generation 3 of 10\n",
            "Model Number: 558 with model GLS in generation 3 of 10\n",
            "Model Number: 559 with model MetricMotif in generation 3 of 10\n",
            "Model Number: 560 with model ARDL in generation 3 of 10\n",
            "Model Number: 561 with model MultivariateMotif in generation 3 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 561 in generation 3: MultivariateMotif\n",
            "New Generation: 4 of 10\n",
            "Model Number: 562 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 563 with model GLM in generation 4 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 563 in generation 4: GLM\n",
            "Model Number: 564 with model ARIMA in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 565 with model NVAR in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 565 in generation 4: NVAR\n",
            "Model Number: 566 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 567 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 568 with model FBProphet in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 568 in generation 4: FBProphet\n",
            "Model Number: 569 with model GLS in generation 4 of 10\n",
            "Model Number: 570 with model Theta in generation 4 of 10\n",
            "Model Number: 571 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 572 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 573 with model ARDL in generation 4 of 10\n",
            "Model Number: 574 with model ARIMA in generation 4 of 10\n",
            "Model Number: 575 with model ARIMA in generation 4 of 10\n",
            "Model Number: 576 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 577 with model GLS in generation 4 of 10\n",
            "Model Number: 578 with model DatepartRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 578 in generation 4: DatepartRegression\n",
            "Model Number: 579 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 580 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 581 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 582 with model AverageValueNaive in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 582 in generation 4: AverageValueNaive\n",
            "Model Number: 583 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 584 with model ARIMA in generation 4 of 10\n",
            "Model Number: 585 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 586 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 587 with model GLM in generation 4 of 10\n",
            "Model Number: 588 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 589 with model ARDL in generation 4 of 10\n",
            "Model Number: 590 with model MultivariateRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 591 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 592 with model Theta in generation 4 of 10\n",
            "Model Number: 593 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 594 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 595 with model Theta in generation 4 of 10\n",
            "Model Number: 596 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 597 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 598 with model Theta in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 599 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 600 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 601 with model Theta in generation 4 of 10\n",
            "Model Number: 602 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 603 with model ARDL in generation 4 of 10\n",
            "Model Number: 604 with model Theta in generation 4 of 10\n",
            "Model Number: 605 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 606 with model ARIMA in generation 4 of 10\n",
            "Model Number: 607 with model Theta in generation 4 of 10\n",
            "Model Number: 608 with model GLM in generation 4 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 608 in generation 4: GLM\n",
            "Model Number: 609 with model AverageValueNaive in generation 4 of 10\n",
            "Model Number: 610 with model DatepartRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 611 with model ETS in generation 4 of 10\n",
            "Model Number: 612 with model ARIMA in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 612 in generation 4: ARIMA\n",
            "Model Number: 613 with model ARIMA in generation 4 of 10\n",
            "Model Number: 614 with model ARIMA in generation 4 of 10\n",
            "Model Number: 615 with model ETS in generation 4 of 10\n",
            "Model Number: 616 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 617 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 618 with model SeasonalNaive in generation 4 of 10\n",
            "Model Number: 619 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 620 with model ARDL in generation 4 of 10\n",
            "Model Number: 621 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 622 with model MultivariateMotif in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/prd9r01o.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/icvh5_46.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=11579', 'data', 'file=/tmp/tmp2xi3y8fj/prd9r01o.json', 'init=/tmp/tmp2xi3y8fj/icvh5_46.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelp7df8w0i/prophet_model-20230410130910.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:09:10 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 623 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:09:10 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 624 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 625 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 626 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 627 with model Theta in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 627 in generation 4: Theta\n",
            "Model Number: 628 with model GLS in generation 4 of 10\n",
            "Model Number: 629 with model GLS in generation 4 of 10\n",
            "Model Number: 630 with model ARDL in generation 4 of 10\n",
            "Model Number: 631 with model GLS in generation 4 of 10\n",
            "Model Number: 632 with model GLM in generation 4 of 10\n",
            "Model Number: 633 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 634 with model GLM in generation 4 of 10\n",
            "Model Number: 635 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 636 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 637 with model ETS in generation 4 of 10\n",
            "Model Number: 638 with model ARIMA in generation 4 of 10\n",
            "Model Number: 639 with model ARIMA in generation 4 of 10\n",
            "Model Number: 640 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 641 with model ETS in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/pcrluird.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/c5b4h1o7.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=894', 'data', 'file=/tmp/tmp2xi3y8fj/pcrluird.json', 'init=/tmp/tmp2xi3y8fj/c5b4h1o7.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model1u8vpii1/prophet_model-20230410130952.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:09:52 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 642 with model FBProphet in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:09:52 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 643 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 644 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 645 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 646 with model ConstantNaive in generation 4 of 10\n",
            "Model Number: 647 with model ARDL in generation 4 of 10\n",
            "Model Number: 648 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 649 with model ARDL in generation 4 of 10\n",
            "Model Number: 650 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 651 with model ARIMA in generation 4 of 10\n",
            "Model Number: 652 with model ARDL in generation 4 of 10\n",
            "Model Number: 653 with model GLM in generation 4 of 10\n",
            "Model Number: 654 with model Theta in generation 4 of 10\n",
            "Model Number: 655 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 656 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 657 with model WindowRegression in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 658 with model MultivariateRegression in generation 4 of 10\n",
            "Model Number: 659 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 660 with model NVAR in generation 4 of 10\n",
            "Model Number: 661 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 662 with model ARDL in generation 4 of 10\n",
            "Model Number: 663 with model MultivariateRegression in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 663 in generation 4: MultivariateRegression\n",
            "Model Number: 664 with model GLM in generation 4 of 10\n",
            "Model Number: 665 with model UnobservedComponents in generation 4 of 10\n",
            "Model Number: 666 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 667 with model SectionalMotif in generation 4 of 10\n",
            "Model Number: 668 with model ARDL in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.24806e-25): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 669 with model Theta in generation 4 of 10\n",
            "Model Number: 670 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 671 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 672 with model Theta in generation 4 of 10\n",
            "Model Number: 673 with model GLM in generation 4 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 673 in generation 4: GLM\n",
            "Model Number: 674 with model ARDL in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 674 in generation 4: ARDL\n",
            "Model Number: 675 with model MultivariateMotif in generation 4 of 10\n",
            "Model Number: 676 with model LastValueNaive in generation 4 of 10\n",
            "Model Number: 677 with model MultivariateMotif in generation 4 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 677 in generation 4: MultivariateMotif\n",
            "Model Number: 678 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 679 with model AverageValueNaive in generation 4 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 680 with model ARDL in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series #Passengers failed with error ValueError('The number of regressors (177) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larer than the sample available for estimation (130).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nmonth                                                                         \\n1949-01-01        1        1  2432917.5      1.0      0.0      0.0      0.0   \\n1949-02-01        0        1  2432948.5      0.0      1.0      0.0      0.0   \\n1949-03-01        0        1  2432976.5      0.0      0.0      1.0      0.0   \\n1949-04-01        0        2  2433007.5      0.0      0.0      0.0      1.0   \\n1949-05-01        1        2  2433037.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n1959-08-01        1        3  2436781.5      0.0      0.0      0.0      0.0   \\n1959-09-01        0        3  2436812.5      0.0      0.0      0.0      0.0   \\n1959-10-01        0        4  2436842.5      0.0      0.0      0.0      0.0   \\n1959-11-01        1        4  2436873.5      0.0      0.0      0.0      0.0   \\n1959-12-01        0        4  2436903.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nmonth                                  ...                                   \\n1949-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n1959-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nmonth                                                                      \\n1949-01-01     0.0               1.0               0.0               0.0   \\n1949-02-01     0.0               1.0               0.0               0.0   \\n1949-03-01     0.0               1.0               0.0               0.0   \\n1949-04-01     0.0               1.0               0.0               0.0   \\n1949-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n1959-08-01     0.0               1.0               0.0               0.0   \\n1959-09-01     0.0               1.0               0.0               0.0   \\n1959-10-01     0.0               1.0               0.0               0.0   \\n1959-11-01     0.0               1.0               0.0               0.0   \\n1959-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nmonth                                           \\n1949-01-01               0.0               0.0  \\n1949-02-01               0.0               0.0  \\n1949-03-01               0.0               0.0  \\n1949-04-01               0.0               0.0  \\n1949-05-01               0.0               0.0  \\n...                      ...               ...  \\n1959-08-01               0.0               0.0  \\n1959-09-01               0.0               0.0  \\n1959-10-01               0.0               0.0  \\n1959-11-01               0.0               0.0  \\n1959-12-01               0.0               0.0  \\n\\n[132 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n1960-01-01        0        1  2436934.5      1.0      0.0      0.0      0.0   \\n1960-02-01        0        1  2436965.5      0.0      1.0      0.0      0.0   \\n1960-03-01        0        1  2436994.5      0.0      0.0      1.0      0.0   \\n1960-04-01        0        2  2437025.5      0.0      0.0      0.0      1.0   \\n1960-05-01        1        2  2437055.5      0.0      0.0      0.0      0.0   \\n1960-06-01        0        2  2437086.5      0.0      0.0      0.0      0.0   \\n1960-07-01        0        3  2437116.5      0.0      0.0      0.0      0.0   \\n1960-08-01        0        3  2437147.5      0.0      0.0      0.0      0.0   \\n1960-09-01        0        3  2437178.5      0.0      0.0      0.0      0.0   \\n1960-10-01        1        4  2437208.5      0.0      0.0      0.0      0.0   \\n1960-11-01        0        4  2437239.5      0.0      0.0      0.0      0.0   \\n1960-12-01        0        4  2437269.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n1960-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n1960-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n1960-01-01     0.0               1.0               0.0               0.0   \\n1960-02-01     0.0               1.0               0.0               0.0   \\n1960-03-01     0.0               1.0               0.0               0.0   \\n1960-04-01     0.0               1.0               0.0               0.0   \\n1960-05-01     0.0               1.0               0.0               0.0   \\n1960-06-01     0.0               1.0               0.0               0.0   \\n1960-07-01     0.0               1.0               0.0               0.0   \\n1960-08-01     0.0               1.0               0.0               0.0   \\n1960-09-01     0.0               1.0               0.0               0.0   \\n1960-10-01     0.0               1.0               0.0               0.0   \\n1960-11-01     0.0               1.0               0.0               0.0   \\n1960-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n1960-01-01               0.0               0.0  \\n1960-02-01               0.0               0.0  \\n1960-03-01               0.0               0.0  \\n1960-04-01               0.0               0.0  \\n1960-05-01               0.0               0.0  \\n1960-06-01               0.0               0.0  \\n1960-07-01               0.0               0.0  \\n1960-08-01               0.0               0.0  \\n1960-09-01               0.0               0.0  \\n1960-10-01               0.0               0.0  \\n1960-11-01               0.0               0.0  \\n1960-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 680 in generation 4: ARDL\n",
            "Model Number: 681 with model UnivariateMotif in generation 4 of 10\n",
            "Model Number: 682 with model MultivariateMotif in generation 4 of 10\n",
            "Template Eval Error: ValueError(\"Model returned NaN due to a preprocessing transformer {'fillna': 'cubic', 'transformations': {'0': 'SeasonalDifference', '1': 'AlignLastValue', '2': 'AlignLastValue'}, 'transformation_params': {'0': {'lag_1': 84, 'method': 'LastValue'}, '1': {'rows': 4, 'lag': 1, 'method': 'additive', 'strength': 1.0, 'first_value_only': False}, '2': {'rows': 1, 'lag': 1, 'method': 'multiplicative', 'strength': 0.5, 'first_value_only': False}}}. fail_on_forecast_nan=True\") in model 682 in generation 4: MultivariateMotif\n",
            "Model Number: 683 with model ARIMA in generation 4 of 10\n",
            "Model Number: 684 with model DatepartRegression in generation 4 of 10\n",
            "Model Number: 685 with model MetricMotif in generation 4 of 10\n",
            "Model Number: 686 with model DatepartRegression in generation 4 of 10\n",
            "New Generation: 5 of 10\n",
            "Model Number: 687 with model DatepartRegression in generation 5 of 10\n",
            "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 688 with model ConstantNaive in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 688 in generation 5: ConstantNaive\n",
            "Model Number: 689 with model MultivariateRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 690 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 691 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 692 with model GLM in generation 5 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 692 in generation 5: GLM\n",
            "Model Number: 693 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 694 with model DatepartRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 694 in generation 5: DatepartRegression\n",
            "Model Number: 695 with model ARDL in generation 5 of 10\n",
            "Model Number: 696 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 697 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 698 with model MetricMotif in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 699 with model WindowRegression in generation 5 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 3s 45ms/step - loss: 114.8724\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 79.1763\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 68.3034\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 61.8403\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 55.8899\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 46.5869\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 43.2860\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 40.1018\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 37.5141\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 36.4625\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 31.5565\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 30.4577\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 30.7408\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 28.1194\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 28.4058\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 25.7273\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 25.4387\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 24.2612\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21.3087\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 22.9047\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 21.8492\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 20.0454\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 19.7832\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 18.2797\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20.3950\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 18.2032\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 16.6210\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 15.9474\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.5517\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.2463\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 16.2099\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 14.3287\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 15.0817\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 15.6361\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 15.0715\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.3059\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13.6119\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 14.9143\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.9593\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 12.1599\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 14.2567\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 12.6823\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13.4619\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 12.5530\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.1666\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 13.4304\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 15.9088\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 13.0447\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.7444\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 12.3270\n",
            "1/1 [==============================] - 0s 218ms/step\n",
            "Model Number: 700 with model Theta in generation 5 of 10\n",
            "Model Number: 701 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 702 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 703 with model NVAR in generation 5 of 10\n",
            "Model Number: 704 with model ARIMA in generation 5 of 10\n",
            "Model Number: 705 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 706 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 707 with model DatepartRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 707 in generation 5: DatepartRegression\n",
            "Model Number: 708 with model ARIMA in generation 5 of 10\n",
            "Model Number: 709 with model ETS in generation 5 of 10\n",
            "Model Number: 710 with model ARIMA in generation 5 of 10\n",
            "Model Number: 711 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 712 with model Theta in generation 5 of 10\n",
            "Model Number: 713 with model ARDL in generation 5 of 10\n",
            "Model Number: 714 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 715 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 716 with model GLM in generation 5 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 716 in generation 5: GLM\n",
            "Model Number: 717 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 718 with model DatepartRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 719 with model GLS in generation 5 of 10\n",
            "Model Number: 720 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 721 with model Theta in generation 5 of 10\n",
            "Model Number: 722 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 723 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 724 with model ARIMA in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/9octuuik.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/1yfu9jsi.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3376', 'data', 'file=/tmp/tmp2xi3y8fj/9octuuik.json', 'init=/tmp/tmp2xi3y8fj/1yfu9jsi.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelwtnmepyp/prophet_model-20230410131101.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:11:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:11:01 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 725 with model FBProphet in generation 5 of 10\n",
            "Model Number: 726 with model ARIMA in generation 5 of 10\n",
            "Model Number: 727 with model ARIMA in generation 5 of 10\n",
            "Model Number: 728 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 729 with model Theta in generation 5 of 10\n",
            "Model Number: 730 with model ARDL in generation 5 of 10\n",
            "Model Number: 731 with model ARDL in generation 5 of 10\n",
            "Model Number: 732 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 733 with model ARDL in generation 5 of 10\n",
            "Model Number: 734 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 735 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 736 with model Theta in generation 5 of 10\n",
            "Model Number: 737 with model MultivariateMotif in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 737 in generation 5: MultivariateMotif\n",
            "Model Number: 738 with model GLM in generation 5 of 10\n",
            "Model Number: 739 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 740 with model MultivariateRegression in generation 5 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 740 in generation 5: MultivariateRegression\n",
            "Model Number: 741 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 742 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 743 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 744 with model ETS in generation 5 of 10\n",
            "Model Number: 745 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 746 with model NVAR in generation 5 of 10\n",
            "Model Number: 747 with model ARIMA in generation 5 of 10\n",
            "Model Number: 748 with model MetricMotif in generation 5 of 10\n",
            "Model Number: 749 with model ETS in generation 5 of 10\n",
            "Model Number: 750 with model ARDL in generation 5 of 10\n",
            "Model Number: 751 with model WindowRegression in generation 5 of 10\n",
            "Model Number: 752 with model Theta in generation 5 of 10\n",
            "Model Number: 753 with model UnobservedComponents in generation 5 of 10\n",
            "Model Number: 754 with model LastValueNaive in generation 5 of 10\n",
            "Model Number: 755 with model DatepartRegression in generation 5 of 10\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 755 in generation 5: DatepartRegression\n",
            "Model Number: 756 with model WindowRegression in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 757 with model ARDL in generation 5 of 10\n",
            "Model Number: 758 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 759 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 760 with model MetricMotif in generation 5 of 10\n",
            "Model Number: 761 with model ETS in generation 5 of 10\n",
            "Model Number: 762 with model MultivariateRegression in generation 5 of 10\n",
            "Model Number: 763 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 764 with model GLM in generation 5 of 10\n",
            "Model Number: 765 with model GLM in generation 5 of 10\n",
            "Model Number: 766 with model MetricMotif in generation 5 of 10\n",
            "Model Number: 767 with model AverageValueNaive in generation 5 of 10\n",
            "Model Number: 768 with model ARDL in generation 5 of 10\n",
            "Model Number: 769 with model ARIMA in generation 5 of 10\n",
            "Model Number: 770 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 771 with model ARIMA in generation 5 of 10\n",
            "Model Number: 772 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 773 with model UnivariateMotif in generation 5 of 10\n",
            "Model Number: 774 with model ETS in generation 5 of 10\n",
            "Model Number: 775 with model SectionalMotif in generation 5 of 10\n",
            "Model Number: 776 with model GLM in generation 5 of 10\n",
            "Model Number: 777 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 778 with model MetricMotif in generation 5 of 10\n",
            "Model Number: 779 with model Theta in generation 5 of 10\n",
            "Model Number: 780 with model MultivariateMotif in generation 5 of 10\n",
            "Model Number: 781 with model SeasonalNaive in generation 5 of 10\n",
            "Model Number: 782 with model ETS in generation 5 of 10\n",
            "Model Number: 783 with model DatepartRegression in generation 5 of 10\n",
            "Model Number: 784 with model ConstantNaive in generation 5 of 10\n",
            "Model Number: 785 with model AverageValueNaive in generation 5 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 786 with model Theta in generation 5 of 10\n",
            "New Generation: 6 of 10\n",
            "Model Number: 787 with model Theta in generation 6 of 10\n",
            "Model Number: 788 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 789 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 790 with model ARDL in generation 6 of 10\n",
            "Model Number: 791 with model GLS in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 791 in generation 6: GLS\n",
            "Model Number: 792 with model ARIMA in generation 6 of 10\n",
            "Model Number: 793 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 794 with model GLM in generation 6 of 10\n",
            "Model Number: 795 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 796 with model AverageValueNaive in generation 6 of 10\n",
            "Model Number: 797 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 798 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 799 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 800 with model ARDL in generation 6 of 10\n",
            "Model Number: 801 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 802 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 802 in generation 6: DatepartRegression\n",
            "Model Number: 803 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 804 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 805 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 806 with model SeasonalNaive in generation 6 of 10\n",
            "Model Number: 807 with model Theta in generation 6 of 10\n",
            "Model Number: 808 with model ARDL in generation 6 of 10\n",
            "Model Number: 809 with model Theta in generation 6 of 10\n",
            "Model Number: 810 with model MetricMotif in generation 6 of 10\n",
            "Model Number: 811 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 812 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 813 with model ARIMA in generation 6 of 10\n",
            "Model Number: 814 with model GLM in generation 6 of 10\n",
            "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 814 in generation 6: GLM\n",
            "Model Number: 815 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 816 with model ETS in generation 6 of 10\n",
            "Model Number: 817 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 818 with model MetricMotif in generation 6 of 10\n",
            "Model Number: 819 with model LastValueNaive in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1346: RuntimeWarning: divide by zero encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1346: RuntimeWarning: invalid value encountered in log\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:1346: RuntimeWarning: invalid value encountered in multiply\n",
            "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 820 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 821 with model UnobservedComponents in generation 6 of 10\n",
            "Model Number: 822 with model ARDL in generation 6 of 10\n",
            "Model Number: 823 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 824 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 825 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 826 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 827 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 828 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 829 with model NVAR in generation 6 of 10\n",
            "Model Number: 830 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 831 with model ARDL in generation 6 of 10\n",
            "Model Number: 832 with model GLM in generation 6 of 10\n",
            "Model Number: 833 with model MetricMotif in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 833 in generation 6: MetricMotif\n",
            "Model Number: 834 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 835 with model ARIMA in generation 6 of 10\n",
            "Model Number: 836 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 837 with model ETS in generation 6 of 10\n",
            "Model Number: 838 with model ETS in generation 6 of 10\n",
            "Model Number: 839 with model GLM in generation 6 of 10\n",
            "Model Number: 840 with model WindowRegression in generation 6 of 10\n",
            "Model Number: 841 with model SectionalMotif in generation 6 of 10\n",
            "Model Number: 842 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 843 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 844 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 845 with model ETS in generation 6 of 10\n",
            "Model Number: 846 with model MetricMotif in generation 6 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 846 in generation 6: MetricMotif\n",
            "Model Number: 847 with model ARDL in generation 6 of 10\n",
            "Model Number: 848 with model DatepartRegression in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 849 with model GLM in generation 6 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 849 in generation 6: GLM\n",
            "Model Number: 850 with model ARDL in generation 6 of 10\n",
            "Model Number: 851 with model NVAR in generation 6 of 10\n",
            "Model Number: 852 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 853 with model GLM in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 854 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 855 with model ARIMA in generation 6 of 10\n",
            "Model Number: 856 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 857 with model NVAR in generation 6 of 10\n",
            "Model Number: 858 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 859 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 860 with model ARIMA in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 861 with model ARDL in generation 6 of 10\n",
            "Model Number: 862 with model DatepartRegression in generation 6 of 10\n",
            "Model Number: 863 with model UnobservedComponents in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 863 in generation 6: UnobservedComponents\n",
            "Model Number: 864 with model Theta in generation 6 of 10\n",
            "Model Number: 865 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 866 with model MetricMotif in generation 6 of 10\n",
            "Model Number: 867 with model ARDL in generation 6 of 10\n",
            "Model Number: 868 with model ETS in generation 6 of 10\n",
            "Model Number: 869 with model ARIMA in generation 6 of 10\n",
            "Model Number: 870 with model DatepartRegression in generation 6 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 870 in generation 6: DatepartRegression\n",
            "Model Number: 871 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 872 with model ARIMA in generation 6 of 10\n",
            "Model Number: 873 with model MultivariateRegression in generation 6 of 10\n",
            "Model Number: 874 with model UnivariateMotif in generation 6 of 10\n",
            "Model Number: 875 with model MetricMotif in generation 6 of 10\n",
            "Model Number: 876 with model ARDL in generation 6 of 10\n",
            "Model Number: 877 with model LastValueNaive in generation 6 of 10\n",
            "Model Number: 878 with model Theta in generation 6 of 10\n",
            "Model Number: 879 with model ARDL in generation 6 of 10\n",
            "Model Number: 880 with model GLM in generation 6 of 10\n",
            "Model Number: 881 with model MetricMotif in generation 6 of 10\n",
            "Model Number: 882 with model MultivariateMotif in generation 6 of 10\n",
            "Model Number: 883 with model GLS in generation 6 of 10\n",
            "Model Number: 884 with model GLM in generation 6 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 884 in generation 6: GLM\n",
            "Model Number: 885 with model ConstantNaive in generation 6 of 10\n",
            "Model Number: 886 with model ETS in generation 6 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Generation: 7 of 10\n",
            "Model Number: 887 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 888 with model GLM in generation 7 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 888 in generation 7: GLM\n",
            "Model Number: 889 with model ARDL in generation 7 of 10\n",
            "Model Number: 890 with model UnobservedComponents in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 891 with model UnobservedComponents in generation 7 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 892 with model GLS in generation 7 of 10\n",
            "Model Number: 893 with model GLM in generation 7 of 10\n",
            "Model Number: 894 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 894 in generation 7: DatepartRegression\n",
            "Model Number: 895 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 896 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 897 with model Theta in generation 7 of 10\n",
            "Model Number: 898 with model GLM in generation 7 of 10\n",
            "Model Number: 899 with model ARIMA in generation 7 of 10\n",
            "Model Number: 900 with model GLM in generation 7 of 10\n",
            "Model Number: 901 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 902 with model Theta in generation 7 of 10\n",
            "Model Number: 903 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 904 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 905 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 906 with model UnobservedComponents in generation 7 of 10\n",
            "Model Number: 907 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 908 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 909 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 910 with model ARDL in generation 7 of 10\n",
            "Model Number: 911 with model Theta in generation 7 of 10\n",
            "Model Number: 912 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 913 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 914 with model ETS in generation 7 of 10\n",
            "Model Number: 915 with model GLM in generation 7 of 10\n",
            "Model Number: 916 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 917 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 918 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 919 with model ARIMA in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 919 in generation 7: ARIMA\n",
            "Model Number: 920 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 921 with model NVAR in generation 7 of 10\n",
            "Model Number: 922 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 923 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 924 with model Theta in generation 7 of 10\n",
            "Model Number: 925 with model ARDL in generation 7 of 10\n",
            "Model Number: 926 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 927 with model ARIMA in generation 7 of 10\n",
            "Model Number: 928 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 929 with model ETS in generation 7 of 10\n",
            "Model Number: 930 with model ETS in generation 7 of 10\n",
            "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "ETS failed on #Passengers with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
            "Model Number: 931 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 931 in generation 7: DatepartRegression\n",
            "Model Number: 932 with model GLM in generation 7 of 10\n",
            "Model Number: 933 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 934 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 935 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 936 with model WindowRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 936 in generation 7: WindowRegression\n",
            "Model Number: 937 with model DatepartRegression in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 937 in generation 7: DatepartRegression\n",
            "Model Number: 938 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 939 with model WindowRegression in generation 7 of 10\n",
            "Template Eval Error: XGBoostError('[13:13:52] ../src/objective/regression_obj.cu:340: PoissonRegression: label must be nonnegative\\nStack trace:\\n  [bt] (0) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x674193) [0x7f57f3b88193]\\n  [bt] (1) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x67f0a7) [0x7f57f3b930a7]\\n  [bt] (2) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(+0x2e0492) [0x7f57f37f4492]\\n  [bt] (3) /usr/local/lib/python3.9/dist-packages/xgboost/lib/libxgboost.so(XGBoosterUpdateOneIter+0x70) [0x7f57f36505f0]\\n  [bt] (4) /lib/x86_64-linux-gnu/libffi.so.7(+0x6ff5) [0x7f5a04af4ff5]\\n  [bt] (5) /lib/x86_64-linux-gnu/libffi.so.7(+0x640a) [0x7f5a04af440a]\\n  [bt] (6) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12a55) [0x7f5a04b27a55]\\n  [bt] (7) /usr/lib/python3.9/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so(+0x12e9d) [0x7f5a04b27e9d]\\n  [bt] (8) /usr/bin/python3(_PyObject_MakeTpCall+0x2aa) [0x62a42a]\\n\\n') in model 939 in generation 7: WindowRegression\n",
            "Model Number: 940 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 941 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 942 with model ETS in generation 7 of 10\n",
            "Model Number: 943 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 944 with model Theta in generation 7 of 10\n",
            "Model Number: 945 with model Theta in generation 7 of 10\n",
            "Model Number: 946 with model ARIMA in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 946 in generation 7: ARIMA\n",
            "Model Number: 947 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 948 with model ARDL in generation 7 of 10\n",
            "Model Number: 949 with model ARIMA in generation 7 of 10\n",
            "Model Number: 950 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 951 with model ARDL in generation 7 of 10\n",
            "Model Number: 952 with model ConstantNaive in generation 7 of 10\n",
            "Model Number: 953 with model ARDL in generation 7 of 10\n",
            "Model Number: 954 with model GLS in generation 7 of 10\n",
            "Model Number: 955 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 956 with model Theta in generation 7 of 10\n",
            "Model Number: 957 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 958 with model WindowRegression in generation 7 of 10\n",
            "Model Number: 959 with model SectionalMotif in generation 7 of 10\n",
            "Template Eval Error: ValueError('kth(=100) out of bounds (91)') in model 959 in generation 7: SectionalMotif\n",
            "Model Number: 960 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 961 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 962 with model Theta in generation 7 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 962 in generation 7: Theta\n",
            "Model Number: 963 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 964 with model ARDL in generation 7 of 10\n",
            "Model Number: 965 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 966 with model MultivariateRegression in generation 7 of 10\n",
            "Model Number: 967 with model Theta in generation 7 of 10\n",
            "Model Number: 968 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 969 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 970 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 971 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 972 with model GLM in generation 7 of 10\n",
            "Model Number: 973 with model SeasonalNaive in generation 7 of 10\n",
            "Model Number: 974 with model UnivariateMotif in generation 7 of 10\n",
            "Model Number: 975 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 976 with model AverageValueNaive in generation 7 of 10\n",
            "Model Number: 977 with model MetricMotif in generation 7 of 10\n",
            "Model Number: 978 with model GLM in generation 7 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 978 in generation 7: GLM\n",
            "Model Number: 979 with model SectionalMotif in generation 7 of 10\n",
            "Model Number: 980 with model ARIMA in generation 7 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 980 in generation 7: ARIMA\n",
            "Model Number: 981 with model LastValueNaive in generation 7 of 10\n",
            "Model Number: 982 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 983 with model Theta in generation 7 of 10\n",
            "Model Number: 984 with model MultivariateMotif in generation 7 of 10\n",
            "Model Number: 985 with model DatepartRegression in generation 7 of 10\n",
            "Model Number: 986 with model LastValueNaive in generation 7 of 10\n",
            "New Generation: 8 of 10\n",
            "Model Number: 987 with model UnobservedComponents in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 987 in generation 8: UnobservedComponents\n",
            "Model Number: 988 with model GLM in generation 8 of 10\n",
            "Model Number: 989 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 990 with model ETS in generation 8 of 10\n",
            "Model Number: 991 with model ARDL in generation 8 of 10\n",
            "Model Number: 992 with model Theta in generation 8 of 10\n",
            "Model Number: 993 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 994 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 995 with model WindowRegression in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 996 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 997 with model GLM in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 998 with model ARIMA in generation 8 of 10\n",
            "Model Number: 999 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1000 with model GLM in generation 8 of 10\n",
            "Model Number: 1001 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1002 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1003 with model AverageValueNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1003 in generation 8: AverageValueNaive\n",
            "Model Number: 1004 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1004 in generation 8: DatepartRegression\n",
            "Model Number: 1005 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 1006 with model Theta in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1006 in generation 8: Theta\n",
            "Model Number: 1007 with model MetricMotif in generation 8 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 1008 with model ETS in generation 8 of 10\n",
            "Model Number: 1009 with model DatepartRegression in generation 8 of 10\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 4s 137ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 18ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 22ms/step - loss: nan - val_loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f58870f9f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 165ms/step\n",
            "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 1009 in generation 8: DatepartRegression\n",
            "Model Number: 1010 with model AverageValueNaive in generation 8 of 10\n",
            "Model Number: 1011 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1012 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1013 with model Theta in generation 8 of 10\n",
            "Model Number: 1014 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1014 in generation 8: DatepartRegression\n",
            "Model Number: 1015 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1016 with model GLM in generation 8 of 10\n",
            "Model Number: 1017 with model ARDL in generation 8 of 10\n",
            "Model Number: 1018 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1019 with model GLM in generation 8 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 1019 in generation 8: GLM\n",
            "Model Number: 1020 with model SeasonalNaive in generation 8 of 10\n",
            "Model Number: 1021 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1022 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1023 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1024 with model GLM in generation 8 of 10\n",
            "Model Number: 1025 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1026 with model Theta in generation 8 of 10\n",
            "Model Number: 1027 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1028 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: InvalidParameterError(\"The 'base_estimator' parameter of AdaBoostRegressor must be an object implementing 'fit' and 'predict' or a str among {'deprecated'}. Got None instead.\") in model 1028 in generation 8: DatepartRegression\n",
            "Model Number: 1029 with model DatepartRegression in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1029 in generation 8: DatepartRegression\n",
            "Model Number: 1030 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1031 with model ARIMA in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1031 in generation 8: ARIMA\n",
            "Model Number: 1032 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1033 with model GLM in generation 8 of 10\n",
            "Model Number: 1034 with model ETS in generation 8 of 10\n",
            "Model Number: 1035 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1036 with model Theta in generation 8 of 10\n",
            "Model Number: 1037 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1038 with model SeasonalNaive in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1038 in generation 8: SeasonalNaive\n",
            "Model Number: 1039 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1040 with model ARIMA in generation 8 of 10\n",
            "Model Number: 1041 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1042 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1043 with model ARIMA in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1043 in generation 8: ARIMA\n",
            "Model Number: 1044 with model ARDL in generation 8 of 10\n",
            "Model Number: 1045 with model GLS in generation 8 of 10\n",
            "Model Number: 1046 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1047 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 1048 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1049 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 1050 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1051 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1052 with model LastValueNaive in generation 8 of 10\n",
            "Model Number: 1053 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1054 with model WindowRegression in generation 8 of 10\n",
            "Model Number: 1055 with model ETS in generation 8 of 10\n",
            "Model Number: 1056 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 1057 with model NVAR in generation 8 of 10\n",
            "Model Number: 1058 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1059 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1060 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 1061 with model Theta in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/vbs_3w90.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/qaj7pag7.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=16803', 'data', 'file=/tmp/tmp2xi3y8fj/vbs_3w90.json', 'init=/tmp/tmp2xi3y8fj/qaj7pag7.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model9h4lz1ae/prophet_model-20230410131501.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:15:01 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1062 with model FBProphet in generation 8 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:15:02 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1063 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1064 with model ARDL in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series #Passengers failed with error ValueError('The number of regressors (553) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larer than the sample available for estimation (130).') exog train             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\nmonth                                                               ...   \\n1949-01-01  1.0  1.0  2432917.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1949-02-01  1.0  0.0  2432948.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1949-03-01  1.0  0.0  2432976.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n1949-04-01  1.0  0.0  2433007.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n1949-05-01  1.0  1.0  2433037.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n...         ...  ...        ...  ...  ...  ...  ...  ...  ...  ...  ...   \\n1959-08-01  1.0  1.0  2436781.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-09-01  1.0  0.0  2436812.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-10-01  1.0  0.0  2436842.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-11-01  1.0  1.0  2436873.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-12-01  1.0  0.0  2436903.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\nmonth                                                                       \\n1949-01-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1949-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1949-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1949-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1949-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \\n1959-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1959-09-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-10-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-12-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\nmonth              \\n1949-01-01    0.0  \\n1949-02-01    0.0  \\n1949-03-01    0.0  \\n1949-04-01    0.0  \\n1949-05-01    1.0  \\n...           ...  \\n1959-08-01    0.0  \\n1959-09-01    0.0  \\n1959-10-01    0.0  \\n1959-11-01    1.0  \\n1959-12-01    0.0  \\n\\n[132 rows x 275 columns] and predict             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\n1960-01-01  1.0  0.0  2436934.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-02-01  1.0  0.0  2436965.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-03-01  1.0  0.0  2436994.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n1960-04-01  1.0  0.0  2437025.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n1960-05-01  1.0  1.0  2437055.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n1960-06-01  1.0  0.0  2437086.5  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   \\n1960-07-01  1.0  0.0  2437116.5  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \\n1960-08-01  1.0  0.0  2437147.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-09-01  1.0  0.0  2437178.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-10-01  1.0  1.0  2437208.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-11-01  1.0  0.0  2437239.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-12-01  1.0  0.0  2437269.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\n1960-01-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-06-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-07-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-09-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-10-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1960-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-12-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\n1960-01-01    0.0  \\n1960-02-01    0.0  \\n1960-03-01    0.0  \\n1960-04-01    0.0  \\n1960-05-01    1.0  \\n1960-06-01    0.0  \\n1960-07-01    0.0  \\n1960-08-01    0.0  \\n1960-09-01    0.0  \\n1960-10-01    0.0  \\n1960-11-01    0.0  \\n1960-12-01    0.0  \\n\\n[12 rows x 275 columns]\") in model 1064 in generation 8: ARDL\n",
            "Model Number: 1065 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1066 with model MultivariateRegression in generation 8 of 10\n",
            "Model Number: 1067 with model GLM in generation 8 of 10\n",
            "Model Number: 1068 with model MetricMotif in generation 8 of 10\n",
            "Model Number: 1069 with model UnivariateMotif in generation 8 of 10\n",
            "Model Number: 1070 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1071 with model Theta in generation 8 of 10\n",
            "Model Number: 1072 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1073 with model DatepartRegression in generation 8 of 10\n",
            "Model Number: 1074 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1075 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1076 with model ARDL in generation 8 of 10\n",
            "Model Number: 1077 with model NVAR in generation 8 of 10\n",
            "Model Number: 1078 with model ARDL in generation 8 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series #Passengers failed with error ValueError('The number of regressors (234) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larer than the sample available for estimation (129).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nmonth                                                                         \\n1949-01-01        1        1  2432917.5      1.0      0.0      0.0      0.0   \\n1949-02-01        0        1  2432948.5      0.0      1.0      0.0      0.0   \\n1949-03-01        0        1  2432976.5      0.0      0.0      1.0      0.0   \\n1949-04-01        0        2  2433007.5      0.0      0.0      0.0      1.0   \\n1949-05-01        1        2  2433037.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n1959-08-01        1        3  2436781.5      0.0      0.0      0.0      0.0   \\n1959-09-01        0        3  2436812.5      0.0      0.0      0.0      0.0   \\n1959-10-01        0        4  2436842.5      0.0      0.0      0.0      0.0   \\n1959-11-01        1        4  2436873.5      0.0      0.0      0.0      0.0   \\n1959-12-01        0        4  2436903.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\nmonth                                  ...                                   \\n1949-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1949-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n...             ...      ...      ...  ...     ...     ...     ...     ...   \\n1959-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1959-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\nmonth                                                                      \\n1949-01-01     0.0               1.0               0.0               0.0   \\n1949-02-01     0.0               1.0               0.0               0.0   \\n1949-03-01     0.0               1.0               0.0               0.0   \\n1949-04-01     0.0               1.0               0.0               0.0   \\n1949-05-01     0.0               1.0               0.0               0.0   \\n...            ...               ...               ...               ...   \\n1959-08-01     0.0               1.0               0.0               0.0   \\n1959-09-01     0.0               1.0               0.0               0.0   \\n1959-10-01     0.0               1.0               0.0               0.0   \\n1959-11-01     0.0               1.0               0.0               0.0   \\n1959-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\nmonth                                           \\n1949-01-01               0.0               0.0  \\n1949-02-01               0.0               0.0  \\n1949-03-01               0.0               0.0  \\n1949-04-01               0.0               0.0  \\n1949-05-01               0.0               0.0  \\n...                      ...               ...  \\n1959-08-01               0.0               0.0  \\n1959-09-01               0.0               0.0  \\n1959-10-01               0.0               0.0  \\n1959-11-01               0.0               0.0  \\n1959-12-01               0.0               0.0  \\n\\n[132 rows x 58 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n1960-01-01        0        1  2436934.5      1.0      0.0      0.0      0.0   \\n1960-02-01        0        1  2436965.5      0.0      1.0      0.0      0.0   \\n1960-03-01        0        1  2436994.5      0.0      0.0      1.0      0.0   \\n1960-04-01        0        2  2437025.5      0.0      0.0      0.0      1.0   \\n1960-05-01        1        2  2437055.5      0.0      0.0      0.0      0.0   \\n1960-06-01        0        2  2437086.5      0.0      0.0      0.0      0.0   \\n1960-07-01        0        3  2437116.5      0.0      0.0      0.0      0.0   \\n1960-08-01        0        3  2437147.5      0.0      0.0      0.0      0.0   \\n1960-09-01        0        3  2437178.5      0.0      0.0      0.0      0.0   \\n1960-10-01        1        4  2437208.5      0.0      0.0      0.0      0.0   \\n1960-11-01        0        4  2437239.5      0.0      0.0      0.0      0.0   \\n1960-12-01        0        4  2437269.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  day_27  day_28  day_29  day_30  \\\\\\n1960-01-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-02-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-03-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-04-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-05-01      1.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-06-01      0.0      1.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-07-01      0.0      0.0      1.0  ...     0.0     0.0     0.0     0.0   \\n1960-08-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-09-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-10-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-11-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n1960-12-01      0.0      0.0      0.0  ...     0.0     0.0     0.0     0.0   \\n\\n            day_31  weekdayofmonth_1  weekdayofmonth_2  weekdayofmonth_3  \\\\\\n1960-01-01     0.0               1.0               0.0               0.0   \\n1960-02-01     0.0               1.0               0.0               0.0   \\n1960-03-01     0.0               1.0               0.0               0.0   \\n1960-04-01     0.0               1.0               0.0               0.0   \\n1960-05-01     0.0               1.0               0.0               0.0   \\n1960-06-01     0.0               1.0               0.0               0.0   \\n1960-07-01     0.0               1.0               0.0               0.0   \\n1960-08-01     0.0               1.0               0.0               0.0   \\n1960-09-01     0.0               1.0               0.0               0.0   \\n1960-10-01     0.0               1.0               0.0               0.0   \\n1960-11-01     0.0               1.0               0.0               0.0   \\n1960-12-01     0.0               1.0               0.0               0.0   \\n\\n            weekdayofmonth_4  weekdayofmonth_5  \\n1960-01-01               0.0               0.0  \\n1960-02-01               0.0               0.0  \\n1960-03-01               0.0               0.0  \\n1960-04-01               0.0               0.0  \\n1960-05-01               0.0               0.0  \\n1960-06-01               0.0               0.0  \\n1960-07-01               0.0               0.0  \\n1960-08-01               0.0               0.0  \\n1960-09-01               0.0               0.0  \\n1960-10-01               0.0               0.0  \\n1960-11-01               0.0               0.0  \\n1960-12-01               0.0               0.0  \\n\\n[12 rows x 58 columns]\") in model 1078 in generation 8: ARDL\n",
            "Model Number: 1079 with model GLS in generation 8 of 10\n",
            "Model Number: 1080 with model ConstantNaive in generation 8 of 10\n",
            "Model Number: 1081 with model ARDL in generation 8 of 10\n",
            "Template Eval Error: Exception('Transformer DifferencedTransformer failed on inverse') in model 1081 in generation 8: ARDL\n",
            "Model Number: 1082 with model UnobservedComponents in generation 8 of 10\n",
            "Model Number: 1083 with model MultivariateMotif in generation 8 of 10\n",
            "Model Number: 1084 with model SectionalMotif in generation 8 of 10\n",
            "Model Number: 1085 with model ARDL in generation 8 of 10\n",
            "Model Number: 1086 with model Theta in generation 8 of 10\n",
            "New Generation: 9 of 10\n",
            "Model Number: 1087 with model GLM in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/3svps2ct.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/o9epgpd2.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=46735', 'data', 'file=/tmp/tmp2xi3y8fj/3svps2ct.json', 'init=/tmp/tmp2xi3y8fj/o9epgpd2.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelins4guy5/prophet_model-20230410131505.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:15:05 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1088 with model FBProphet in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:15:05 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1089 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1090 with model Theta in generation 9 of 10\n",
            "Model Number: 1091 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1092 with model DatepartRegression in generation 9 of 10\n",
            "Model Number: 1093 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1094 with model ETS in generation 9 of 10\n",
            "Model Number: 1095 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1096 with model ETS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1096 in generation 9: ETS\n",
            "Model Number: 1097 with model UnivariateMotif in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1097 in generation 9: UnivariateMotif\n",
            "Model Number: 1098 with model ARIMA in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer LocalLinearTrend failed on fit') in model 1098 in generation 9: ARIMA\n",
            "Model Number: 1099 with model MultivariateRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 1099 in generation 9: MultivariateRegression\n",
            "Model Number: 1100 with model Theta in generation 9 of 10\n",
            "Model Number: 1101 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1102 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1103 with model LastValueNaive in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1103 in generation 9: LastValueNaive\n",
            "Model Number: 1104 with model DatepartRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.24806e-25): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1105 with model WindowRegression in generation 9 of 10\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 11s 129ms/step - loss: 7582408.0000 - val_loss: 390978.8750\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6731328.0000 - val_loss: 300486.9688\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6520430.5000 - val_loss: 244231.0781\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6251781.5000 - val_loss: 240165.2969\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 6144611.5000 - val_loss: 203859.3906\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 6100160.5000 - val_loss: 168507.4219\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5973288.0000 - val_loss: 137429.7500\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5717478.0000 - val_loss: 125407.8438\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5811086.0000 - val_loss: 115967.9062\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 6057883.5000 - val_loss: 112415.7891\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5606072.0000 - val_loss: 87202.2500\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 5757264.0000 - val_loss: 83032.2578\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5687616.0000 - val_loss: 86178.1328\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 5547582.5000 - val_loss: 96516.1797\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 5448398.0000 - val_loss: 83044.4688\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 5477943.5000 - val_loss: 91687.6641\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 5519038.5000 - val_loss: 79313.8125\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5507376.5000 - val_loss: 76838.0938\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5430083.5000 - val_loss: 67880.0391\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5792853.5000 - val_loss: 63164.4805\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 5544896.5000 - val_loss: 74588.1641\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 5506486.5000 - val_loss: 60746.7461\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5466383.5000 - val_loss: 60524.4883\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5425843.5000 - val_loss: 64677.4375\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5388151.5000 - val_loss: 72836.6953\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5285430.5000 - val_loss: 74472.1484\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5586115.0000 - val_loss: 86728.0312\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5561233.5000 - val_loss: 65285.9492\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 5565932.0000 - val_loss: 73264.0234\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5464870.5000 - val_loss: 72516.0703\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 5548070.5000 - val_loss: 73473.2422\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 5379613.5000 - val_loss: 66713.2891\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5438726.5000 - val_loss: 72845.2578\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5985991040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 419ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Model Number: 1106 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1107 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1108 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1109 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1110 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1111 with model GLS in generation 9 of 10\n",
            "Model Number: 1112 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1112 in generation 9: DatepartRegression\n",
            "Model Number: 1113 with model MultivariateRegression in generation 9 of 10\n",
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000022 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Model Number: 1114 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1115 with model GLM in generation 9 of 10\n",
            "Model Number: 1116 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1117 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1118 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1119 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1120 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1121 with model ETS in generation 9 of 10\n",
            "Model Number: 1122 with model ARIMA in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/tools/probabilistic.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
            "  (prior_mu / prior_sigma**2) + ((n * data_mu) / prior_sigma**2)\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/probabilistic.py:68: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  ) / ((1 / prior_sigma**2) + (n / prior_sigma**2))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1123 with model NVAR in generation 9 of 10\n",
            "Model Number: 1124 with model GLM in generation 9 of 10\n",
            "Model Number: 1125 with model SeasonalNaive in generation 9 of 10\n",
            "Model Number: 1126 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1126 in generation 9: DatepartRegression\n",
            "Model Number: 1127 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1128 with model ARDL in generation 9 of 10\n",
            "Model Number: 1129 with model ARDL in generation 9 of 10\n",
            "Model Number: 1130 with model UnobservedComponents in generation 9 of 10\n",
            "Template Eval Error: LinAlgError('Singular matrix') in model 1130 in generation 9: UnobservedComponents\n",
            "Model Number: 1131 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1132 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1133 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1134 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1135 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1136 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1137 with model GLS in generation 9 of 10\n",
            "Model Number: 1138 with model UnobservedComponents in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1139 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1140 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1141 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1142 with model Theta in generation 9 of 10\n",
            "Model Number: 1143 with model Theta in generation 9 of 10\n",
            "Model Number: 1144 with model WindowRegression in generation 9 of 10\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Model Number: 1145 with model AverageValueNaive in generation 9 of 10\n",
            "HolidayTransformer: no anomalies detected.\n",
            "Model Number: 1146 with model UnobservedComponents in generation 9 of 10\n",
            "Model Number: 1147 with model GLM in generation 9 of 10\n",
            "Model Number: 1148 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1149 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1150 with model MultivariateRegression in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=8.24806e-25): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1151 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1152 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1152 in generation 9: DatepartRegression\n",
            "Model Number: 1153 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1154 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1155 with model DatepartRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1155 in generation 9: DatepartRegression\n",
            "Model Number: 1156 with model ARDL in generation 9 of 10\n",
            "Model Number: 1157 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1158 with model ARIMA in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1158 in generation 9: ARIMA\n",
            "Model Number: 1159 with model ARDL in generation 9 of 10\n",
            "Model Number: 1160 with model GLM in generation 9 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1160 in generation 9: GLM\n",
            "Model Number: 1161 with model UnobservedComponents in generation 9 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1162 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1163 with model ETS in generation 9 of 10\n",
            "Model Number: 1164 with model ARDL in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1164 in generation 9: ARDL\n",
            "Model Number: 1165 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1166 with model WindowRegression in generation 9 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1166 in generation 9: WindowRegression\n",
            "Model Number: 1167 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1168 with model SectionalMotif in generation 9 of 10\n",
            "Model Number: 1169 with model MultivariateMotif in generation 9 of 10\n",
            "Model Number: 1170 with model Theta in generation 9 of 10\n",
            "Model Number: 1171 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1172 with model UnivariateMotif in generation 9 of 10\n",
            "Model Number: 1173 with model Theta in generation 9 of 10\n",
            "Model Number: 1174 with model GLM in generation 9 of 10\n",
            "Model Number: 1175 with model WindowRegression in generation 9 of 10\n",
            "Model Number: 1176 with model Theta in generation 9 of 10\n",
            "Model Number: 1177 with model ARDL in generation 9 of 10\n",
            "Model Number: 1178 with model ConstantNaive in generation 9 of 10\n",
            "Model Number: 1179 with model ARIMA in generation 9 of 10\n",
            "Model Number: 1180 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1181 with model MetricMotif in generation 9 of 10\n",
            "Model Number: 1182 with model GLS in generation 9 of 10\n",
            "Model Number: 1183 with model ETS in generation 9 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1183 in generation 9: ETS\n",
            "Model Number: 1184 with model LastValueNaive in generation 9 of 10\n",
            "Model Number: 1185 with model MultivariateRegression in generation 9 of 10\n",
            "Model Number: 1186 with model DatepartRegression in generation 9 of 10\n",
            "New Generation: 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1187 with model DatepartRegression in generation 10 of 10\n",
            "Model Number: 1188 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1189 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1190 with model Theta in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Cointegration failed on fit') in model 1190 in generation 10: Theta\n",
            "Model Number: 1191 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1192 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1193 with model ARDL in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1193 in generation 10: ARDL\n",
            "Model Number: 1194 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1195 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1196 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1197 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1198 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 1198 in generation 10: DatepartRegression\n",
            "Model Number: 1199 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1200 with model GLM in generation 10 of 10\n",
            "Model Number: 1201 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1202 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: InvalidParameterError(\"The 'base_estimator' parameter of AdaBoostRegressor must be an object implementing 'fit' and 'predict' or a str among {'deprecated'}. Got None instead.\") in model 1202 in generation 10: DatepartRegression\n",
            "Model Number: 1203 with model Theta in generation 10 of 10\n",
            "Model Number: 1204 with model ARDL in generation 10 of 10\n",
            "Model Number: 1205 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1206 with model ConstantNaive in generation 10 of 10\n",
            "Model Number: 1207 with model ARDL in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 1207 in generation 10: ARDL\n",
            "Model Number: 1208 with model ARDL in generation 10 of 10\n",
            "Model Number: 1209 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1210 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1211 with model ARDL in generation 10 of 10\n",
            "Model Number: 1212 with model GLM in generation 10 of 10\n",
            "Model Number: 1213 with model GLM in generation 10 of 10\n",
            "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 1213 in generation 10: GLM\n",
            "Model Number: 1214 with model SectionalMotif in generation 10 of 10\n",
            "Model Number: 1215 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1215 in generation 10: DatepartRegression\n",
            "Model Number: 1216 with model GLM in generation 10 of 10\n",
            "Model Number: 1217 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1218 with model MetricMotif in generation 10 of 10\n",
            "Model Number: 1219 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1220 with model LastValueNaive in generation 10 of 10\n",
            "Model Number: 1221 with model MultivariateMotif in generation 10 of 10\n",
            "Template Eval Error: Exception('Transformer BTCD failed on fit') in model 1221 in generation 10: MultivariateMotif\n",
            "Model Number: 1222 with model ETS in generation 10 of 10\n",
            "Model Number: 1223 with model WindowRegression in generation 10 of 10\n",
            "Model Number: 1224 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1225 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1225 in generation 10: WindowRegression\n",
            "Model Number: 1226 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: InvalidParameterError(\"The 'base_estimator' parameter of AdaBoostRegressor must be an object implementing 'fit' and 'predict' or a str among {'deprecated'}. Got None instead.\") in model 1226 in generation 10: DatepartRegression\n",
            "Model Number: 1227 with model GLM in generation 10 of 10\n",
            "Model Number: 1228 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1229 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1230 with model DatepartRegression in generation 10 of 10\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 5s 6ms/step - loss: 247.0228\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 203.7881\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 170.7430\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 141.9685\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 120.1264\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 105.9735\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 97.7122\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 93.0272\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 89.5171\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.6825\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 88.5531\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.4662\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 88.4258\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 88.7609\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.5148\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.5688\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.9107\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.6352\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.3534\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.5554\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.7698\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 88.3111\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.5025\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.6651\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.9323\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 88.8368\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.6867\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.7844\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.7525\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4353\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.8441\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.7419\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.8487\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4080\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.7539\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.8409\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4583\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.8579\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.7571\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.6484\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4510\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4328\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 88.4744\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.4030\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.5227\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.8748\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.8229\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.6283\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 88.6517\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 88.4703\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "Model Number: 1231 with model MultivariateRegression in generation 10 of 10\n",
            "Model Number: 1232 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1233 with model WindowRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError('Input X contains NaN.\\nRadiusNeighborsRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values') in model 1233 in generation 10: WindowRegression\n",
            "Model Number: 1234 with model Theta in generation 10 of 10\n",
            "Model Number: 1235 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1236 with model ARIMA in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_regression.py:494: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
            "  warnings.warn(empty_warning_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1237 with model MetricMotif in generation 10 of 10\n",
            "Model Number: 1238 with model DatepartRegression in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 1238 in generation 10: DatepartRegression\n",
            "Model Number: 1239 with model GLM in generation 10 of 10\n",
            "Model Number: 1240 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1241 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1242 with model Theta in generation 10 of 10\n",
            "Model Number: 1243 with model ARDL in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series #Passengers failed with error ValueError('The number of regressors (828) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larer than the sample available for estimation (130).') exog train             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\nmonth                                                               ...   \\n1949-01-01  1.0  1.0  2432917.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1949-02-01  1.0  0.0  2432948.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1949-03-01  1.0  0.0  2432976.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n1949-04-01  1.0  0.0  2433007.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n1949-05-01  1.0  1.0  2433037.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n...         ...  ...        ...  ...  ...  ...  ...  ...  ...  ...  ...   \\n1959-08-01  1.0  1.0  2436781.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-09-01  1.0  0.0  2436812.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-10-01  1.0  0.0  2436842.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-11-01  1.0  1.0  2436873.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1959-12-01  1.0  0.0  2436903.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\nmonth                                                                       \\n1949-01-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1949-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1949-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1949-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1949-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \\n1959-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1959-09-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-10-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1959-12-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\nmonth              \\n1949-01-01    0.0  \\n1949-02-01    0.0  \\n1949-03-01    0.0  \\n1949-04-01    0.0  \\n1949-05-01    1.0  \\n...           ...  \\n1959-08-01    0.0  \\n1959-09-01    0.0  \\n1959-10-01    0.0  \\n1959-11-01    1.0  \\n1959-12-01    0.0  \\n\\n[132 rows x 275 columns] and predict             dp0  dp1        dp2  dp3  dp4  dp5  dp6  dp7  dp8  dp9  ...  \\\\\\n1960-01-01  1.0  0.0  2436934.5  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-02-01  1.0  0.0  2436965.5  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-03-01  1.0  0.0  2436994.5  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   \\n1960-04-01  1.0  0.0  2437025.5  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...   \\n1960-05-01  1.0  1.0  2437055.5  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ...   \\n1960-06-01  1.0  0.0  2437086.5  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...   \\n1960-07-01  1.0  0.0  2437116.5  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...   \\n1960-08-01  1.0  0.0  2437147.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-09-01  1.0  0.0  2437178.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-10-01  1.0  1.0  2437208.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-11-01  1.0  0.0  2437239.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n1960-12-01  1.0  0.0  2437269.5  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \\n\\n            dp265  dp266  dp267  dp268  dp269  dp270  dp271  dp272  dp273  \\\\\\n1960-01-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-02-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-03-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-04-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-05-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-06-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-07-01    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0   \\n1960-08-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-09-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-10-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    1.0    0.0   \\n1960-11-01    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n1960-12-01    1.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \\n\\n            dp274  \\n1960-01-01    0.0  \\n1960-02-01    0.0  \\n1960-03-01    0.0  \\n1960-04-01    0.0  \\n1960-05-01    1.0  \\n1960-06-01    0.0  \\n1960-07-01    0.0  \\n1960-08-01    0.0  \\n1960-09-01    0.0  \\n1960-10-01    0.0  \\n1960-11-01    0.0  \\n1960-12-01    0.0  \\n\\n[12 rows x 275 columns]\") in model 1243 in generation 10: ARDL\n",
            "Model Number: 1244 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1245 with model ARIMA in generation 10 of 10\n",
            "Model Number: 1246 with model Theta in generation 10 of 10\n",
            "Model Number: 1247 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1248 with model ARDL in generation 10 of 10\n",
            "Model Number: 1249 with model Theta in generation 10 of 10\n",
            "Model Number: 1250 with model MetricMotif in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1251 with model MetricMotif in generation 10 of 10\n",
            "Model Number: 1252 with model Theta in generation 10 of 10\n",
            "Model Number: 1253 with model LastValueNaive in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1254 with model ARDL in generation 10 of 10\n",
            "Model Number: 1255 with model GLM in generation 10 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1255 in generation 10: GLM\n",
            "Model Number: 1256 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1257 with model MultivariateMotif in generation 10 of 10\n",
            "Model Number: 1258 with model UnivariateMotif in generation 10 of 10\n",
            "Model Number: 1259 with model Theta in generation 10 of 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1260 with model ARDL in generation 10 of 10\n",
            "Template Eval Error: ValueError(\"ARDL series #Passengers failed with error ValueError('The number of regressors (67) including deterministics, lags of the endog, lags of the exogenous, and fixed regressors is larer than the sample available for estimation (64).') exog train             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\nmonth                                                                         \\n1954-07-01        0        3  2434924.5      0.0      0.0      0.0      0.0   \\n1954-08-01        1        3  2434955.5      0.0      0.0      0.0      0.0   \\n1954-09-01        0        3  2434986.5      0.0      0.0      0.0      0.0   \\n1954-10-01        0        4  2435016.5      0.0      0.0      0.0      0.0   \\n1954-11-01        0        4  2435047.5      0.0      0.0      0.0      0.0   \\n...             ...      ...        ...      ...      ...      ...      ...   \\n1959-08-01        1        3  2436781.5      0.0      0.0      0.0      0.0   \\n1959-09-01        0        3  2436812.5      0.0      0.0      0.0      0.0   \\n1959-10-01        0        4  2436842.5      0.0      0.0      0.0      0.0   \\n1959-11-01        1        4  2436873.5      0.0      0.0      0.0      0.0   \\n1959-12-01        0        4  2436903.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\nmonth                                  ...                                 \\n1954-07-01      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n1954-08-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1954-09-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1954-10-01      0.0      0.0      0.0  ...       1.0       0.0       0.0   \\n1954-11-01      0.0      0.0      0.0  ...       0.0       1.0       0.0   \\n...             ...      ...      ...  ...       ...       ...       ...   \\n1959-08-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1959-09-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1959-10-01      0.0      0.0      0.0  ...       1.0       0.0       0.0   \\n1959-11-01      0.0      0.0      0.0  ...       0.0       1.0       0.0   \\n1959-12-01      0.0      0.0      0.0  ...       0.0       0.0       1.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\nmonth                                                                          \\n1954-07-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n1954-08-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n1954-09-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n1954-10-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n1954-11-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n...               ...        ...        ...        ...        ...        ...   \\n1959-08-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n1959-09-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n1959-10-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n1959-11-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n1959-12-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n\\n            weekday_6  \\nmonth                  \\n1954-07-01        0.0  \\n1954-08-01        1.0  \\n1954-09-01        0.0  \\n1954-10-01        0.0  \\n1954-11-01        0.0  \\n...               ...  \\n1959-08-01        0.0  \\n1959-09-01        0.0  \\n1959-10-01        0.0  \\n1959-11-01        1.0  \\n1959-12-01        0.0  \\n\\n[66 rows x 22 columns] and predict             weekend  quarter      epoch  month_1  month_2  month_3  month_4  \\\\\\n1960-01-01        0        1  2436934.5      1.0      0.0      0.0      0.0   \\n1960-02-01        0        1  2436965.5      0.0      1.0      0.0      0.0   \\n1960-03-01        0        1  2436994.5      0.0      0.0      1.0      0.0   \\n1960-04-01        0        2  2437025.5      0.0      0.0      0.0      1.0   \\n1960-05-01        1        2  2437055.5      0.0      0.0      0.0      0.0   \\n1960-06-01        0        2  2437086.5      0.0      0.0      0.0      0.0   \\n1960-07-01        0        3  2437116.5      0.0      0.0      0.0      0.0   \\n1960-08-01        0        3  2437147.5      0.0      0.0      0.0      0.0   \\n1960-09-01        0        3  2437178.5      0.0      0.0      0.0      0.0   \\n1960-10-01        1        4  2437208.5      0.0      0.0      0.0      0.0   \\n1960-11-01        0        4  2437239.5      0.0      0.0      0.0      0.0   \\n1960-12-01        0        4  2437269.5      0.0      0.0      0.0      0.0   \\n\\n            month_5  month_6  month_7  ...  month_10  month_11  month_12  \\\\\\n1960-01-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-02-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-03-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-04-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-05-01      1.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-06-01      0.0      1.0      0.0  ...       0.0       0.0       0.0   \\n1960-07-01      0.0      0.0      1.0  ...       0.0       0.0       0.0   \\n1960-08-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-09-01      0.0      0.0      0.0  ...       0.0       0.0       0.0   \\n1960-10-01      0.0      0.0      0.0  ...       1.0       0.0       0.0   \\n1960-11-01      0.0      0.0      0.0  ...       0.0       1.0       0.0   \\n1960-12-01      0.0      0.0      0.0  ...       0.0       0.0       1.0   \\n\\n            weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  weekday_5  \\\\\\n1960-01-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n1960-02-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n1960-03-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n1960-04-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n1960-05-01        0.0        0.0        0.0        0.0        0.0        0.0   \\n1960-06-01        0.0        0.0        1.0        0.0        0.0        0.0   \\n1960-07-01        0.0        0.0        0.0        0.0        1.0        0.0   \\n1960-08-01        1.0        0.0        0.0        0.0        0.0        0.0   \\n1960-09-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n1960-10-01        0.0        0.0        0.0        0.0        0.0        1.0   \\n1960-11-01        0.0        1.0        0.0        0.0        0.0        0.0   \\n1960-12-01        0.0        0.0        0.0        1.0        0.0        0.0   \\n\\n            weekday_6  \\n1960-01-01        0.0  \\n1960-02-01        0.0  \\n1960-03-01        0.0  \\n1960-04-01        0.0  \\n1960-05-01        1.0  \\n1960-06-01        0.0  \\n1960-07-01        0.0  \\n1960-08-01        0.0  \\n1960-09-01        0.0  \\n1960-10-01        0.0  \\n1960-11-01        0.0  \\n1960-12-01        0.0  \\n\\n[12 rows x 22 columns]\") in model 1260 in generation 10: ARDL\n",
            "Model Number: 1261 with model GLM in generation 10 of 10\n",
            "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 1261 in generation 10: GLM\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/links.py:516: RuntimeWarning: overflow encountered in exp\n",
            "  return np.exp(z)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:426: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  endog_mu = self._clean(endog / mu)\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: invalid value encountered in multiply\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/families/family.py:132: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n",
            "/usr/local/lib/python3.9/dist-packages/statsmodels/genmod/generalized_linear_model.py:1211: RuntimeWarning: invalid value encountered in multiply\n",
            "  wlsendog = (lin_pred + self.family.link.deriv(mu) * (self.endog-mu)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 1262 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1263 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1264 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1265 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1266 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1267 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1268 with model Ensemble in generation 11 of Ensembles\n",
            "Model Number: 1269 with model Ensemble in generation 11 of Ensembles\n",
            "Validation Round: 1\n",
            "Model Number: 1 of 188 with model ARIMA for Validation 1\n",
            "📈 1 - ARIMA with avg smape 8.22: \n",
            "Model Number: 2 of 188 with model Ensemble for Validation 1\n",
            "2 - Ensemble with avg smape 9.14: \n",
            "Model Number: 3 of 188 with model Ensemble for Validation 1\n",
            "3 - Ensemble with avg smape 9.34: \n",
            "Model Number: 4 of 188 with model ARIMA for Validation 1\n",
            "4 - ARIMA with avg smape 9.41: \n",
            "Model Number: 5 of 188 with model Ensemble for Validation 1\n",
            "5 - Ensemble with avg smape 10.4: \n",
            "Model Number: 6 of 188 with model ARIMA for Validation 1\n",
            "6 - ARIMA with avg smape 10.4: \n",
            "Model Number: 7 of 188 with model ARIMA for Validation 1\n",
            "7 - ARIMA with avg smape 10.4: \n",
            "Model Number: 8 of 188 with model ARIMA for Validation 1\n",
            "8 - ARIMA with avg smape 10.41: \n",
            "Model Number: 9 of 188 with model ARIMA for Validation 1\n",
            "9 - ARIMA with avg smape 10.45: \n",
            "Model Number: 10 of 188 with model ARIMA for Validation 1\n",
            "10 - ARIMA with avg smape 10.45: \n",
            "Model Number: 11 of 188 with model ARIMA for Validation 1\n",
            "11 - ARIMA with avg smape 10.45: \n",
            "Model Number: 12 of 188 with model ARIMA for Validation 1\n",
            "12 - ARIMA with avg smape 11.33: \n",
            "Model Number: 13 of 188 with model Ensemble for Validation 1\n",
            "13 - Ensemble with avg smape 9.82: \n",
            "Model Number: 14 of 188 with model Ensemble for Validation 1\n",
            "📈 14 - Ensemble with avg smape 4.86: \n",
            "Model Number: 15 of 188 with model Ensemble for Validation 1\n",
            "15 - Ensemble with avg smape 4.9: \n",
            "Model Number: 16 of 188 with model Ensemble for Validation 1\n",
            "16 - Ensemble with avg smape 4.9: \n",
            "Model Number: 17 of 188 with model Ensemble for Validation 1\n",
            "17 - Ensemble with avg smape 6.42: \n",
            "Model Number: 18 of 188 with model MultivariateMotif for Validation 1\n",
            "18 - MultivariateMotif with avg smape 10.04: \n",
            "Model Number: 19 of 188 with model MultivariateMotif for Validation 1\n",
            "19 - MultivariateMotif with avg smape 10.04: \n",
            "Model Number: 20 of 188 with model MultivariateMotif for Validation 1\n",
            "20 - MultivariateMotif with avg smape 10.08: \n",
            "Model Number: 21 of 188 with model MultivariateMotif for Validation 1\n",
            "21 - MultivariateMotif with avg smape 10.08: \n",
            "Model Number: 22 of 188 with model MultivariateMotif for Validation 1\n",
            "22 - MultivariateMotif with avg smape 10.08: \n",
            "Model Number: 23 of 188 with model MultivariateMotif for Validation 1\n",
            "23 - MultivariateMotif with avg smape 10.08: \n",
            "Model Number: 24 of 188 with model ARDL for Validation 1\n",
            "📈 24 - ARDL with avg smape 4.01: \n",
            "Model Number: 25 of 188 with model ARDL for Validation 1\n",
            "📈 25 - ARDL with avg smape 2.92: \n",
            "Model Number: 26 of 188 with model ARDL for Validation 1\n",
            "26 - ARDL with avg smape 4.38: \n",
            "Model Number: 27 of 188 with model ARDL for Validation 1\n",
            "27 - ARDL with avg smape 4.5: \n",
            "Model Number: 28 of 188 with model ARDL for Validation 1\n",
            "28 - ARDL with avg smape 4.5: \n",
            "Model Number: 29 of 188 with model ARDL for Validation 1\n",
            "29 - ARDL with avg smape 4.5: \n",
            "Model Number: 30 of 188 with model ARDL for Validation 1\n",
            "30 - ARDL with avg smape 4.5: \n",
            "Model Number: 31 of 188 with model DatepartRegression for Validation 1\n",
            "31 - DatepartRegression with avg smape 4.55: \n",
            "Model Number: 32 of 188 with model ARDL for Validation 1\n",
            "32 - ARDL with avg smape 4.5: \n",
            "Model Number: 33 of 188 with model Theta for Validation 1\n",
            "33 - Theta with avg smape 10.46: \n",
            "Model Number: 34 of 188 with model Theta for Validation 1\n",
            "34 - Theta with avg smape 10.46: \n",
            "Model Number: 35 of 188 with model ARDL for Validation 1\n",
            "35 - ARDL with avg smape 5.48: \n",
            "Model Number: 36 of 188 with model UnivariateMotif for Validation 1\n",
            "36 - UnivariateMotif with avg smape 9.66: \n",
            "Model Number: 37 of 188 with model Theta for Validation 1\n",
            "37 - Theta with avg smape 10.68: \n",
            "Model Number: 38 of 188 with model Theta for Validation 1\n",
            "38 - Theta with avg smape 10.68: \n",
            "Model Number: 39 of 188 with model Theta for Validation 1\n",
            "39 - Theta with avg smape 10.68: \n",
            "Model Number: 40 of 188 with model Theta for Validation 1\n",
            "40 - Theta with avg smape 10.68: \n",
            "Model Number: 41 of 188 with model Theta for Validation 1\n",
            "41 - Theta with avg smape 10.7: \n",
            "Model Number: 42 of 188 with model DatepartRegression for Validation 1\n",
            "42 - DatepartRegression with avg smape 4.2: \n",
            "Model Number: 43 of 188 with model MultivariateMotif for Validation 1\n",
            "43 - MultivariateMotif with avg smape 11.02: \n",
            "Model Number: 44 of 188 with model UnivariateMotif for Validation 1\n",
            "44 - UnivariateMotif with avg smape 5.37: \n",
            "Model Number: 45 of 188 with model UnivariateMotif for Validation 1\n",
            "45 - UnivariateMotif with avg smape 5.37: \n",
            "Model Number: 46 of 188 with model UnivariateMotif for Validation 1\n",
            "46 - UnivariateMotif with avg smape 5.61: \n",
            "Model Number: 47 of 188 with model UnivariateMotif for Validation 1\n",
            "47 - UnivariateMotif with avg smape 5.61: \n",
            "Model Number: 48 of 188 with model Theta for Validation 1\n",
            "48 - Theta with avg smape 9.26: \n",
            "Model Number: 49 of 188 with model Theta for Validation 1\n",
            "49 - Theta with avg smape 9.26: \n",
            "Model Number: 50 of 188 with model DatepartRegression for Validation 1\n",
            "50 - DatepartRegression with avg smape 9.06: \n",
            "Model Number: 51 of 188 with model UnivariateMotif for Validation 1\n",
            "51 - UnivariateMotif with avg smape 3.7: \n",
            "Model Number: 52 of 188 with model UnivariateMotif for Validation 1\n",
            "52 - UnivariateMotif with avg smape 9.77: \n",
            "Model Number: 53 of 188 with model UnivariateMotif for Validation 1\n",
            "53 - UnivariateMotif with avg smape 9.77: \n",
            "Model Number: 54 of 188 with model UnivariateMotif for Validation 1\n",
            "54 - UnivariateMotif with avg smape 4.08: \n",
            "Model Number: 55 of 188 with model MetricMotif for Validation 1\n",
            "55 - MetricMotif with avg smape 6.25: \n",
            "Model Number: 56 of 188 with model MetricMotif for Validation 1\n",
            "56 - MetricMotif with avg smape 7.82: \n",
            "Model Number: 57 of 188 with model MultivariateMotif for Validation 1\n",
            "57 - MultivariateMotif with avg smape 3.83: \n",
            "Model Number: 58 of 188 with model ConstantNaive for Validation 1\n",
            "58 - ConstantNaive with avg smape 11.49: \n",
            "Model Number: 59 of 188 with model DatepartRegression for Validation 1\n",
            "59 - DatepartRegression with avg smape 5.14: \n",
            "Model Number: 60 of 188 with model WindowRegression for Validation 1\n",
            "60 - WindowRegression with avg smape 3.96: \n",
            "Model Number: 61 of 188 with model MultivariateMotif for Validation 1\n",
            "61 - MultivariateMotif with avg smape 4.59: \n",
            "Model Number: 62 of 188 with model GLM for Validation 1\n",
            "62 - GLM with avg smape 8.02: \n",
            "Model Number: 63 of 188 with model GLM for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63 - GLM with avg smape 7.75: \n",
            "Model Number: 64 of 188 with model GLM for Validation 1\n",
            "64 - GLM with avg smape 7.74: \n",
            "Model Number: 65 of 188 with model GLM for Validation 1\n",
            "65 - GLM with avg smape 7.74: \n",
            "Model Number: 66 of 188 with model GLM for Validation 1\n",
            "66 - GLM with avg smape 7.74: \n",
            "Model Number: 67 of 188 with model GLM for Validation 1\n",
            "67 - GLM with avg smape 7.74: \n",
            "Model Number: 68 of 188 with model GLM for Validation 1\n",
            "68 - GLM with avg smape 3.64: \n",
            "Model Number: 69 of 188 with model GLM for Validation 1\n",
            "69 - GLM with avg smape 5.86: \n",
            "Model Number: 70 of 188 with model GLM for Validation 1\n",
            "70 - GLM with avg smape 3.67: \n",
            "Model Number: 71 of 188 with model MultivariateRegression for Validation 1\n",
            "71 - MultivariateRegression with avg smape 8.24: \n",
            "Model Number: 72 of 188 with model MetricMotif for Validation 1\n",
            "72 - MetricMotif with avg smape 8.38: \n",
            "Model Number: 73 of 188 with model MetricMotif for Validation 1\n",
            "73 - MetricMotif with avg smape 8.38: \n",
            "Model Number: 74 of 188 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 - WindowRegression with avg smape 9.88: \n",
            "Model Number: 75 of 188 with model SectionalMotif for Validation 1\n",
            "75 - SectionalMotif with avg smape 13.07: \n",
            "Model Number: 76 of 188 with model MultivariateRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76 - MultivariateRegression with avg smape 11.63: \n",
            "Model Number: 77 of 188 with model DatepartRegression for Validation 1\n",
            "77 - DatepartRegression with avg smape 4.57: \n",
            "Model Number: 78 of 188 with model MetricMotif for Validation 1\n",
            "78 - MetricMotif with avg smape 8.28: \n",
            "Model Number: 79 of 188 with model MetricMotif for Validation 1\n",
            "79 - MetricMotif with avg smape 8.28: \n",
            "Model Number: 80 of 188 with model WindowRegression for Validation 1\n",
            "80 - WindowRegression with avg smape 10.61: \n",
            "Model Number: 81 of 188 with model DatepartRegression for Validation 1\n",
            "81 - DatepartRegression with avg smape 4.92: \n",
            "Model Number: 82 of 188 with model DatepartRegression for Validation 1\n",
            "82 - DatepartRegression with avg smape 9.53: \n",
            "Model Number: 83 of 188 with model DatepartRegression for Validation 1\n",
            "83 - DatepartRegression with avg smape 9.52: \n",
            "Model Number: 84 of 188 with model MetricMotif for Validation 1\n",
            "84 - MetricMotif with avg smape 10.39: \n",
            "Model Number: 85 of 188 with model DatepartRegression for Validation 1\n",
            "85 - DatepartRegression with avg smape 8.86: \n",
            "Model Number: 86 of 188 with model GLS for Validation 1\n",
            "86 - GLS with avg smape 10.23: \n",
            "Model Number: 87 of 188 with model SectionalMotif for Validation 1\n",
            "87 - SectionalMotif with avg smape 5.91: \n",
            "Model Number: 88 of 188 with model ETS for Validation 1\n",
            "88 - ETS with avg smape 9.56: \n",
            "Model Number: 89 of 188 with model ETS for Validation 1\n",
            "89 - ETS with avg smape 9.56: \n",
            "Model Number: 90 of 188 with model LastValueNaive for Validation 1\n",
            "90 - LastValueNaive with avg smape 13.51: \n",
            "Model Number: 91 of 188 with model LastValueNaive for Validation 1\n",
            "91 - LastValueNaive with avg smape 13.51: \n",
            "Model Number: 92 of 188 with model LastValueNaive for Validation 1\n",
            "92 - LastValueNaive with avg smape 13.54: \n",
            "Model Number: 93 of 188 with model LastValueNaive for Validation 1\n",
            "93 - LastValueNaive with avg smape 13.54: \n",
            "Model Number: 94 of 188 with model MetricMotif for Validation 1\n",
            "94 - MetricMotif with avg smape 7.35: \n",
            "Model Number: 95 of 188 with model LastValueNaive for Validation 1\n",
            "95 - LastValueNaive with avg smape 13.69: \n",
            "Model Number: 96 of 188 with model WindowRegression for Validation 1\n",
            "96 - WindowRegression with avg smape 10.61: \n",
            "Model Number: 97 of 188 with model MetricMotif for Validation 1\n",
            "97 - MetricMotif with avg smape 7.74: \n",
            "Model Number: 98 of 188 with model AverageValueNaive for Validation 1\n",
            "98 - AverageValueNaive with avg smape 10.44: \n",
            "Model Number: 99 of 188 with model AverageValueNaive for Validation 1\n",
            "99 - AverageValueNaive with avg smape 10.08: \n",
            "Model Number: 100 of 188 with model AverageValueNaive for Validation 1\n",
            "100 - AverageValueNaive with avg smape 10.08: \n",
            "Model Number: 101 of 188 with model ETS for Validation 1\n",
            "101 - ETS with avg smape 11.18: \n",
            "Model Number: 102 of 188 with model MultivariateRegression for Validation 1\n",
            "102 - MultivariateRegression with avg smape 8.71: \n",
            "Model Number: 103 of 188 with model SectionalMotif for Validation 1\n",
            "103 - SectionalMotif with avg smape 10.7: \n",
            "Model Number: 104 of 188 with model ETS for Validation 1\n",
            "104 - ETS with avg smape 10.05: \n",
            "Model Number: 105 of 188 with model ETS for Validation 1\n",
            "105 - ETS with avg smape 10.05: \n",
            "Model Number: 106 of 188 with model ETS for Validation 1\n",
            "106 - ETS with avg smape 10.03: \n",
            "Model Number: 107 of 188 with model MultivariateRegression for Validation 1\n",
            "107 - MultivariateRegression with avg smape 10.71: \n",
            "Model Number: 108 of 188 with model ETS for Validation 1\n",
            "108 - ETS with avg smape 15.59: \n",
            "Model Number: 109 of 188 with model ETS for Validation 1\n",
            "109 - ETS with avg smape 15.59: \n",
            "Model Number: 110 of 188 with model MultivariateRegression for Validation 1\n",
            "110 - MultivariateRegression with avg smape 13.06: \n",
            "Model Number: 111 of 188 with model MultivariateRegression for Validation 1\n",
            "111 - MultivariateRegression with avg smape 11.41: \n",
            "Model Number: 112 of 188 with model LastValueNaive for Validation 1\n",
            "112 - LastValueNaive with avg smape 8.05: \n",
            "Model Number: 113 of 188 with model LastValueNaive for Validation 1\n",
            "113 - LastValueNaive with avg smape 18.52: \n",
            "Model Number: 114 of 188 with model MultivariateRegression for Validation 1\n",
            "114 - MultivariateRegression with avg smape 12.17: \n",
            "Model Number: 115 of 188 with model MultivariateRegression for Validation 1\n",
            "115 - MultivariateRegression with avg smape 12.0: \n",
            "Model Number: 116 of 188 with model UnobservedComponents for Validation 1\n",
            "116 - UnobservedComponents with avg smape 11.18: \n",
            "Model Number: 117 of 188 with model MultivariateRegression for Validation 1\n",
            "117 - MultivariateRegression with avg smape 10.86: \n",
            "Model Number: 118 of 188 with model LastValueNaive for Validation 1\n",
            "118 - LastValueNaive with avg smape 18.71: \n",
            "Model Number: 119 of 188 with model LastValueNaive for Validation 1\n",
            "119 - LastValueNaive with avg smape 18.71: \n",
            "Model Number: 120 of 188 with model WindowRegression for Validation 1\n",
            "120 - WindowRegression with avg smape 10.06: \n",
            "Model Number: 121 of 188 with model ETS for Validation 1\n",
            "121 - ETS with avg smape 11.17: \n",
            "Model Number: 122 of 188 with model WindowRegression for Validation 1\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000059 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "122 - WindowRegression with avg smape 16.05: \n",
            "Model Number: 123 of 188 with model ConstantNaive for Validation 1\n",
            "123 - ConstantNaive with avg smape 11.49: \n",
            "Model Number: 124 of 188 with model UnobservedComponents for Validation 1\n",
            "124 - UnobservedComponents with avg smape 11.08: \n",
            "Model Number: 125 of 188 with model UnobservedComponents for Validation 1\n",
            "125 - UnobservedComponents with avg smape 11.08: \n",
            "Model Number: 126 of 188 with model WindowRegression for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - WindowRegression with avg smape 10.38: \n",
            "Model Number: 127 of 188 with model UnobservedComponents for Validation 1\n",
            "127 - UnobservedComponents with avg smape 13.05: \n",
            "Model Number: 128 of 188 with model UnobservedComponents for Validation 1\n",
            "128 - UnobservedComponents with avg smape 13.05: \n",
            "Model Number: 129 of 188 with model SectionalMotif for Validation 1\n",
            "129 - SectionalMotif with avg smape 11.76: \n",
            "Model Number: 130 of 188 with model SectionalMotif for Validation 1\n",
            "130 - SectionalMotif with avg smape 11.76: \n",
            "Model Number: 131 of 188 with model ConstantNaive for Validation 1\n",
            "131 - ConstantNaive with avg smape 11.76: \n",
            "Model Number: 132 of 188 with model ConstantNaive for Validation 1\n",
            "132 - ConstantNaive with avg smape 11.76: \n",
            "Model Number: 133 of 188 with model UnobservedComponents for Validation 1\n",
            "133 - UnobservedComponents with avg smape 11.39: \n",
            "Model Number: 134 of 188 with model ConstantNaive for Validation 1\n",
            "134 - ConstantNaive with avg smape 11.79: \n",
            "Model Number: 135 of 188 with model UnobservedComponents for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - UnobservedComponents with avg smape 15.91: \n",
            "Model Number: 136 of 188 with model UnobservedComponents for Validation 1\n",
            "136 - UnobservedComponents with avg smape 15.92: \n",
            "Model Number: 137 of 188 with model UnobservedComponents for Validation 1\n",
            "137 - UnobservedComponents with avg smape 11.67: \n",
            "Model Number: 138 of 188 with model SectionalMotif for Validation 1\n",
            "138 - SectionalMotif with avg smape 11.49: \n",
            "Model Number: 139 of 188 with model AverageValueNaive for Validation 1\n",
            "139 - AverageValueNaive with avg smape 11.45: \n",
            "Model Number: 140 of 188 with model AverageValueNaive for Validation 1\n",
            "140 - AverageValueNaive with avg smape 11.4: \n",
            "Model Number: 141 of 188 with model AverageValueNaive for Validation 1\n",
            "141 - AverageValueNaive with avg smape 10.66: \n",
            "Model Number: 142 of 188 with model GLS for Validation 1\n",
            "142 - GLS with avg smape 11.44: \n",
            "Model Number: 143 of 188 with model GLS for Validation 1\n",
            "143 - GLS with avg smape 11.44: \n",
            "Model Number: 144 of 188 with model GLS for Validation 1\n",
            "144 - GLS with avg smape 11.44: \n",
            "Model Number: 145 of 188 with model GLS for Validation 1\n",
            "145 - GLS with avg smape 11.44: \n",
            "Model Number: 146 of 188 with model AverageValueNaive for Validation 1\n",
            "146 - AverageValueNaive with avg smape 17.16: \n",
            "Model Number: 147 of 188 with model SectionalMotif for Validation 1\n",
            "147 - SectionalMotif with avg smape 14.04: \n",
            "Model Number: 148 of 188 with model SeasonalNaive for Validation 1\n",
            "148 - SeasonalNaive with avg smape 12.41: \n",
            "Model Number: 149 of 188 with model WindowRegression for Validation 1\n",
            "149 - WindowRegression with avg smape 13.66: \n",
            "Model Number: 150 of 188 with model GLS for Validation 1\n",
            "150 - GLS with avg smape 11.65: \n",
            "Model Number: 151 of 188 with model SeasonalNaive for Validation 1\n",
            "151 - SeasonalNaive with avg smape 18.46: \n",
            "Model Number: 152 of 188 with model SeasonalNaive for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/2f0ua59a.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152 - SeasonalNaive with avg smape 18.46: \n",
            "Model Number: 153 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/su0uep3n.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=53524', 'data', 'file=/tmp/tmp2xi3y8fj/2f0ua59a.json', 'init=/tmp/tmp2xi3y8fj/su0uep3n.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model_8_2pz6o/prophet_model-20230410132833.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:33 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:28:33 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153 - FBProphet with avg smape 14.09: \n",
            "Model Number: 154 of 188 with model NVAR for Validation 1\n",
            "154 - NVAR with avg smape 10.64: \n",
            "Model Number: 155 of 188 with model WindowRegression for Validation 1\n",
            "155 - WindowRegression with avg smape 11.55: \n",
            "Model Number: 156 of 188 with model SeasonalNaive for Validation 1\n",
            "156 - SeasonalNaive with avg smape 12.41: \n",
            "Model Number: 157 of 188 with model SeasonalNaive for Validation 1\n",
            "157 - SeasonalNaive with avg smape 12.62: \n",
            "Model Number: 158 of 188 with model SeasonalNaive for Validation 1\n",
            "158 - SeasonalNaive with avg smape 12.62: \n",
            "Model Number: 159 of 188 with model AverageValueNaive for Validation 1\n",
            "159 - AverageValueNaive with avg smape 20.77: \n",
            "Model Number: 160 of 188 with model SeasonalNaive for Validation 1\n",
            "160 - SeasonalNaive with avg smape 23.2: \n",
            "Model Number: 161 of 188 with model GLS for Validation 1\n",
            "161 - GLS with avg smape 17.21: \n",
            "Model Number: 162 of 188 with model AverageValueNaive for Validation 1\n",
            "162 - AverageValueNaive with avg smape 20.18: \n",
            "Model Number: 163 of 188 with model SeasonalNaive for Validation 1\n",
            "163 - SeasonalNaive with avg smape 18.09: \n",
            "Model Number: 164 of 188 with model NVAR for Validation 1\n",
            "164 - NVAR with avg smape 15.24: \n",
            "Model Number: 165 of 188 with model SectionalMotif for Validation 1\n",
            "165 - SectionalMotif with avg smape 13.14: \n",
            "Model Number: 166 of 188 with model SeasonalNaive for Validation 1\n",
            "166 - SeasonalNaive with avg smape 14.59: \n",
            "Model Number: 167 of 188 with model NVAR for Validation 1\n",
            "167 - NVAR with avg smape 16.46: \n",
            "Model Number: 168 of 188 with model ConstantNaive for Validation 1\n",
            "168 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 169 of 188 with model GLS for Validation 1\n",
            "169 - GLS with avg smape 12.74: \n",
            "Model Number: 170 of 188 with model SectionalMotif for Validation 1\n",
            "170 - SectionalMotif with avg smape 13.91: \n",
            "Model Number: 171 of 188 with model ConstantNaive for Validation 1\n",
            "171 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 172 of 188 with model NVAR for Validation 1\n",
            "172 - NVAR with avg smape 13.16: \n",
            "Model Number: 173 of 188 with model ConstantNaive for Validation 1\n",
            "173 - ConstantNaive with avg smape 11.44: \n",
            "Model Number: 174 of 188 with model ConstantNaive for Validation 1\n",
            "174 - ConstantNaive with avg smape 11.44: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/fwv0crus.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Number: 175 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/2va6qbrv.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=18981', 'data', 'file=/tmp/tmp2xi3y8fj/fwv0crus.json', 'init=/tmp/tmp2xi3y8fj/2va6qbrv.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modely_d45_9h/prophet_model-20230410132834.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:34 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:28:34 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175 - FBProphet with avg smape 15.61: \n",
            "Model Number: 176 of 188 with model NVAR for Validation 1\n",
            "176 - NVAR with avg smape 13.51: \n",
            "Model Number: 177 of 188 with model NVAR for Validation 1\n",
            "177 - NVAR with avg smape 11.8: \n",
            "Model Number: 178 of 188 with model NVAR for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/j0q048yo.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 - NVAR with avg smape 11.8: \n",
            "Model Number: 179 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/03nr9xh4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3748', 'data', 'file=/tmp/tmp2xi3y8fj/j0q048yo.json', 'init=/tmp/tmp2xi3y8fj/03nr9xh4.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelukul_ja3/prophet_model-20230410132835.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:35 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:28:35 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/t58uotlm.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/o7ihd7d9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=16041', 'data', 'file=/tmp/tmp2xi3y8fj/t58uotlm.json', 'init=/tmp/tmp2xi3y8fj/o7ihd7d9.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelav5u6zxm/prophet_model-20230410132835.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:35 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179 - FBProphet with avg smape 15.07: \n",
            "Model Number: 180 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:28:36 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/2npxazz5.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/j7niaohd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=55573', 'data', 'file=/tmp/tmp2xi3y8fj/2npxazz5.json', 'init=/tmp/tmp2xi3y8fj/j7niaohd.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelv0mpcdbb/prophet_model-20230410132836.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180 - FBProphet with avg smape 14.19: \n",
            "Model Number: 181 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:28:36 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181 - FBProphet with avg smape 14.19: \n",
            "Model Number: 182 of 188 with model NVAR for Validation 1\n",
            "182 - NVAR with avg smape 22.39: \n",
            "Model Number: 183 of 188 with model NVAR for Validation 1\n",
            "183 - NVAR with avg smape 24.35: \n",
            "Model Number: 184 of 188 with model GLS for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/53_h4bof.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/35bwg8ud.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=37940', 'data', 'file=/tmp/tmp2xi3y8fj/53_h4bof.json', 'init=/tmp/tmp2xi3y8fj/35bwg8ud.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model5xpeccav/prophet_model-20230410132836.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:36 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184 - GLS with avg smape 21.62: \n",
            "Model Number: 185 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:28:36 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/x5wcn7wu.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/1lqrni9m.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=61580', 'data', 'file=/tmp/tmp2xi3y8fj/x5wcn7wu.json', 'init=/tmp/tmp2xi3y8fj/1lqrni9m.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelwhxk46f2/prophet_model-20230410132837.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:37 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185 - FBProphet with avg smape 16.94: \n",
            "Model Number: 186 of 188 with model FBProphet for Validation 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:28:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/m9prl1xz.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/nf6r9h4u.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87060', 'data', 'file=/tmp/tmp2xi3y8fj/m9prl1xz.json', 'init=/tmp/tmp2xi3y8fj/nf6r9h4u.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelkyd71ula/prophet_model-20230410132837.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:28:37 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186 - FBProphet with avg smape 14.69: \n",
            "Model Number: 187 of 188 with model FBProphet for Validation 1\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:28:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/k758t86u.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/2l4citx3.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=10468', 'data', 'file=/tmp/tmp2xi3y8fj/k758t86u.json', 'init=/tmp/tmp2xi3y8fj/2l4citx3.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelled7nvh5/prophet_model-20230410132837.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:28:37 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:28:37 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187 - FBProphet with avg smape 21.54: \n",
            "Model Number: 188 of 188 with model FBProphet for Validation 1\n",
            "188 - FBProphet with avg smape 17.79: \n",
            "Validation Round: 2\n",
            "Model Number: 1 of 188 with model ARIMA for Validation 2\n",
            "📈 1 - ARIMA with avg smape 6.0: \n",
            "Model Number: 2 of 188 with model Ensemble for Validation 2\n",
            "📈 2 - Ensemble with avg smape 5.1: \n",
            "Model Number: 3 of 188 with model Ensemble for Validation 2\n",
            "3 - Ensemble with avg smape 5.93: \n",
            "Model Number: 4 of 188 with model ARIMA for Validation 2\n",
            "4 - ARIMA with avg smape 6.25: \n",
            "Model Number: 5 of 188 with model Ensemble for Validation 2\n",
            "5 - Ensemble with avg smape 5.53: \n",
            "Model Number: 6 of 188 with model ARIMA for Validation 2\n",
            "6 - ARIMA with avg smape 5.53: \n",
            "Model Number: 7 of 188 with model ARIMA for Validation 2\n",
            "7 - ARIMA with avg smape 5.53: \n",
            "Model Number: 8 of 188 with model ARIMA for Validation 2\n",
            "8 - ARIMA with avg smape 5.51: \n",
            "Model Number: 9 of 188 with model ARIMA for Validation 2\n",
            "9 - ARIMA with avg smape 5.47: \n",
            "Model Number: 10 of 188 with model ARIMA for Validation 2\n",
            "10 - ARIMA with avg smape 5.47: \n",
            "Model Number: 11 of 188 with model ARIMA for Validation 2\n",
            "11 - ARIMA with avg smape 5.47: \n",
            "Model Number: 12 of 188 with model ARIMA for Validation 2\n",
            "📈 12 - ARIMA with avg smape 4.47: \n",
            "Model Number: 13 of 188 with model Ensemble for Validation 2\n",
            "📈 13 - Ensemble with avg smape 4.33: \n",
            "Model Number: 14 of 188 with model Ensemble for Validation 2\n",
            "14 - Ensemble with avg smape 6.99: \n",
            "Model Number: 15 of 188 with model Ensemble for Validation 2\n",
            "15 - Ensemble with avg smape 6.95: \n",
            "Model Number: 16 of 188 with model Ensemble for Validation 2\n",
            "16 - Ensemble with avg smape 6.95: \n",
            "Model Number: 17 of 188 with model Ensemble for Validation 2\n",
            "17 - Ensemble with avg smape 5.84: \n",
            "Model Number: 18 of 188 with model MultivariateMotif for Validation 2\n",
            "18 - MultivariateMotif with avg smape 4.69: \n",
            "Model Number: 19 of 188 with model MultivariateMotif for Validation 2\n",
            "19 - MultivariateMotif with avg smape 4.69: \n",
            "Model Number: 20 of 188 with model MultivariateMotif for Validation 2\n",
            "📈 20 - MultivariateMotif with avg smape 4.29: \n",
            "Model Number: 21 of 188 with model MultivariateMotif for Validation 2\n",
            "21 - MultivariateMotif with avg smape 4.29: \n",
            "Model Number: 22 of 188 with model MultivariateMotif for Validation 2\n",
            "22 - MultivariateMotif with avg smape 4.29: \n",
            "Model Number: 23 of 188 with model MultivariateMotif for Validation 2\n",
            "23 - MultivariateMotif with avg smape 4.29: \n",
            "Model Number: 24 of 188 with model ARDL for Validation 2\n",
            "24 - ARDL with avg smape 11.14: \n",
            "Model Number: 25 of 188 with model ARDL for Validation 2\n",
            "25 - ARDL with avg smape 6.67: \n",
            "Model Number: 26 of 188 with model ARDL for Validation 2\n",
            "26 - ARDL with avg smape 10.0: \n",
            "Model Number: 27 of 188 with model ARDL for Validation 2\n",
            "27 - ARDL with avg smape 9.86: \n",
            "Model Number: 28 of 188 with model ARDL for Validation 2\n",
            "28 - ARDL with avg smape 9.86: \n",
            "Model Number: 29 of 188 with model ARDL for Validation 2\n",
            "29 - ARDL with avg smape 9.86: \n",
            "Model Number: 30 of 188 with model ARDL for Validation 2\n",
            "30 - ARDL with avg smape 9.86: \n",
            "Model Number: 31 of 188 with model DatepartRegression for Validation 2\n",
            "31 - DatepartRegression with avg smape 7.33: \n",
            "Model Number: 32 of 188 with model ARDL for Validation 2\n",
            "32 - ARDL with avg smape 7.91: \n",
            "Model Number: 33 of 188 with model Theta for Validation 2\n",
            "📈 33 - Theta with avg smape 4.15: \n",
            "Model Number: 34 of 188 with model Theta for Validation 2\n",
            "34 - Theta with avg smape 4.15: \n",
            "Model Number: 35 of 188 with model ARDL for Validation 2\n",
            "35 - ARDL with avg smape 9.95: \n",
            "Model Number: 36 of 188 with model UnivariateMotif for Validation 2\n",
            "36 - UnivariateMotif with avg smape 5.07: \n",
            "Model Number: 37 of 188 with model Theta for Validation 2\n",
            "📈 37 - Theta with avg smape 4.09: \n",
            "Model Number: 38 of 188 with model Theta for Validation 2\n",
            "38 - Theta with avg smape 4.09: \n",
            "Model Number: 39 of 188 with model Theta for Validation 2\n",
            "39 - Theta with avg smape 4.09: \n",
            "Model Number: 40 of 188 with model Theta for Validation 2\n",
            "40 - Theta with avg smape 4.09: \n",
            "Model Number: 41 of 188 with model Theta for Validation 2\n",
            "41 - Theta with avg smape 4.09: \n",
            "Model Number: 42 of 188 with model DatepartRegression for Validation 2\n",
            "42 - DatepartRegression with avg smape 8.37: \n",
            "Model Number: 43 of 188 with model MultivariateMotif for Validation 2\n",
            "📈 43 - MultivariateMotif with avg smape 3.37: \n",
            "Model Number: 44 of 188 with model UnivariateMotif for Validation 2\n",
            "44 - UnivariateMotif with avg smape 7.7: \n",
            "Model Number: 45 of 188 with model UnivariateMotif for Validation 2\n",
            "45 - UnivariateMotif with avg smape 7.7: \n",
            "Model Number: 46 of 188 with model UnivariateMotif for Validation 2\n",
            "46 - UnivariateMotif with avg smape 8.21: \n",
            "Model Number: 47 of 188 with model UnivariateMotif for Validation 2\n",
            "47 - UnivariateMotif with avg smape 8.21: \n",
            "Model Number: 48 of 188 with model Theta for Validation 2\n",
            "48 - Theta with avg smape 4.51: \n",
            "Model Number: 49 of 188 with model Theta for Validation 2\n",
            "49 - Theta with avg smape 4.51: \n",
            "Model Number: 50 of 188 with model DatepartRegression for Validation 2\n",
            "50 - DatepartRegression with avg smape 7.15: \n",
            "Model Number: 51 of 188 with model UnivariateMotif for Validation 2\n",
            "51 - UnivariateMotif with avg smape 6.12: \n",
            "Model Number: 52 of 188 with model UnivariateMotif for Validation 2\n",
            "52 - UnivariateMotif with avg smape 5.34: \n",
            "Model Number: 53 of 188 with model UnivariateMotif for Validation 2\n",
            "53 - UnivariateMotif with avg smape 5.34: \n",
            "Model Number: 54 of 188 with model UnivariateMotif for Validation 2\n",
            "54 - UnivariateMotif with avg smape 6.51: \n",
            "Model Number: 55 of 188 with model MetricMotif for Validation 2\n",
            "55 - MetricMotif with avg smape 14.03: \n",
            "Model Number: 56 of 188 with model MetricMotif for Validation 2\n",
            "56 - MetricMotif with avg smape 8.54: \n",
            "Model Number: 57 of 188 with model MultivariateMotif for Validation 2\n",
            "57 - MultivariateMotif with avg smape 6.6: \n",
            "Model Number: 58 of 188 with model ConstantNaive for Validation 2\n",
            "58 - ConstantNaive with avg smape 5.03: \n",
            "Model Number: 59 of 188 with model DatepartRegression for Validation 2\n",
            "59 - DatepartRegression with avg smape 5.23: \n",
            "Model Number: 60 of 188 with model WindowRegression for Validation 2\n",
            "60 - WindowRegression with avg smape 10.35: \n",
            "Model Number: 61 of 188 with model MultivariateMotif for Validation 2\n",
            "61 - MultivariateMotif with avg smape 6.12: \n",
            "Model Number: 62 of 188 with model GLM for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62 - GLM with avg smape 4.58: \n",
            "Model Number: 63 of 188 with model GLM for Validation 2\n",
            "63 - GLM with avg smape 4.81: \n",
            "Model Number: 64 of 188 with model GLM for Validation 2\n",
            "64 - GLM with avg smape 4.8: \n",
            "Model Number: 65 of 188 with model GLM for Validation 2\n",
            "65 - GLM with avg smape 4.8: \n",
            "Model Number: 66 of 188 with model GLM for Validation 2\n",
            "66 - GLM with avg smape 4.8: \n",
            "Model Number: 67 of 188 with model GLM for Validation 2\n",
            "67 - GLM with avg smape 4.8: \n",
            "Model Number: 68 of 188 with model GLM for Validation 2\n",
            "📈 68 - GLM with avg smape 3.06: \n",
            "Model Number: 69 of 188 with model GLM for Validation 2\n",
            "69 - GLM with avg smape 7.7: \n",
            "Model Number: 70 of 188 with model GLM for Validation 2\n",
            "70 - GLM with avg smape 3.19: \n",
            "Model Number: 71 of 188 with model MultivariateRegression for Validation 2\n",
            "71 - MultivariateRegression with avg smape 11.83: \n",
            "Model Number: 72 of 188 with model MetricMotif for Validation 2\n",
            "72 - MetricMotif with avg smape 11.38: \n",
            "Model Number: 73 of 188 with model MetricMotif for Validation 2\n",
            "73 - MetricMotif with avg smape 11.38: \n",
            "Model Number: 74 of 188 with model WindowRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 - WindowRegression with avg smape 6.72: \n",
            "Model Number: 75 of 188 with model SectionalMotif for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75 - SectionalMotif with avg smape 3.34: \n",
            "Model Number: 76 of 188 with model MultivariateRegression for Validation 2\n",
            "76 - MultivariateRegression with avg smape 11.18: \n",
            "Model Number: 77 of 188 with model DatepartRegression for Validation 2\n",
            "77 - DatepartRegression with avg smape 14.46: \n",
            "Model Number: 78 of 188 with model MetricMotif for Validation 2\n",
            "78 - MetricMotif with avg smape 11.87: \n",
            "Model Number: 79 of 188 with model MetricMotif for Validation 2\n",
            "79 - MetricMotif with avg smape 11.87: \n",
            "Model Number: 80 of 188 with model WindowRegression for Validation 2\n",
            "80 - WindowRegression with avg smape 4.78: \n",
            "Model Number: 81 of 188 with model DatepartRegression for Validation 2\n",
            "81 - DatepartRegression with avg smape 16.28: \n",
            "Model Number: 82 of 188 with model DatepartRegression for Validation 2\n",
            "82 - DatepartRegression with avg smape 9.2: \n",
            "Model Number: 83 of 188 with model DatepartRegression for Validation 2\n",
            "83 - DatepartRegression with avg smape 9.22: \n",
            "Model Number: 84 of 188 with model MetricMotif for Validation 2\n",
            "84 - MetricMotif with avg smape 9.95: \n",
            "Model Number: 85 of 188 with model DatepartRegression for Validation 2\n",
            "85 - DatepartRegression with avg smape 9.55: \n",
            "Model Number: 86 of 188 with model GLS for Validation 2\n",
            "86 - GLS with avg smape 11.65: \n",
            "Model Number: 87 of 188 with model SectionalMotif for Validation 2\n",
            "87 - SectionalMotif with avg smape 5.81: \n",
            "Model Number: 88 of 188 with model ETS for Validation 2\n",
            "88 - ETS with avg smape 8.45: \n",
            "Model Number: 89 of 188 with model ETS for Validation 2\n",
            "89 - ETS with avg smape 8.45: \n",
            "Model Number: 90 of 188 with model LastValueNaive for Validation 2\n",
            "90 - LastValueNaive with avg smape 5.94: \n",
            "Model Number: 91 of 188 with model LastValueNaive for Validation 2\n",
            "91 - LastValueNaive with avg smape 5.94: \n",
            "Model Number: 92 of 188 with model LastValueNaive for Validation 2\n",
            "92 - LastValueNaive with avg smape 5.94: \n",
            "Model Number: 93 of 188 with model LastValueNaive for Validation 2\n",
            "93 - LastValueNaive with avg smape 5.94: \n",
            "Model Number: 94 of 188 with model MetricMotif for Validation 2\n",
            "94 - MetricMotif with avg smape 6.99: \n",
            "Model Number: 95 of 188 with model LastValueNaive for Validation 2\n",
            "95 - LastValueNaive with avg smape 5.95: \n",
            "Model Number: 96 of 188 with model WindowRegression for Validation 2\n",
            "96 - WindowRegression with avg smape 4.78: \n",
            "Model Number: 97 of 188 with model MetricMotif for Validation 2\n",
            "97 - MetricMotif with avg smape 9.58: \n",
            "Model Number: 98 of 188 with model AverageValueNaive for Validation 2\n",
            "98 - AverageValueNaive with avg smape 8.43: \n",
            "Model Number: 99 of 188 with model AverageValueNaive for Validation 2\n",
            "99 - AverageValueNaive with avg smape 8.78: \n",
            "Model Number: 100 of 188 with model AverageValueNaive for Validation 2\n",
            "100 - AverageValueNaive with avg smape 8.78: \n",
            "Model Number: 101 of 188 with model ETS for Validation 2\n",
            "101 - ETS with avg smape 6.52: \n",
            "Model Number: 102 of 188 with model MultivariateRegression for Validation 2\n",
            "102 - MultivariateRegression with avg smape 15.83: \n",
            "Model Number: 103 of 188 with model SectionalMotif for Validation 2\n",
            "103 - SectionalMotif with avg smape 8.37: \n",
            "Model Number: 104 of 188 with model ETS for Validation 2\n",
            "104 - ETS with avg smape 6.74: \n",
            "Model Number: 105 of 188 with model ETS for Validation 2\n",
            "105 - ETS with avg smape 6.74: \n",
            "Model Number: 106 of 188 with model ETS for Validation 2\n",
            "106 - ETS with avg smape 7.07: \n",
            "Model Number: 107 of 188 with model MultivariateRegression for Validation 2\n",
            "107 - MultivariateRegression with avg smape 14.13: \n",
            "Model Number: 108 of 188 with model ETS for Validation 2\n",
            "108 - ETS with avg smape 6.77: \n",
            "Model Number: 109 of 188 with model ETS for Validation 2\n",
            "109 - ETS with avg smape 6.77: \n",
            "Model Number: 110 of 188 with model MultivariateRegression for Validation 2\n",
            "110 - MultivariateRegression with avg smape 3.24: \n",
            "Model Number: 111 of 188 with model MultivariateRegression for Validation 2\n",
            "111 - MultivariateRegression with avg smape 10.52: \n",
            "Model Number: 112 of 188 with model LastValueNaive for Validation 2\n",
            "112 - LastValueNaive with avg smape 9.76: \n",
            "Model Number: 113 of 188 with model LastValueNaive for Validation 2\n",
            "113 - LastValueNaive with avg smape 7.99: \n",
            "Model Number: 114 of 188 with model MultivariateRegression for Validation 2\n",
            "114 - MultivariateRegression with avg smape 11.32: \n",
            "Model Number: 115 of 188 with model MultivariateRegression for Validation 2\n",
            "115 - MultivariateRegression with avg smape 9.74: \n",
            "Model Number: 116 of 188 with model UnobservedComponents for Validation 2\n",
            "116 - UnobservedComponents with avg smape 15.63: \n",
            "Model Number: 117 of 188 with model MultivariateRegression for Validation 2\n",
            "117 - MultivariateRegression with avg smape 13.95: \n",
            "Model Number: 118 of 188 with model LastValueNaive for Validation 2\n",
            "118 - LastValueNaive with avg smape 8.11: \n",
            "Model Number: 119 of 188 with model LastValueNaive for Validation 2\n",
            "119 - LastValueNaive with avg smape 8.11: \n",
            "Model Number: 120 of 188 with model WindowRegression for Validation 2\n",
            "120 - WindowRegression with avg smape 9.22: \n",
            "Model Number: 121 of 188 with model ETS for Validation 2\n",
            "121 - ETS with avg smape 5.67: \n",
            "Model Number: 122 of 188 with model WindowRegression for Validation 2\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000038 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "122 - WindowRegression with avg smape 5.22: \n",
            "Model Number: 123 of 188 with model ConstantNaive for Validation 2\n",
            "📈 123 - ConstantNaive with avg smape 3.03: \n",
            "Model Number: 124 of 188 with model UnobservedComponents for Validation 2\n",
            "124 - UnobservedComponents with avg smape 12.86: \n",
            "Model Number: 125 of 188 with model UnobservedComponents for Validation 2\n",
            "125 - UnobservedComponents with avg smape 12.86: \n",
            "Model Number: 126 of 188 with model WindowRegression for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - WindowRegression with avg smape 4.08: \n",
            "Model Number: 127 of 188 with model UnobservedComponents for Validation 2\n",
            "127 - UnobservedComponents with avg smape 17.02: \n",
            "Model Number: 128 of 188 with model UnobservedComponents for Validation 2\n",
            "128 - UnobservedComponents with avg smape 32.12: \n",
            "Model Number: 129 of 188 with model SectionalMotif for Validation 2\n",
            "129 - SectionalMotif with avg smape 3.22: \n",
            "Model Number: 130 of 188 with model SectionalMotif for Validation 2\n",
            "130 - SectionalMotif with avg smape 3.22: \n",
            "Model Number: 131 of 188 with model ConstantNaive for Validation 2\n",
            "131 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 132 of 188 with model ConstantNaive for Validation 2\n",
            "132 - ConstantNaive with avg smape 3.22: \n",
            "Model Number: 133 of 188 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133 - UnobservedComponents with avg smape 11.66: \n",
            "Model Number: 134 of 188 with model ConstantNaive for Validation 2\n",
            "134 - ConstantNaive with avg smape 3.25: \n",
            "Model Number: 135 of 188 with model UnobservedComponents for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - UnobservedComponents with avg smape 12.51: \n",
            "Model Number: 136 of 188 with model UnobservedComponents for Validation 2\n",
            "136 - UnobservedComponents with avg smape 12.52: \n",
            "Model Number: 137 of 188 with model UnobservedComponents for Validation 2\n",
            "137 - UnobservedComponents with avg smape 11.53: \n",
            "Model Number: 138 of 188 with model SectionalMotif for Validation 2\n",
            "138 - SectionalMotif with avg smape 16.02: \n",
            "Model Number: 139 of 188 with model AverageValueNaive for Validation 2\n",
            "139 - AverageValueNaive with avg smape 15.88: \n",
            "Model Number: 140 of 188 with model AverageValueNaive for Validation 2\n",
            "140 - AverageValueNaive with avg smape 15.29: \n",
            "Model Number: 141 of 188 with model AverageValueNaive for Validation 2\n",
            "141 - AverageValueNaive with avg smape 12.49: \n",
            "Model Number: 142 of 188 with model GLS for Validation 2\n",
            "142 - GLS with avg smape 12.63: \n",
            "Model Number: 143 of 188 with model GLS for Validation 2\n",
            "143 - GLS with avg smape 12.59: \n",
            "Model Number: 144 of 188 with model GLS for Validation 2\n",
            "144 - GLS with avg smape 12.66: \n",
            "Model Number: 145 of 188 with model GLS for Validation 2\n",
            "145 - GLS with avg smape 12.66: \n",
            "Model Number: 146 of 188 with model AverageValueNaive for Validation 2\n",
            "146 - AverageValueNaive with avg smape 12.06: \n",
            "Model Number: 147 of 188 with model SectionalMotif for Validation 2\n",
            "147 - SectionalMotif with avg smape 15.68: \n",
            "Model Number: 148 of 188 with model SeasonalNaive for Validation 2\n",
            "148 - SeasonalNaive with avg smape 10.9: \n",
            "Model Number: 149 of 188 with model WindowRegression for Validation 2\n",
            "149 - WindowRegression with avg smape 14.98: \n",
            "Model Number: 150 of 188 with model GLS for Validation 2\n",
            "150 - GLS with avg smape 12.3: \n",
            "Model Number: 151 of 188 with model SeasonalNaive for Validation 2\n",
            "151 - SeasonalNaive with avg smape 11.17: \n",
            "Model Number: 152 of 188 with model SeasonalNaive for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152 - SeasonalNaive with avg smape 11.17: \n",
            "Model Number: 153 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/lymhlfki.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/gfxq4ehm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=37236', 'data', 'file=/tmp/tmp2xi3y8fj/lymhlfki.json', 'init=/tmp/tmp2xi3y8fj/gfxq4ehm.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modela9ps54vt/prophet_model-20230410133513.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:13 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:35:13 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153 - FBProphet with avg smape 14.4: \n",
            "Model Number: 154 of 188 with model NVAR for Validation 2\n",
            "154 - NVAR with avg smape 11.73: \n",
            "Model Number: 155 of 188 with model WindowRegression for Validation 2\n",
            "155 - WindowRegression with avg smape 49.03: \n",
            "Model Number: 156 of 188 with model SeasonalNaive for Validation 2\n",
            "156 - SeasonalNaive with avg smape 10.9: \n",
            "Model Number: 157 of 188 with model SeasonalNaive for Validation 2\n",
            "157 - SeasonalNaive with avg smape 10.69: \n",
            "Model Number: 158 of 188 with model SeasonalNaive for Validation 2\n",
            "158 - SeasonalNaive with avg smape 10.69: \n",
            "Model Number: 159 of 188 with model AverageValueNaive for Validation 2\n",
            "159 - AverageValueNaive with avg smape 12.02: \n",
            "Model Number: 160 of 188 with model SeasonalNaive for Validation 2\n",
            "160 - SeasonalNaive with avg smape 8.01: \n",
            "Model Number: 161 of 188 with model GLS for Validation 2\n",
            "161 - GLS with avg smape 6.81: \n",
            "Model Number: 162 of 188 with model AverageValueNaive for Validation 2\n",
            "162 - AverageValueNaive with avg smape 12.87: \n",
            "Model Number: 163 of 188 with model SeasonalNaive for Validation 2\n",
            "163 - SeasonalNaive with avg smape 11.41: \n",
            "Model Number: 164 of 188 with model NVAR for Validation 2\n",
            "164 - NVAR with avg smape 12.4: \n",
            "Model Number: 165 of 188 with model SectionalMotif for Validation 2\n",
            "165 - SectionalMotif with avg smape 9.29: \n",
            "Model Number: 166 of 188 with model SeasonalNaive for Validation 2\n",
            "166 - SeasonalNaive with avg smape 14.51: \n",
            "Model Number: 167 of 188 with model NVAR for Validation 2\n",
            "167 - NVAR with avg smape 11.97: \n",
            "Model Number: 168 of 188 with model ConstantNaive for Validation 2\n",
            "168 - ConstantNaive with avg smape 12.68: \n",
            "Model Number: 169 of 188 with model GLS for Validation 2\n",
            "169 - GLS with avg smape 16.58: \n",
            "Model Number: 170 of 188 with model SectionalMotif for Validation 2\n",
            "170 - SectionalMotif with avg smape 9.98: \n",
            "Model Number: 171 of 188 with model ConstantNaive for Validation 2\n",
            "171 - ConstantNaive with avg smape 11.99: \n",
            "Model Number: 172 of 188 with model NVAR for Validation 2\n",
            "172 - NVAR with avg smape 11.52: \n",
            "Model Number: 173 of 188 with model ConstantNaive for Validation 2\n",
            "173 - ConstantNaive with avg smape 11.9: \n",
            "Model Number: 174 of 188 with model ConstantNaive for Validation 2\n",
            "174 - ConstantNaive with avg smape 11.9: \n",
            "Model Number: 175 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/rawppzhm.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/pachoebn.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=61182', 'data', 'file=/tmp/tmp2xi3y8fj/rawppzhm.json', 'init=/tmp/tmp2xi3y8fj/pachoebn.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model45eoh7f9/prophet_model-20230410133514.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:14 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:35:14 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175 - FBProphet with avg smape 14.29: \n",
            "Model Number: 176 of 188 with model NVAR for Validation 2\n",
            "176 - NVAR with avg smape 17.86: \n",
            "Model Number: 177 of 188 with model NVAR for Validation 2\n",
            "177 - NVAR with avg smape 11.28: \n",
            "Model Number: 178 of 188 with model NVAR for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/msu986yx.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/5rula6s0.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84670', 'data', 'file=/tmp/tmp2xi3y8fj/msu986yx.json', 'init=/tmp/tmp2xi3y8fj/5rula6s0.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model6ovpzcdq/prophet_model-20230410133514.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:14 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 - NVAR with avg smape 11.28: \n",
            "Model Number: 179 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:35:15 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/stoz06x2.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/0va7ppxq.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=98518', 'data', 'file=/tmp/tmp2xi3y8fj/stoz06x2.json', 'init=/tmp/tmp2xi3y8fj/0va7ppxq.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model8nfvu2jv/prophet_model-20230410133515.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:15 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179 - FBProphet with avg smape 14.33: \n",
            "Model Number: 180 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:35:16 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/a0079plt.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/szsovjng.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=35935', 'data', 'file=/tmp/tmp2xi3y8fj/a0079plt.json', 'init=/tmp/tmp2xi3y8fj/szsovjng.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelf_e7xx70/prophet_model-20230410133516.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:16 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180 - FBProphet with avg smape 10.01: \n",
            "Model Number: 181 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:35:17 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181 - FBProphet with avg smape 10.01: \n",
            "Model Number: 182 of 188 with model NVAR for Validation 2\n",
            "182 - NVAR with avg smape 12.35: \n",
            "Model Number: 183 of 188 with model NVAR for Validation 2\n",
            "183 - NVAR with avg smape 34.06: \n",
            "Model Number: 184 of 188 with model GLS for Validation 2\n",
            "184 - GLS with avg smape 13.49: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/66nxucbt.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Number: 185 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/5eza3obd.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=63141', 'data', 'file=/tmp/tmp2xi3y8fj/66nxucbt.json', 'init=/tmp/tmp2xi3y8fj/5eza3obd.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelouqmnw94/prophet_model-20230410133517.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:17 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:35:17 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/60df30iq.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/pf3qw1tf.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=82312', 'data', 'file=/tmp/tmp2xi3y8fj/60df30iq.json', 'init=/tmp/tmp2xi3y8fj/pf3qw1tf.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelcz2wwzej/prophet_model-20230410133517.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:17 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185 - FBProphet with avg smape 13.1: \n",
            "Model Number: 186 of 188 with model FBProphet for Validation 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:35:17 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/k3u_29kq.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/i905d4ii.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=74309', 'data', 'file=/tmp/tmp2xi3y8fj/k3u_29kq.json', 'init=/tmp/tmp2xi3y8fj/i905d4ii.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model7qmth6dw/prophet_model-20230410133518.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:35:18 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186 - FBProphet with avg smape 12.74: \n",
            "Model Number: 187 of 188 with model FBProphet for Validation 2\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:35:18 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/gnh25_3k.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/kzb8g651.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=84431', 'data', 'file=/tmp/tmp2xi3y8fj/gnh25_3k.json', 'init=/tmp/tmp2xi3y8fj/kzb8g651.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelu0y7p0t7/prophet_model-20230410133518.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "13:35:18 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:35:18 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187 - FBProphet with avg smape 21.98: \n",
            "Model Number: 188 of 188 with model FBProphet for Validation 2\n",
            "188 - FBProphet with avg smape 24.06: \n",
            "Validation Round: 3\n",
            "Model Number: 1 of 188 with model ARIMA for Validation 3\n",
            "📈 1 - ARIMA with avg smape 2.96: \n",
            "Model Number: 2 of 188 with model Ensemble for Validation 3\n",
            "2 - Ensemble with avg smape 3.75: \n",
            "Model Number: 3 of 188 with model Ensemble for Validation 3\n",
            "3 - Ensemble with avg smape 2.97: \n",
            "Model Number: 4 of 188 with model ARIMA for Validation 3\n",
            "📈 4 - ARIMA with avg smape 2.83: \n",
            "Model Number: 5 of 188 with model Ensemble for Validation 3\n",
            "5 - Ensemble with avg smape 3.45: \n",
            "Model Number: 6 of 188 with model ARIMA for Validation 3\n",
            "6 - ARIMA with avg smape 3.47: \n",
            "Model Number: 7 of 188 with model ARIMA for Validation 3\n",
            "7 - ARIMA with avg smape 3.47: \n",
            "Model Number: 8 of 188 with model ARIMA for Validation 3\n",
            "8 - ARIMA with avg smape 3.45: \n",
            "Model Number: 9 of 188 with model ARIMA for Validation 3\n",
            "9 - ARIMA with avg smape 3.24: \n",
            "Model Number: 10 of 188 with model ARIMA for Validation 3\n",
            "10 - ARIMA with avg smape 3.24: \n",
            "Model Number: 11 of 188 with model ARIMA for Validation 3\n",
            "11 - ARIMA with avg smape 3.24: \n",
            "Model Number: 12 of 188 with model ARIMA for Validation 3\n",
            "12 - ARIMA with avg smape 4.62: \n",
            "Model Number: 13 of 188 with model Ensemble for Validation 3\n",
            "13 - Ensemble with avg smape 3.8: \n",
            "Model Number: 14 of 188 with model Ensemble for Validation 3\n",
            "📈 14 - Ensemble with avg smape 2.75: \n",
            "Model Number: 15 of 188 with model Ensemble for Validation 3\n",
            "15 - Ensemble with avg smape 2.77: \n",
            "Model Number: 16 of 188 with model Ensemble for Validation 3\n",
            "16 - Ensemble with avg smape 2.77: \n",
            "Model Number: 17 of 188 with model Ensemble for Validation 3\n",
            "17 - Ensemble with avg smape 3.66: \n",
            "Model Number: 18 of 188 with model MultivariateMotif for Validation 3\n",
            "18 - MultivariateMotif with avg smape 4.18: \n",
            "Model Number: 19 of 188 with model MultivariateMotif for Validation 3\n",
            "19 - MultivariateMotif with avg smape 4.18: \n",
            "Model Number: 20 of 188 with model MultivariateMotif for Validation 3\n",
            "20 - MultivariateMotif with avg smape 4.13: \n",
            "Model Number: 21 of 188 with model MultivariateMotif for Validation 3\n",
            "21 - MultivariateMotif with avg smape 4.13: \n",
            "Model Number: 22 of 188 with model MultivariateMotif for Validation 3\n",
            "22 - MultivariateMotif with avg smape 4.13: \n",
            "Model Number: 23 of 188 with model MultivariateMotif for Validation 3\n",
            "23 - MultivariateMotif with avg smape 4.13: \n",
            "Model Number: 24 of 188 with model ARDL for Validation 3\n",
            "24 - ARDL with avg smape 3.5: \n",
            "Model Number: 25 of 188 with model ARDL for Validation 3\n",
            "25 - ARDL with avg smape 3.82: \n",
            "Model Number: 26 of 188 with model ARDL for Validation 3\n",
            "26 - ARDL with avg smape 3.89: \n",
            "Model Number: 27 of 188 with model ARDL for Validation 3\n",
            "27 - ARDL with avg smape 3.86: \n",
            "Model Number: 28 of 188 with model ARDL for Validation 3\n",
            "28 - ARDL with avg smape 3.86: \n",
            "Model Number: 29 of 188 with model ARDL for Validation 3\n",
            "29 - ARDL with avg smape 3.86: \n",
            "Model Number: 30 of 188 with model ARDL for Validation 3\n",
            "30 - ARDL with avg smape 3.86: \n",
            "Model Number: 31 of 188 with model DatepartRegression for Validation 3\n",
            "31 - DatepartRegression with avg smape 4.05: \n",
            "Model Number: 32 of 188 with model ARDL for Validation 3\n",
            "32 - ARDL with avg smape 4.89: \n",
            "Model Number: 33 of 188 with model Theta for Validation 3\n",
            "33 - Theta with avg smape 5.61: \n",
            "Model Number: 34 of 188 with model Theta for Validation 3\n",
            "34 - Theta with avg smape 5.61: \n",
            "Model Number: 35 of 188 with model ARDL for Validation 3\n",
            "35 - ARDL with avg smape 3.91: \n",
            "Model Number: 36 of 188 with model UnivariateMotif for Validation 3\n",
            "36 - UnivariateMotif with avg smape 5.66: \n",
            "Model Number: 37 of 188 with model Theta for Validation 3\n",
            "37 - Theta with avg smape 5.89: \n",
            "Model Number: 38 of 188 with model Theta for Validation 3\n",
            "38 - Theta with avg smape 5.89: \n",
            "Model Number: 39 of 188 with model Theta for Validation 3\n",
            "39 - Theta with avg smape 5.89: \n",
            "Model Number: 40 of 188 with model Theta for Validation 3\n",
            "40 - Theta with avg smape 5.89: \n",
            "Model Number: 41 of 188 with model Theta for Validation 3\n",
            "41 - Theta with avg smape 5.89: \n",
            "Model Number: 42 of 188 with model DatepartRegression for Validation 3\n",
            "42 - DatepartRegression with avg smape 5.52: \n",
            "Model Number: 43 of 188 with model MultivariateMotif for Validation 3\n",
            "43 - MultivariateMotif with avg smape 5.23: \n",
            "Model Number: 44 of 188 with model UnivariateMotif for Validation 3\n",
            "44 - UnivariateMotif with avg smape 5.18: \n",
            "Model Number: 45 of 188 with model UnivariateMotif for Validation 3\n",
            "45 - UnivariateMotif with avg smape 5.18: \n",
            "Model Number: 46 of 188 with model UnivariateMotif for Validation 3\n",
            "46 - UnivariateMotif with avg smape 6.01: \n",
            "Model Number: 47 of 188 with model UnivariateMotif for Validation 3\n",
            "47 - UnivariateMotif with avg smape 6.01: \n",
            "Model Number: 48 of 188 with model Theta for Validation 3\n",
            "48 - Theta with avg smape 5.73: \n",
            "Model Number: 49 of 188 with model Theta for Validation 3\n",
            "49 - Theta with avg smape 5.73: \n",
            "Model Number: 50 of 188 with model DatepartRegression for Validation 3\n",
            "50 - DatepartRegression with avg smape 4.91: \n",
            "Model Number: 51 of 188 with model UnivariateMotif for Validation 3\n",
            "51 - UnivariateMotif with avg smape 7.02: \n",
            "Model Number: 52 of 188 with model UnivariateMotif for Validation 3\n",
            "52 - UnivariateMotif with avg smape 6.39: \n",
            "Model Number: 53 of 188 with model UnivariateMotif for Validation 3\n",
            "53 - UnivariateMotif with avg smape 6.39: \n",
            "Model Number: 54 of 188 with model UnivariateMotif for Validation 3\n",
            "54 - UnivariateMotif with avg smape 7.31: \n",
            "Model Number: 55 of 188 with model MetricMotif for Validation 3\n",
            "55 - MetricMotif with avg smape 14.68: \n",
            "Model Number: 56 of 188 with model MetricMotif for Validation 3\n",
            "56 - MetricMotif with avg smape 13.74: \n",
            "Model Number: 57 of 188 with model MultivariateMotif for Validation 3\n",
            "57 - MultivariateMotif with avg smape 8.6: \n",
            "Model Number: 58 of 188 with model ConstantNaive for Validation 3\n",
            "58 - ConstantNaive with avg smape 3.29: \n",
            "Model Number: 59 of 188 with model DatepartRegression for Validation 3\n",
            "59 - DatepartRegression with avg smape 6.88: \n",
            "Model Number: 60 of 188 with model WindowRegression for Validation 3\n",
            "60 - WindowRegression with avg smape 3.22: \n",
            "Model Number: 61 of 188 with model MultivariateMotif for Validation 3\n",
            "61 - MultivariateMotif with avg smape 9.05: \n",
            "Model Number: 62 of 188 with model GLM for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62 - GLM with avg smape 3.35: \n",
            "Model Number: 63 of 188 with model GLM for Validation 3\n",
            "63 - GLM with avg smape 3.38: \n",
            "Model Number: 64 of 188 with model GLM for Validation 3\n",
            "64 - GLM with avg smape 3.37: \n",
            "Model Number: 65 of 188 with model GLM for Validation 3\n",
            "65 - GLM with avg smape 3.37: \n",
            "Model Number: 66 of 188 with model GLM for Validation 3\n",
            "66 - GLM with avg smape 3.37: \n",
            "Model Number: 67 of 188 with model GLM for Validation 3\n",
            "67 - GLM with avg smape 3.37: \n",
            "Model Number: 68 of 188 with model GLM for Validation 3\n",
            "68 - GLM with avg smape 15.14: \n",
            "Model Number: 69 of 188 with model GLM for Validation 3\n",
            "69 - GLM with avg smape 4.33: \n",
            "Model Number: 70 of 188 with model GLM for Validation 3\n",
            "70 - GLM with avg smape 15.45: \n",
            "Model Number: 71 of 188 with model MultivariateRegression for Validation 3\n",
            "71 - MultivariateRegression with avg smape 8.43: \n",
            "Model Number: 72 of 188 with model MetricMotif for Validation 3\n",
            "72 - MetricMotif with avg smape 12.5: \n",
            "Model Number: 73 of 188 with model MetricMotif for Validation 3\n",
            "73 - MetricMotif with avg smape 12.5: \n",
            "Model Number: 74 of 188 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74 - WindowRegression with avg smape 3.7: \n",
            "Model Number: 75 of 188 with model SectionalMotif for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75 - SectionalMotif with avg smape 4.89: \n",
            "Model Number: 76 of 188 with model MultivariateRegression for Validation 3\n",
            "76 - MultivariateRegression with avg smape 9.42: \n",
            "Model Number: 77 of 188 with model DatepartRegression for Validation 3\n",
            "77 - DatepartRegression with avg smape 6.97: \n",
            "Model Number: 78 of 188 with model MetricMotif for Validation 3\n",
            "78 - MetricMotif with avg smape 6.93: \n",
            "Model Number: 79 of 188 with model MetricMotif for Validation 3\n",
            "79 - MetricMotif with avg smape 6.93: \n",
            "Model Number: 80 of 188 with model WindowRegression for Validation 3\n",
            "80 - WindowRegression with avg smape 3.35: \n",
            "Model Number: 81 of 188 with model DatepartRegression for Validation 3\n",
            "81 - DatepartRegression with avg smape 7.81: \n",
            "Model Number: 82 of 188 with model DatepartRegression for Validation 3\n",
            "82 - DatepartRegression with avg smape 5.79: \n",
            "Model Number: 83 of 188 with model DatepartRegression for Validation 3\n",
            "83 - DatepartRegression with avg smape 5.8: \n",
            "Model Number: 84 of 188 with model MetricMotif for Validation 3\n",
            "84 - MetricMotif with avg smape 13.66: \n",
            "Model Number: 85 of 188 with model DatepartRegression for Validation 3\n",
            "85 - DatepartRegression with avg smape 5.86: \n",
            "Model Number: 86 of 188 with model GLS for Validation 3\n",
            "86 - GLS with avg smape 6.29: \n",
            "Model Number: 87 of 188 with model SectionalMotif for Validation 3\n",
            "87 - SectionalMotif with avg smape 4.62: \n",
            "Model Number: 88 of 188 with model ETS for Validation 3\n",
            "88 - ETS with avg smape 6.3: \n",
            "Model Number: 89 of 188 with model ETS for Validation 3\n",
            "89 - ETS with avg smape 6.3: \n",
            "Model Number: 90 of 188 with model LastValueNaive for Validation 3\n",
            "90 - LastValueNaive with avg smape 8.54: \n",
            "Model Number: 91 of 188 with model LastValueNaive for Validation 3\n",
            "91 - LastValueNaive with avg smape 8.54: \n",
            "Model Number: 92 of 188 with model LastValueNaive for Validation 3\n",
            "92 - LastValueNaive with avg smape 8.55: \n",
            "Model Number: 93 of 188 with model LastValueNaive for Validation 3\n",
            "93 - LastValueNaive with avg smape 8.55: \n",
            "Model Number: 94 of 188 with model MetricMotif for Validation 3\n",
            "94 - MetricMotif with avg smape 8.97: \n",
            "Model Number: 95 of 188 with model LastValueNaive for Validation 3\n",
            "95 - LastValueNaive with avg smape 8.66: \n",
            "Model Number: 96 of 188 with model WindowRegression for Validation 3\n",
            "96 - WindowRegression with avg smape 6.24: \n",
            "Model Number: 97 of 188 with model MetricMotif for Validation 3\n",
            "97 - MetricMotif with avg smape 8.81: \n",
            "Model Number: 98 of 188 with model AverageValueNaive for Validation 3\n",
            "98 - AverageValueNaive with avg smape 7.77: \n",
            "Model Number: 99 of 188 with model AverageValueNaive for Validation 3\n",
            "99 - AverageValueNaive with avg smape 7.67: \n",
            "Model Number: 100 of 188 with model AverageValueNaive for Validation 3\n",
            "100 - AverageValueNaive with avg smape 7.67: \n",
            "Model Number: 101 of 188 with model ETS for Validation 3\n",
            "101 - ETS with avg smape 7.11: \n",
            "Model Number: 102 of 188 with model MultivariateRegression for Validation 3\n",
            "102 - MultivariateRegression with avg smape 7.36: \n",
            "Model Number: 103 of 188 with model SectionalMotif for Validation 3\n",
            "103 - SectionalMotif with avg smape 7.43: \n",
            "Model Number: 104 of 188 with model ETS for Validation 3\n",
            "104 - ETS with avg smape 7.73: \n",
            "Model Number: 105 of 188 with model ETS for Validation 3\n",
            "105 - ETS with avg smape 7.73: \n",
            "Model Number: 106 of 188 with model ETS for Validation 3\n",
            "106 - ETS with avg smape 7.23: \n",
            "Model Number: 107 of 188 with model MultivariateRegression for Validation 3\n",
            "107 - MultivariateRegression with avg smape 11.28: \n",
            "Model Number: 108 of 188 with model ETS for Validation 3\n",
            "108 - ETS with avg smape 11.01: \n",
            "Model Number: 109 of 188 with model ETS for Validation 3\n",
            "109 - ETS with avg smape 11.01: \n",
            "Model Number: 110 of 188 with model MultivariateRegression for Validation 3\n",
            "110 - MultivariateRegression with avg smape 6.46: \n",
            "Model Number: 111 of 188 with model MultivariateRegression for Validation 3\n",
            "111 - MultivariateRegression with avg smape 10.21: \n",
            "Model Number: 112 of 188 with model LastValueNaive for Validation 3\n",
            "112 - LastValueNaive with avg smape 14.91: \n",
            "Model Number: 113 of 188 with model LastValueNaive for Validation 3\n",
            "113 - LastValueNaive with avg smape 14.52: \n",
            "Model Number: 114 of 188 with model MultivariateRegression for Validation 3\n",
            "114 - MultivariateRegression with avg smape 15.1: \n",
            "Model Number: 115 of 188 with model MultivariateRegression for Validation 3\n",
            "115 - MultivariateRegression with avg smape 12.53: \n",
            "Model Number: 116 of 188 with model UnobservedComponents for Validation 3\n",
            "116 - UnobservedComponents with avg smape 14.69: \n",
            "Model Number: 117 of 188 with model MultivariateRegression for Validation 3\n",
            "117 - MultivariateRegression with avg smape 14.86: \n",
            "Model Number: 118 of 188 with model LastValueNaive for Validation 3\n",
            "118 - LastValueNaive with avg smape 14.66: \n",
            "Model Number: 119 of 188 with model LastValueNaive for Validation 3\n",
            "119 - LastValueNaive with avg smape 14.66: \n",
            "Model Number: 120 of 188 with model WindowRegression for Validation 3\n",
            "120 - WindowRegression with avg smape 8.08: \n",
            "Model Number: 121 of 188 with model ETS for Validation 3\n",
            "121 - ETS with avg smape 8.51: \n",
            "Model Number: 122 of 188 with model WindowRegression for Validation 3\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000039 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "122 - WindowRegression with avg smape 9.77: \n",
            "Model Number: 123 of 188 with model ConstantNaive for Validation 3\n",
            "123 - ConstantNaive with avg smape 11.07: \n",
            "Model Number: 124 of 188 with model UnobservedComponents for Validation 3\n",
            "124 - UnobservedComponents with avg smape 11.97: \n",
            "Model Number: 125 of 188 with model UnobservedComponents for Validation 3\n",
            "125 - UnobservedComponents with avg smape 11.97: \n",
            "Model Number: 126 of 188 with model WindowRegression for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 - WindowRegression with avg smape 15.87: \n",
            "Model Number: 127 of 188 with model UnobservedComponents for Validation 3\n",
            "127 - UnobservedComponents with avg smape 18.62: \n",
            "Model Number: 128 of 188 with model UnobservedComponents for Validation 3\n",
            "128 - UnobservedComponents with avg smape 18.62: \n",
            "Model Number: 129 of 188 with model SectionalMotif for Validation 3\n",
            "129 - SectionalMotif with avg smape 11.38: \n",
            "Model Number: 130 of 188 with model SectionalMotif for Validation 3\n",
            "130 - SectionalMotif with avg smape 11.38: \n",
            "Model Number: 131 of 188 with model ConstantNaive for Validation 3\n",
            "131 - ConstantNaive with avg smape 11.38: \n",
            "Model Number: 132 of 188 with model ConstantNaive for Validation 3\n",
            "132 - ConstantNaive with avg smape 11.38: \n",
            "Model Number: 133 of 188 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n",
            "/usr/local/lib/python3.9/dist-packages/autots/tools/thresholding.py:321: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  if (E_seq_max_sorted[i] - E_seq_max_sorted[i + 1]) / E_seq_max_sorted[\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133 - UnobservedComponents with avg smape 12.11: \n",
            "Model Number: 134 of 188 with model ConstantNaive for Validation 3\n",
            "134 - ConstantNaive with avg smape 11.41: \n",
            "Model Number: 135 of 188 with model UnobservedComponents for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/decomposition/_fastica.py:708: FutureWarning: Starting in v1.3, whiten=True should be specified as whiten='arbitrary-variance' (its current behaviour). This behavior is deprecated in 1.1 and will raise ValueError in 1.3.\n",
            "  return self._fit_transform(X, compute_sources=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "135 - UnobservedComponents with avg smape 12.18: \n",
            "Model Number: 136 of 188 with model UnobservedComponents for Validation 3\n",
            "136 - UnobservedComponents with avg smape 12.18: \n",
            "Model Number: 137 of 188 with model UnobservedComponents for Validation 3\n",
            "137 - UnobservedComponents with avg smape 12.62: \n",
            "Model Number: 138 of 188 with model SectionalMotif for Validation 3\n",
            "138 - SectionalMotif with avg smape 9.84: \n",
            "Model Number: 139 of 188 with model AverageValueNaive for Validation 3\n",
            "139 - AverageValueNaive with avg smape 11.79: \n",
            "Model Number: 140 of 188 with model AverageValueNaive for Validation 3\n",
            "140 - AverageValueNaive with avg smape 11.65: \n",
            "Model Number: 141 of 188 with model AverageValueNaive for Validation 3\n",
            "141 - AverageValueNaive with avg smape 11.97: \n",
            "Model Number: 142 of 188 with model GLS for Validation 3\n",
            "142 - GLS with avg smape 12.27: \n",
            "Model Number: 143 of 188 with model GLS for Validation 3\n",
            "143 - GLS with avg smape 12.46: \n",
            "Model Number: 144 of 188 with model GLS for Validation 3\n",
            "144 - GLS with avg smape 12.35: \n",
            "Model Number: 145 of 188 with model GLS for Validation 3\n",
            "145 - GLS with avg smape 12.35: \n",
            "Model Number: 146 of 188 with model AverageValueNaive for Validation 3\n",
            "146 - AverageValueNaive with avg smape 13.85: \n",
            "Model Number: 147 of 188 with model SectionalMotif for Validation 3\n",
            "147 - SectionalMotif with avg smape 10.48: \n",
            "Model Number: 148 of 188 with model SeasonalNaive for Validation 3\n",
            "148 - SeasonalNaive with avg smape 14.26: \n",
            "Model Number: 149 of 188 with model WindowRegression for Validation 3\n",
            "149 - WindowRegression with avg smape 12.88: \n",
            "Model Number: 150 of 188 with model GLS for Validation 3\n",
            "150 - GLS with avg smape 12.3: \n",
            "Model Number: 151 of 188 with model SeasonalNaive for Validation 3\n",
            "151 - SeasonalNaive with avg smape 14.79: \n",
            "Model Number: 152 of 188 with model SeasonalNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:541: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/tz7gs3_g.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152 - SeasonalNaive with avg smape 14.79: \n",
            "Model Number: 153 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/hfz2v8r9.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=99882', 'data', 'file=/tmp/tmp2xi3y8fj/tz7gs3_g.json', 'init=/tmp/tmp2xi3y8fj/hfz2v8r9.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model0q96v22l/prophet_model-20230410133938.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:38 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:39:38 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153 - FBProphet with avg smape 21.51: \n",
            "Model Number: 154 of 188 with model NVAR for Validation 3\n",
            "154 - NVAR with avg smape 12.47: \n",
            "Model Number: 155 of 188 with model WindowRegression for Validation 3\n",
            "155 - WindowRegression with avg smape 14.6: \n",
            "Model Number: 156 of 188 with model SeasonalNaive for Validation 3\n",
            "156 - SeasonalNaive with avg smape 14.26: \n",
            "Model Number: 157 of 188 with model SeasonalNaive for Validation 3\n",
            "157 - SeasonalNaive with avg smape 14.32: \n",
            "Model Number: 158 of 188 with model SeasonalNaive for Validation 3\n",
            "158 - SeasonalNaive with avg smape 14.32: \n",
            "Model Number: 159 of 188 with model AverageValueNaive for Validation 3\n",
            "159 - AverageValueNaive with avg smape 13.38: \n",
            "Model Number: 160 of 188 with model SeasonalNaive for Validation 3\n",
            "160 - SeasonalNaive with avg smape 10.96: \n",
            "Model Number: 161 of 188 with model GLS for Validation 3\n",
            "161 - GLS with avg smape 15.33: \n",
            "Model Number: 162 of 188 with model AverageValueNaive for Validation 3\n",
            "162 - AverageValueNaive with avg smape 15.51: \n",
            "Model Number: 163 of 188 with model SeasonalNaive for Validation 3\n",
            "163 - SeasonalNaive with avg smape 15.38: \n",
            "Model Number: 164 of 188 with model NVAR for Validation 3\n",
            "164 - NVAR with avg smape 14.02: \n",
            "Model Number: 165 of 188 with model SectionalMotif for Validation 3\n",
            "165 - SectionalMotif with avg smape 11.75: \n",
            "Model Number: 166 of 188 with model SeasonalNaive for Validation 3\n",
            "166 - SeasonalNaive with avg smape 11.14: \n",
            "Model Number: 167 of 188 with model NVAR for Validation 3\n",
            "167 - NVAR with avg smape 13.25: \n",
            "Model Number: 168 of 188 with model ConstantNaive for Validation 3\n",
            "168 - ConstantNaive with avg smape 12.49: \n",
            "Model Number: 169 of 188 with model GLS for Validation 3\n",
            "169 - GLS with avg smape 12.99: \n",
            "Model Number: 170 of 188 with model SectionalMotif for Validation 3\n",
            "170 - SectionalMotif with avg smape 12.98: \n",
            "Model Number: 171 of 188 with model ConstantNaive for Validation 3\n",
            "171 - ConstantNaive with avg smape 13.03: \n",
            "Model Number: 172 of 188 with model NVAR for Validation 3\n",
            "172 - NVAR with avg smape 14.0: \n",
            "Model Number: 173 of 188 with model ConstantNaive for Validation 3\n",
            "173 - ConstantNaive with avg smape 13.13: \n",
            "Model Number: 174 of 188 with model ConstantNaive for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "174 - ConstantNaive with avg smape 13.13: \n",
            "Model Number: 175 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/p94bm0gm.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/oazfd4hg.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=65130', 'data', 'file=/tmp/tmp2xi3y8fj/p94bm0gm.json', 'init=/tmp/tmp2xi3y8fj/oazfd4hg.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelj9ps8ik0/prophet_model-20230410133939.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:39 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "13:39:39 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175 - FBProphet with avg smape 21.96: \n",
            "Model Number: 176 of 188 with model NVAR for Validation 3\n",
            "176 - NVAR with avg smape 14.36: \n",
            "Model Number: 177 of 188 with model NVAR for Validation 3\n",
            "177 - NVAR with avg smape 13.23: \n",
            "Model Number: 178 of 188 with model NVAR for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/5ehxlnwn.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/glbyd5xm.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=21469', 'data', 'file=/tmp/tmp2xi3y8fj/5ehxlnwn.json', 'init=/tmp/tmp2xi3y8fj/glbyd5xm.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_models3df9t1e/prophet_model-20230410133940.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:40 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 - NVAR with avg smape 13.23: \n",
            "Model Number: 179 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:42 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/ryhv73t6.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/9wsz8j_o.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=97485', 'data', 'file=/tmp/tmp2xi3y8fj/ryhv73t6.json', 'init=/tmp/tmp2xi3y8fj/9wsz8j_o.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelg_j19xlh/prophet_model-20230410133942.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:42 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179 - FBProphet with avg smape 14.04: \n",
            "Model Number: 180 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:43 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/mwg3vmik.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/fpgiorx1.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=25907', 'data', 'file=/tmp/tmp2xi3y8fj/mwg3vmik.json', 'init=/tmp/tmp2xi3y8fj/fpgiorx1.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model4rbf0n5a/prophet_model-20230410133943.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:43 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180 - FBProphet with avg smape 14.47: \n",
            "Model Number: 181 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:43 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "181 - FBProphet with avg smape 14.47: \n",
            "Model Number: 182 of 188 with model NVAR for Validation 3\n",
            "182 - NVAR with avg smape 14.98: \n",
            "Model Number: 183 of 188 with model NVAR for Validation 3\n",
            "183 - NVAR with avg smape 55.49: \n",
            "Model Number: 184 of 188 with model GLS for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/hycqp1wo.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/o26xgxix.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=12806', 'data', 'file=/tmp/tmp2xi3y8fj/hycqp1wo.json', 'init=/tmp/tmp2xi3y8fj/o26xgxix.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_model03u729m6/prophet_model-20230410133944.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:44 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "184 - GLS with avg smape 18.58: \n",
            "Model Number: 185 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:44 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/cc21ra67.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/rr842on4.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=62774', 'data', 'file=/tmp/tmp2xi3y8fj/cc21ra67.json', 'init=/tmp/tmp2xi3y8fj/rr842on4.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelvvt1wpec/prophet_model-20230410133944.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:44 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "185 - FBProphet with avg smape 96.52: \n",
            "Model Number: 186 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:45 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/sfj04h5x.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/5ddh565i.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=68275', 'data', 'file=/tmp/tmp2xi3y8fj/sfj04h5x.json', 'init=/tmp/tmp2xi3y8fj/5ddh565i.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelnhp4hq8a/prophet_model-20230410133945.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:45 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "186 - FBProphet with avg smape 15.97: \n",
            "Model Number: 187 of 188 with model FBProphet for Validation 3\n",
            "No anomalies detected.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:45 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n",
            "INFO:prophet:Disabling weekly seasonality. Run prophet with weekly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/vdssn_ze.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmp2xi3y8fj/1erntvgn.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.9/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=18776', 'data', 'file=/tmp/tmp2xi3y8fj/vdssn_ze.json', 'init=/tmp/tmp2xi3y8fj/1erntvgn.json', 'output', 'file=/tmp/tmp2xi3y8fj/prophet_modelxm5micas/prophet_model-20230410133946.csv', 'method=optimize', 'algorithm=newton', 'iter=10000']\n",
            "13:39:46 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "187 - FBProphet with avg smape 18.94: \n",
            "Model Number: 188 of 188 with model FBProphet for Validation 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "13:39:47 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "188 - FBProphet with avg smape 20.76: \n",
            "Model Number: 1834 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1835 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1836 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1837 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1838 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1839 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1840 with model Ensemble in generation 12 of Ensembles\n",
            "Model Number: 1841 with model Ensemble in generation 12 of Ensembles\n",
            "Validation Round: 1\n",
            "Model Number: 1 of 8 with model Ensemble for Validation 1\n",
            "📈 1 - Ensemble with avg smape 4.89: \n",
            "Model Number: 2 of 8 with model Ensemble for Validation 1\n",
            "2 - Ensemble with avg smape 4.91: \n",
            "Model Number: 3 of 8 with model Ensemble for Validation 1\n",
            "📈 3 - Ensemble with avg smape 3.67: \n",
            "Model Number: 4 of 8 with model Ensemble for Validation 1\n",
            "4 - Ensemble with avg smape 5.1: \n",
            "Model Number: 5 of 8 with model Ensemble for Validation 1\n",
            "5 - Ensemble with avg smape 4.74: \n",
            "Model Number: 6 of 8 with model Ensemble for Validation 1\n",
            "6 - Ensemble with avg smape 5.76: \n",
            "Model Number: 7 of 8 with model Ensemble for Validation 1\n",
            "7 - Ensemble with avg smape 4.82: \n",
            "Model Number: 8 of 8 with model Ensemble for Validation 1\n",
            "8 - Ensemble with avg smape 4.74: \n",
            "Validation Round: 2\n",
            "Model Number: 1 of 8 with model Ensemble for Validation 2\n",
            "📈 1 - Ensemble with avg smape 6.97: \n",
            "Model Number: 2 of 8 with model Ensemble for Validation 2\n",
            "📈 2 - Ensemble with avg smape 6.95: \n",
            "Model Number: 3 of 8 with model Ensemble for Validation 2\n",
            "📈 3 - Ensemble with avg smape 6.81: \n",
            "Model Number: 4 of 8 with model Ensemble for Validation 2\n",
            "📈 4 - Ensemble with avg smape 6.57: \n",
            "Model Number: 5 of 8 with model Ensemble for Validation 2\n",
            "📈 5 - Ensemble with avg smape 6.49: \n",
            "Model Number: 6 of 8 with model Ensemble for Validation 2\n",
            "📈 6 - Ensemble with avg smape 6.14: \n",
            "Model Number: 7 of 8 with model Ensemble for Validation 2\n",
            "7 - Ensemble with avg smape 6.51: \n",
            "Model Number: 8 of 8 with model Ensemble for Validation 2\n",
            "8 - Ensemble with avg smape 6.49: \n",
            "Validation Round: 3\n",
            "Model Number: 1 of 8 with model Ensemble for Validation 3\n",
            "📈 1 - Ensemble with avg smape 2.76: \n",
            "Model Number: 2 of 8 with model Ensemble for Validation 3\n",
            "2 - Ensemble with avg smape 2.77: \n",
            "Model Number: 3 of 8 with model Ensemble for Validation 3\n",
            "3 - Ensemble with avg smape 2.77: \n",
            "Model Number: 4 of 8 with model Ensemble for Validation 3\n",
            "4 - Ensemble with avg smape 2.89: \n",
            "Model Number: 5 of 8 with model Ensemble for Validation 3\n",
            "📈 5 - Ensemble with avg smape 2.51: \n",
            "Model Number: 6 of 8 with model Ensemble for Validation 3\n",
            "6 - Ensemble with avg smape 3.1: \n",
            "Model Number: 7 of 8 with model Ensemble for Validation 3\n",
            "7 - Ensemble with avg smape 2.51: \n",
            "Model Number: 8 of 8 with model Ensemble for Validation 3\n",
            "8 - Ensemble with avg smape 2.51: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict()\n",
        "forecast = prediction.forecast\n",
        "print(\"Passengers Forecast\")\n",
        "print(forecast)"
      ],
      "metadata": {
        "id": "gMrB2n4OYiZ0",
        "outputId": "26cae651-ca25-4395-e8be-c0b292f692f2",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:41:10.812799Z",
          "iopub.execute_input": "2022-05-05T08:41:10.813179Z",
          "iopub.status.idle": "2022-05-05T08:41:11.141821Z",
          "shell.execute_reply.started": "2022-05-05T08:41:10.813147Z",
          "shell.execute_reply": "2022-05-05T08:41:11.140945Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passengers Forecast\n",
            "            #Passengers\n",
            "1961-01-01   441.999230\n",
            "1961-02-01   428.043743\n",
            "1961-03-01   478.928019\n",
            "1961-04-01   495.014765\n",
            "1961-05-01   505.714379\n",
            "1961-06-01   571.381871\n",
            "1961-07-01   650.846993\n",
            "1961-08-01   636.514429\n",
            "1961-09-01   560.433543\n",
            "1961-10-01   501.240366\n",
            "1961-11-01   441.087516\n",
            "1961-12-01   489.691034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_air=data.set_index('month')\n",
        "plt.plot(np.arange(144), data_air)\n",
        "plt.plot(np.arange(144, 144+12), forecast)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yhslxHrMYxbj",
        "outputId": "460812dd-e539-48df-b419-b244553646a1",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:41:11.143423Z",
          "iopub.execute_input": "2022-05-05T08:41:11.143734Z",
          "iopub.status.idle": "2022-05-05T08:41:11.332957Z",
          "shell.execute_reply.started": "2022-05-05T08:41:11.143693Z",
          "shell.execute_reply": "2022-05-05T08:41:11.332083Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAGdCAYAAADey0OaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3OUlEQVR4nO3deXxcdb0//teZPctM1mZrk3Sn+0JbSiiCQKVAEZBeFW7ZlCuKRQUUvfwuoKJXFhcUrSBeLsULCPKVRSpQSgst2D2ldF/olrTZt5lss5/fH2c+Z2aSSTIzmTPJJK/n45FHkpmTOecEzbz7/rzf748ky7IMIiIiomFON9QXQERERBQNBi1ERESUEhi0EBERUUpg0EJEREQpgUELERERpQQGLURERJQSGLQQERFRSmDQQkRERCnBMNQXEA+/34+amhpYrVZIkjTUl0NERERRkGUZ7e3tKCkpgU4Xe94kJYOWmpoalJaWDvVlEBERURyqq6sxbty4mH8uJYMWq9UKQLlpm802xFdDRERE0XA4HCgtLVXfx2OVkkGLWBKy2WwMWoiIiFJMvKUdLMQlIiKilMCghYiIiFICgxYiIiJKCQxaiIiIKCUwaCEiIqKUwKCFiIiIUgKDFiIiIkoJDFqIiIgoJTBoISIiopTAoIWIiIhSAoMWIiIiSgkMWoiIiCglMGghIiIaiY6+Bxx5d6ivIqFScpdnIiIi6oenG/jbzYDPDXxvL5BdOtRXlBDMtBAREY003W2A1wnIfuDQP4b6ahKGQQsREdFI47QHvz745tBdR4IxaCEiIhppXI7g19XbAfvZobuWBGLQQkRENNI4HeHfj5AlIgYtREREI43LHv79CFkiYtBCREQ00oialuK5yueqbYCjduiuJ0EYtBAREY00YnlozHRg3HkA5BGxRMSghYiIaKQRhbiWLGDGtcrXB94YsstJFAYtREREI43ItFhswNQrlK/PVg7d9SQIgxYiIqKRRtS0mG1AZoHytc8FeJxDd00JwKCFiIhopHGFZFpMmYAUeLt32vv+mRTAoIWIiGikcYbUtOh0SsYFYNBCREREw4zItIhgxcKghYiIiIYjEZxYssI/M2ghIiKiYSV0eQgALNmBx9uG4moShkELERHRSOL3R1geYqaFiIiIQjy96Th+9P/2wuvzD91FuDsAyMrXFgYtREREFMHv3j+GV3ZVY8vx5qG7CBGY6IyAwaJ8LYIWlyPyz6QIBi1EREQJ4PH50e3xAQA2Hm4YugsJHeEvScGvAWZaiIiICOh0edWvNxyuhyzLQ3MhoSP8BQYtREREJLQ7g0FLdUs3jjd2DM2F9CzCBRi0EBERUVBHSKYFGMIlImZaiIiIqD89g5YNh4YqaGlTPotAJfRrBi1ERETUEVgeys80AQB2nW6FvcuT/AtRl4cYtBAREVEE7YFMy5QCK6YUZMLnl7H5WGPyL4TLQ0RERNQfkWnJtBhw6fQCAENU19JfIa7XCXicyb+mBGHQQkRElAAdLmUpyGo24LJphQCAD440wO9Pcutzz80SAcBkBRCY2ZLCA+ZiDlrOnj2Lm266CXl5eUhLS8Ps2bOxa9cu9XlZlvHQQw+huLgYaWlpWLp0KY4dOxb2Gi0tLVi5ciVsNhuys7Nx++23o6NjiFrDiIiIEiA00zKvNBsA0NblgcOZ5LqWSMtDOl3w+xReIoopaGltbcWSJUtgNBrxzjvv4ODBg/j1r3+NnJwc9ZjHH38cTz75JJ5++mls374dGRkZWLZsGZzOYDpq5cqVOHDgANavX4+1a9di8+bNuOOOOxJ3V0REREkmaloyzQaYDDqYDMpbbKfbl9wLibQ8BAQLc1M4aDHEcvBjjz2G0tJSPPfcc+pjEyZMUL+WZRm//e1v8cADD+Daa68FAPzlL39BYWEh3njjDdxwww04dOgQ3n33XezcuRMLFy4EAPz+97/HVVddhV/96lcoKSlJxH0RERElVWimBVCClxavO2xSblJEyrQAynKRHcGW6BQUU6blH//4BxYuXIgvf/nLKCgowPz58/HnP/9Zff7kyZOoq6vD0qVL1ceysrKwePFibN26FQCwdetWZGdnqwELACxduhQ6nQ7bt2+PeF6XywWHwxH2QURENJyIOS1WsxK0pJv0ADAEQUuEmpbQ71M40xJT0HLixAk89dRTmDJlCtatW4c777wT3/3ud/H8888DAOrq6gAAhYWFYT9XWFioPldXV4eCgoKw5w0GA3Jzc9VjenrkkUeQlZWlfpSWlsZy2URERJoTQYvItGSYlM+drmGyPDTagha/349zzz0Xv/jFLzB//nzccccd+MY3voGnn35aq+sDANx///2w2+3qR3V1tabnIyIiipXYeyjTbAQAZJgDmRZ3EjMtfh/gDjS2jPZMS3FxMWbMmBH22PTp01FVVQUAKCoqAgDU19eHHVNfX68+V1RUhIaG8L51r9eLlpYW9ZiezGYzbDZb2AcREdFw0hFSiAsAGYHPXckMWkLbmUd7pmXJkiU4cuRI2GNHjx5FeXk5AKUot6ioCBs2bFCfdzgc2L59OyoqKgAAFRUVaGtrQ2VlpXrMxo0b4ff7sXjx4rhvhIiIaCiJ2hWrJbympSOZy0MiIDGkAQZT+HNq0JK6daExdQ/dc889uOCCC/CLX/wCX/nKV7Bjxw4888wzeOaZZwAAkiTh7rvvxs9//nNMmTIFEyZMwIMPPoiSkhJcd911AJTMzBVXXKEuK3k8Htx111244YYb2DlEREQpS+0e6plpSWYhbl+dQ8CIyLTEFLQsWrQIr7/+Ou6//348/PDDmDBhAn77299i5cqV6jE//OEP0dnZiTvuuANtbW248MIL8e6778JisajHvPjii7jrrrtw2WWXQafTYcWKFXjyyScTd1dERERJ5PfL6HD3UYibzDktfRXhAqMvaAGAq6++GldffXWfz0uShIcffhgPP/xwn8fk5ubipZdeivXUREREw1KXxwc5MK2/Z6YlqS3PIzzTwr2HiIiIBkksDRl0EsyBSbgZgZqWpBbi9jWjJfQxBi1ERESjl9gsMdNigCQpGxOmm4dgTssIXx5i0EJERDRI7T2KcJWvh2AiLpeHiIiIqD89Z7QAQLpaiJvMOS2BgKS/TIu3G/C6kndNCcSghYiIaJBETYuY0QIEJ+J2JbN7SM20ZPd+zmwDIIUfl2IYtBAREQ1Se4RMi2h57kjq8pAoxI2QadHpghmYFF0iYtBCREQ0SOpgOYtRfSw4XG6YFOICwWCGQQsREdHoFLmmZZgV4gIhxbhtSbmcRGPQQkRENEgdrt41LSKA6XR7IYvJc1oTmZZIc1pCH2emhYiIaHSK1PIs5rT4ZcDl9SfnQpz9dA8BDFqIiIhGu4jLQ0Z9r+c1118hLsCghYiIaLTrcAYn4go6naTWtSSlGNfTDXidytdpuZGPYdBCREQ0uolR/VZz+D7ESR0w19WifNYZALM18jEiaHFxTgsREdGopM5psYQHLUkd5d/dqnxOywEC+x/1wkwLERHR6KZumNhnpiUJy0OhQUtfGLQQERGNbh0RuoeAkFH+Scm0BJaH+qpnARi0EBERDRcenx8+f5JmogTIshzsHrL0DFqSOMo/lkxLd5vml6MFBi1ERDQi+P0ybnxmG5Y8uhHdSdyk0OX1w+NTAqVemZbA8lBSNk0Uhbjp/WVaspXPIsBJMQxaiIhoRPjwaAN2nW5FncOJ6taupJ03NIsighRBtDwPm0xLRr7yuasZSNaU3gRi0EJERCPCc/86pX6dzJ2VQ+tZdLrwrh1108RktDyrNS39BC3pecpn2ZeS+w8xaCEiopT3WUM7PjrWpH6fzJ2VI03DFTLUludkdA+1KZ/7C1oMZsAUmOEilpNSCIMWIiJKeWu2nAr7PpmZFnXfIUvvoEVteU7G9URT0xL6fGdT/8cNQwxaiIgopdm7Pfh75VkAQFaaEUCSlmMC+su0ZJqTWIgbTU0LEF7XkmIYtBARUUp7dVc1uj0+nFNoRcVEpWYjKZmNADFYzhox0xJYHkpKTYsIWgbKtATqWrqYaSEiIkqq13YrWZbblowPmYuSxJqWPgbLhT6meRAly9EV4gJAOjMtREREQ6KhXdnZeH5ZtrrXTzKXh9r7WR5KV4MWjYMoTxfgcwdOypoWIiKiYUeWZTi6laDBZjGqQcKQtDxHWB7KMCUpiBJFuHoTYEzv/1i1poXdQ0REREnj8vrh9vkBALY0Y/KWY0KIAMkaseU5SctV0ezwLLCmhYiIKPkc3UoRrE5SshoZauHrENS0RMy0JGm4XDSbJQqsaSEiIko+h1MJWmxpRkiSFFJDMhQtz8Zez6WrNTY++LXcyDHadmcgmGlhTQsREVHyOJzBehYgid06IUTQIqbfhgotzu3yaJj9iXawHMCaFiIioqEglofEjJSMZHXrhFBrWiIsD5kNOojtiLq0DKTUTEv2wMeKwMbdDnhdml2SFhi0EBFRyuqZaclI5jC3AHWMf4TlIUmS1LoWTTuaoh0sBwCWbEAKZIVSrK6FQQsREaUskWmxpQ1dpqWtS5mPkp3eO2gJvSZNR/nHUtMiSSlb18KghYiIUpZaiKtmWpJb0+Lzy2gLBE59BS3p6k7PSci0RFPTAoS0PTPTQkRElBTqYLnARomiGLbb44NPy24d9fweyIHTZKeZIh6jBlJaLll1RTnCX0jRTRMZtBARUcrqlWkJ7dZJQl1La2BpyGo2wGSI/JaaoWZakrE8FG2mJXAcgxYiIqLk6FnTYjbooA+06ySjrqW1K7A0lBF5aQhI0oC5aDdLFMSAOda0EBERJUfP7iGlW0fJbCRj/6HWTiXTkpMeeWkISMIof1lmTQsREdFwF8y0BDMdmeYkjc5HcHkou9+gJTAVV6sgytUO+AOvHXNNCzMtRERESRGsaQnWsiRzp+e2wPJQbh+dQwCQrhbiapRpEVkWgwUwpkX3M2qmJbWm4jJoISKilNWzewgImYuSlJqWaDItGrdhx7JZosA5LURERMkVumGikGlO3lRcEbT0W9Oi9ZTeWAbLCaxpISIiSh6nxwe31w+gx/JQMsbmB7R2KkFTTj/dQ5rvPB3LZolC6JwWvz/x16QRBi1ERJSSRJZFJwXbioGQQtwkLg/1l2kRmR/NxvjHslmiIDItsg9w2RN+SVph0EJERClJ1LNYLUboxFbKCHbrJLMQt7+gJV3rrQW625TPsdS0GMyAyap83Zk6S0QMWoiIKCW1O8MHywnJ3H+odYDNEsOvR6tMS4yD5YQUnIrLoIWIiFJSz8Fygtqto+WuygBkWQ4uD2UMPKdF80LcWGpagJTcf4hBCxERpSR1sFyPoCXdlIRdlaEERR6fsltibhQtz5rVtMS6WaKgdhClTtszgxYiIkpJjj6WhzK17tYJECP8zQYd0gKBUiTWQGeTo9sDvxY7T8e6WaKQPsIzLT/5yU8gSVLYx7Rp09TnnU4nVq1ahby8PGRmZmLFihWor68Pe42qqiosX74c6enpKCgowH333QevV/t1RyIi0sav3zuCFU9tQbfGyzE9hRbihgouD2n73hJNES4A5GeaIUmA1y+jJbCclDA+L9B2Wvk61uUhcXwKDZiLOdMyc+ZM1NbWqh8ff/yx+tw999yDt956C6+++io2bdqEmpoaXH/99erzPp8Py5cvh9vtxpYtW/D8889jzZo1eOihhxJzN0RElFStnW489eFxVJ5uxSfVrUk9d3CEf8+gRSwPaRtEtURRhAsARr0OeRlmAEC9w5nYizi8FuioV5Z6SubH9rNqTUvqjPI3DHxIjx8wGFBUVNTrcbvdjmeffRYvvfQSLr30UgDAc889h+nTp2Pbtm04//zz8d577+HgwYN4//33UVhYiHnz5uFnP/sZfvSjH+EnP/kJTKb+o1UiIhpe1h2ogzew5JH8TMsA3UOaZ1qUoCW3nyJcocBqRlOHCw3tLsxM5EVs+6PyeeHt0e87JIyGmpZjx46hpKQEEydOxMqVK1FVVQUAqKyshMfjwdKlS9Vjp02bhrKyMmzduhUAsHXrVsyePRuFhYXqMcuWLYPD4cCBAwf6PKfL5YLD4Qj7ICKioffPfbXq11p36/Q0YPdQkmpaBloeAoBCm5JpaUhkpuXMLqB6O6A3AYv+I/afFzUtI3V5aPHixVizZg3effddPPXUUzh58iQ+97nPob29HXV1dTCZTMjOzg77mcLCQtTV1QEA6urqwgIW8bx4ri+PPPIIsrKy1I/S0tJYLpuIiDTQ3OHCluPBIs6uJMxFCRXMtPQVtGgbRLUGaloGWh4CgEKbBQBQ73Al7gK2rlY+z/o3wFrY/7GRiExL9whdHrryyivVr+fMmYPFixejvLwcf/vb35CWFmNaKgb3338/7r33XvV7h8PBwIWIaIi9s78OvpBumORnWkRNS4/loZC5KLIsQ5KkXj+bCNGM8BcK1KAlQZmWtmrg4JvK1xXfju811OWh1AlaBtXynJ2djalTp+Kzzz5DUVER3G432trawo6pr69Xa2CKiop6dROJ7yPVyQhmsxk2my3sg4iIhtY/9ypLQ4bACP3hkmkRLc+yDHR7tAukRKalv8FyQoFVFOImKNOy4xll36AJFwFFs+N7DdE95HIA3gRmgDQ0qKClo6MDx48fR3FxMRYsWACj0YgNGzaozx85cgRVVVWoqKgAAFRUVGDfvn1oaGhQj1m/fj1sNhtmzJgxmEshIqIkamh3YvtJZWnosukFAIZPTUuaUQ+RXNFy/6E2NdMS/fJQQ3sCMi2yDOz/u/L14m/F/zqWbEAKzJdJkWxLTEHLD37wA2zatAmnTp3Cli1b8KUvfQl6vR433ngjsrKycPvtt+Pee+/FBx98gMrKSnzta19DRUUFzj//fADA5ZdfjhkzZuDmm2/Gp59+inXr1uGBBx7AqlWrYDabNblBIiJKvHf318EvA/NKs3FOobLxXpfG3To99dU9JEmS2kGk5U7PsSwPBQtxE5DRqN8POM4CxnRg0mXxv45Ol3L7D8VU03LmzBnceOONaG5uxpgxY3DhhRdi27ZtGDNmDADgiSeegE6nw4oVK+ByubBs2TL88Y9/VH9er9dj7dq1uPPOO1FRUYGMjAzceuutePjhhxN7V0REpKn3DykZ86vnFKstz1oXvoZyenxwef0Aei8PAcoo/w6XV9NMS2tn7IW4jR0u+Pwy9LpB1NkcXad8nnAxYLTE/zqAUtfS2RgetJz4UDlHWQUw45rBvX6CxRS0vPzyy/0+b7FYsHr1aqxevbrPY8rLy/H222/HcloiIhpmatq6AQAzSmw43tABILmZlvbA0pAkAZmm3m9lmWYDGtpdmrY9t8YwpyUvwwSdBPj8Mpo7XSiwDiLYEEHL1GXxv4agFuOGBC1V25T5L+7OYRe0cO8hIiKKWXOHssyRn2lGuik5uyqHEp1DVrMBughZC603KXR5feprZ0exPGTQ65CXmYAlos5m4MxO5espl8f/OkKk5aH2wAgSa98NMkOFQQsREcXE6/OjLVBPkpthUluMk9k9JDItkZaGgOBOz1otD4l9h/Q6qVfLdV9EXcug2p4/ex+ADBTOBrLGxv86QqRMS0egyzczjtkvGmPQQkREMWnt8kCWlaWZnHTT0GRauiPvOyRkqpkWbYIWsTSUnWaMeg5MoVV0EA0i03L0XeXz1ARkWYDIQQszLURENFI0dypvurnpJuh1UjDTksSaFnWwXFrkLIdYHurQqDi4pTO6zRJDDXrAnM8DHA+MFZl6RXyv0VO/mRYGLURElOJaOsILUNVMSxK7hxzdkWe0CMGdnrVdHoqmCFcILg/FmWmp3g447UqgMXZBfK/Rk9h/SAQtfn8waIlnawCNMWghIqKYNAWyDHmZyhu2OhNlSDItfQQtGu/0rC4PRVGEK4iOobg3TRRdQ5OXAjp9fK/RU89MS3cL4A/8zjIKEnOOBGLQQkREMRGdQ3kZSuYgXV0e8sEfsheRlgaqadF6p2eRaYlmGq6gZlrinYrbcFD5XL4kvp+PRO0eCkzEFfUs6XmAIfqALFkYtBARUUxa+si0ANru9RNq4JoWsTykbU1LNNNwBXWUf7zLQ2LZxlYS389HEpppkWWgIxC0DMN6FoBBCxERxagpUNMiMi0Wo07d60er5ZieRE2LdYgyLeoI/xhqWgoCmZamDhe8Pn/sJ+0I7NuXmcBlGxG0eJ3KMLn24VvPAjBoISKiGLWI7qFApiVZe/2EUjMtfcxI0bqmJZ7lobwMM/Q6CX4ZaA5kaqLm9ynj9oHEzk8xZQD6wN5/Xc3MtBAR0cjSHMi05IdkGcQwt2RlWkTQkNVXIa6GLc8enx/7z9oBBJd8oqHXScgPBHoxtz13tQCyH4AU7PhJBEkCMkI6iJhpISKikaRZrWkxq49pPTa/pyaxjYDVHPF5Laf0vrO/Dg3tLoyxmnHBpNgCiEJ1VkuMdS2iniU9D9DHtG3gwEKLcZlpISKiRHJ6fHht9xn89v2jcCap8DWU6B7KjZRpScIof1mW1aBlTGYfQYtJu5qWNf86CQC4aXE5TIbY3kbVtudYO4i0HK0fWow7zDMtCQ7XiIhIK/YuD5756Dhe3lGtZjtmFNtw+czk/avY7fXDEdj3Ryx1AKGzWrQPojpcXjg9/sA19JVp0WZrgU+r27C7qg0mvQ7/vrgs5p+Pe8CcFkW4QmjQMswzLQxaiIhSxM//eRCvVp4Je6yxYxD72MRBtPoqGwUG60nSNZ5AG0p0L2WaDUgzRR6ylhnSPSTLctT7Aw1kzZZTAICr5xZjTB9LU/2Je8BcUjItTcM+08LlISKiFHGiqRMA8P0vTMX15yo7/IqC1GRR9x3KMEGnCwYCycy0qPUsmX23G4sgyuuX4fLG0V4cQUO7E2v31gAAvnbBhLheI+6dnpORaWk9BXi7A+cZnpkWBi1ERCmizq680V04JV+t5WiNtXV2kJrVGS3hAUMyu4ca20XQ0nemI9NkgD4QVNm7ExPYvbyjGh6fjAXlOZg9Liuu14i7ELczCUFLfWDirtkGmNITf54EYNBCRJQCfH4ZdYF/nRdnpal73rR0JTloCWRa8npkOdTuoSTMaVGLcPtZntHpJLVQuClBS2g7Tymj7kWWKx4i0BK/x6glY3mo+Zh250gQBi1ERCmgqcMFn1+GXidhjNWsDjVL+vJQj2m4QjIzLU1RZFqAYDZIXPNg1QYyXePzMuJ+DTFXJubsTzKWh8RGidbhuTQEMGghIkoJ4g2zwKpMVRWZltakZ1rC9x0SkplpaeyIMmgJXGNLApbQZFlGbZtS71GcFf1AuZ5E0OL0+OHyxvC7SkamRdAiMEoQBi1ERCmgzq68YRYF3jDF0kfyMy1ih+ehrGkJTOS19r/vT25GcK+fwXI4vWr7dHFWWtyvY7UY1H2aos62eF1Ad6vydVKCFmZaiIhoEGralExLSeANUywPJSKLEIuWCNNwgaHpHuprsJwgAqtE/I5qA0FjTrqxzzbraOh0EqyBrJQj2qBF7DmkMwKW7LjP3ScxEVcYpu3OAIMWIqKUIIpwRaZFLA85nB74/HLSrkPMSMntmWlJ4pwWtXtogDkpoiU6ETUtYnmuaBBZFiErPca6FlHPkjEG0Gnwtm0wAyZr8HtmWoiIaDDEm2axGrQob3yynLiW3miIrpeeM1KSlWmJZoS/IJaHYu7UiaBWzXTFX88ixFyMq2URrpARskTETAsREQ1Gz5oWo14Hq0UJFJJZjNsyxN1DHS6vOiwu2kLc5gQuDxVnDz5oyU5Triv6oEXDIlwhtK6FmRYiIhqMnpkWAMgRHURJqmtxenxqMWruEHUPiaWh/kb4C4lcHhI1RYMpwhXUTEu0RdTJyLSkM9NCREQJ4PfL6tj30DdNUYzbmqQOIpGxMOl1ajGpkKxMi6ip6W+Ev6AuDyWge0hkWkoSkGmxqctDUf6ukplp0Zu1KfZNEAYtRETDXFOnCx6fDJ0UPgU22bNa1HbnTFOvDQjVTIvbB1nWrjBYZFqi2axQLA91un1wegaXAQpmuhKXaWnr7uO/m88DHFsPNB9Xvk9m0GItBBK0uaQWGLQQEQ1zYs+hMVYzjPrgn+3grJZkBS2RO4eAYKbFl8ANCiNpinKwHABYzQYY9cob8GDqWmRZRk0CBssJAxbivnU38OK/Abv+V/letDxnjhn0ufsk2p6HcT0LwKCFiGjY66vdNlud1ZLc5aGeM1oAIN0UXC7SsoMolqBFkiS1YHgwS0RtXR41ECtKYNDS55yWc65QPh94A/D7k5NpyZ2kfM6fqt05EsAw8CFERDSURKal2Bb+hikKcZOXaYk8DRcA9DoJFqMOTo8fnS5vxGxMIsSyPAQoS0R1DuegMi01gXqW/EwTzIb4B8sJA2ZaJn9BmZviOAOc2RlSiKth0DLtauDGV4DS87Q7RwIw00JENMzV9Gh3FoKFuEkKWkSmpY+AJBmzWmLJtADBpazBdBDVJrBzCIgiaDFagGlXKV9/8n+Au0P5WsvuIb1ByfD0nI47zDBoISIa5kSmpWfnSk6GKMRN0vJQR9/LQ0DIVFwNO4gaY+geUo5TrrVlEAPm1BktCVgaAqIcLjfzeuXzvleVz8Z0wJSZkPOnMgYtRETDXF81Lcme0yIyOiLD05OaadFwVktTlCP8hbwEZFpq1KBRu0yLw+nBmdYueHyBIuZJlwLmLMCrnBuZBcO6qydZGLQQEQ1zdREGywHBQtxkZVrEm6x40+1J61ktsiyjMcoR/oIYgtc0qOUhbTItTo8fLq8S4G04VI8LH/sAt/7vDuUggwmYfnXwh7SsZ0khDFqIiIYxv19Wg5aifgpxtZyNIgwUtARntWgTtLS7vHAHuniiLcTNzxj88lCNmulKTNBitRjUpIn4nUacuCuWiABls0Ri0EJENJy1dLnh9vkhSUBhH0GL1y+jIwm7K4sWXdtAmRaNlodCR/hbjNF18SRi/6HgNNzELA/pdBJslvC254h1MxMvBtLE/BRmWgAGLUREw5rIsuRnmmEyhP/JTjPpYTEqj7UmYVbLgJkWk7aZlqYY252BwXcP+f0y6u3KeRO1PAT0rmtRO5RCi631RmD2vylfj5mWsHOnMs5pISIaxiJtlBgqJ92EWrsTrV1ulOWla3YdTo9PHbCW1Uchrto9pFGmJZZ9hwTRPdTc6YIsy722HxhIc2ffma7B6Bm0qMW+Pduqv/AzYOIlwOTLEnbuVMZMCxHRMFYnZrT08YaZrP2HxDKGTgIyTZH/vat1pqWxPZh1ipbItDg9/rjmx4hlm4IeWygMVs+gRfx3Lu65IaOY2WKI/p5HMgYtRETDWM2AmZbA5nsadxCJN1erxQidLnK2Qozy79RouJzItMSyPJQesoQWzxJRxALZBFCDli4Put0+tQMs0ecZaRi0EBENYwPVcYgBcy0az2oZqJ4FADICy0NdGhUFxzoNF+ix/1AcHUTBItzELQ0BwWJme7dXPUeGSQ+bhVUb/WHQQkQ0jLUFggWxDNRTMNMy9EGL1pmW6tYuAH0vlfVF7SCKI9OiDvazaZNpaet2hwwPtMRcczPaMGghIhrG7F0iaIkcLKhTcTVeHnI4Y8i0aFDTIssy9p91AABmlNhi+ll1Km4/mZbTzZ348tNb8O7+2rDHTzQq+/6UJ7jIObSmpaYtsS3VIxnzUEREw1hbt5IdyE6LnGlJViGuCJ6iyrRo0D10prUb9m4PjHoJUwpj24MnT+0g6vt39IeNn2HnqVYAwBWzitXHj9YrQcvUQmusl9wv8Xt0dHsG7BCjIGZaiIj60e704N39tcE9YZKsbYBMS25GsgpxlexJX4PlAKUmA9Am07L/rB0AcE6RFWZDdIPlhIH2H2p3erB2r5JhOVzbrk4X7nJ71SWpqTEGSgMJzbQEgxZmWgbCoIWIqB9PbzqOb72wGz/+x4Gkn1uW5ZCalsjBgsi0JKsQ15bWd4I+3axdpmV/jRK0zCrJivlnRU1LX7+jN/fUoNujXHO7y4szrcpyzWcNHZBlJejpa2freIUHLdoU+45EDFqIiPpxuLYdAPDXHVXYd8ae1HM7PX51r52+C3GD+w9pKaruIQ0zLfsC9SyzxsYRtAS6h0T3UU+v7KwO+/5QrXIurZaGgB5Bi0Zt1SMRgxYion6cDRRJyjLw0D/2w+/XfmNCQdSzGHSSGhD0lJOknZ6j6h4ya9M9JMsyDgSWh+IJWnL76R7af9aOfWftMOl1uOQcZVPCQ4FA9Vi98jnRS0NAMHNm7/agJtK+QxQRgxYion6cDSwV6HUSPqlqw993n0nauUPrWfpqhRVzWro9Pjg92rQaA1F2DwUCK7fXP+gaIJc3eC+1dieaO93Q6yRMK4o96xHc6bl30PLyzioAwOUzC7Fkcj6A0EyLErRM0SDTImqDnB4/2p1KZqqY3UMDGlTQ8uijj0KSJNx9993qY06nE6tWrUJeXh4yMzOxYsUK1NfXh/1cVVUVli9fjvT0dBQUFOC+++6D16v9DqVERLGwd3vQHhiU9p1LJwMAHnv3sPoGrrW2KDp2rGYDDIEJtVp2EDlimNMCIK6R+cIHhxsw/cF3seZfJwEEi3CnFGRGvbtzKFHT0tThCsuUdbm9ePOTGgDAjeeVYXqx0kp9uE775SGr2YDQONRqMSDTzIbegcQdtOzcuRN/+tOfMGfOnLDH77nnHrz11lt49dVXsWnTJtTU1OD6669Xn/f5fFi+fDncbje2bNmC559/HmvWrMFDDz0U/10QEWngTKBzJDfDhG9/fjImjslAU4cbb++tHeAnE0PUqfRVzwIoE1/FUoOWOz1HszxkMuhg1CvvxIOpa9l2ohl+GXji/WPocHnVoCWepSFAmSYsSYDXL4e1PW893ox2lxeluWmomJinZnFOt3ShweFUlwa1WB7S6STYLMHfZa+NEimiuIKWjo4OrFy5En/+85+Rk5OjPm632/Hss8/iN7/5DS699FIsWLAAzz33HLZs2YJt27YBAN577z0cPHgQL7zwAubNm4crr7wSP/vZz7B69Wq43doWkhERxUIsDY3NToPJoMMFk/IAQB0GpjW1c6ifQAEIHTCn3d/QaIIWAOob8WACKHEf9m4PXtp+GvtrlMzH7DiDFqNep47+r3c41cdFl9CskizodBLyMs0osJohy1BboAus5n6DxsEI/V322iiRIooraFm1ahWWL1+OpUuXhj1eWVkJj8cT9vi0adNQVlaGrVu3AgC2bt2K2bNno7CwUD1m2bJlcDgcOHAg+S2FRER9Ef/SHhuoNRiTqbyxNPbRhZJo6vJQH+3OQq468VWboMXjC+6QHJodiKQgMGK/vt3Z73H9CS0q/p+PTmLvmTYAwKyxsU3CDVVoU4KWOnvwukLH5wvTAktEb36qLBtpsTQkhAUtzLREJeYFtJdffhm7d+/Gzp07ez1XV1cHk8mE7OzssMcLCwtRV1enHhMasIjnxXORuFwuuFzBPxIOhyPWyyYiipmaaclR3lAKAm98DY4kBS2B7qGcAf6lH9xbR5vrElkWoP/hcgBQZDPjUC1Qb48/aAlt324IbBipk6DWnMSjyGbB/rMO1DlCg5beXTvTi63YfLQRn1a3AUhm0MJMSzRiyrRUV1fje9/7Hl588UVYLMn7BT/yyCPIyspSP0pLS5N2biIavXpnWpSgJVmZFnXfoQEChbx+umMSQRThWs0G6HX9b+gnshahwUGsRKblCzOC/8CdNCYzrNA3VoWBDFCDI1KmJZjlmF4UHhhpUc8iMGiJXUxBS2VlJRoaGnDuuefCYDDAYDBg06ZNePLJJ2EwGFBYWAi32422trawn6uvr0dRUREAoKioqFc3kfheHNPT/fffD7vdrn5UV1dHPI6IKJFE0DJuqDItA4zwF7ReHgpOw+3/OoBgcFA/iKBFZFq+dfEkdQ5NvPUsgtgZOjSYqouw50/PbI4W7c5C6O+TmyVGJ6ag5bLLLsO+ffuwZ88e9WPhwoVYuXKl+rXRaMSGDRvUnzly5AiqqqpQUVEBAKioqMC+ffvQ0NCgHrN+/XrYbDbMmDEj4nnNZjNsNlvYBxGR1nouD42xBierJmPInFgeyopyeailj711BivaIlwgJDiIc3lIlmU1WCvJtuD7l58DSQKunF08wE/2r1DNALnU80QKWiaOyYBJH3xrZKZleIkp12a1WjFr1qywxzIyMpCXl6c+fvvtt+Pee+9Fbm4ubDYbvvOd76CiogLnn38+AODyyy/HjBkzcPPNN+Pxxx9HXV0dHnjgAaxatQpmc2L3diAiile326dmLsZlpwOA2oHi9cto7XInfD+antqiXB4KZlq0rWmJJmjpGRzEqt3lhTcQEOakm3DT+eX46qJSGPWDm4UqgilRa9PS6Ybb54ckAQXWYMBg1OswuSATB2sdKMmywDpA4fFgsBA3dgmfiPvEE0/g6quvxooVK3DRRRehqKgIr732mvq8Xq/H2rVrodfrUVFRgZtuugm33HILHn744URfChFR3MTSUKbZoG4SaNTr1AAhGXUt9gE2SxRETYtWy0OOKDZLFIoGuTzUFmiVthh16iC5wQYsQO9aG1HPkp9phskQ/vpiiUjLpSEgGLTkpBuR1sc2DRRu0OP3Pvzww7DvLRYLVq9ejdWrV/f5M+Xl5Xj77bcHe2oiIs2EFuGGjtAvsJrR0ulGg8OFaZHL8BImmGmJcnlI45qWWJaHWjrdcHl9MBtiezMWM1oG6piKlai1sXd74PT41KAl0rLM5TML8ffdZ7B0RmGv5xJJ1OswyxI9zgwmIoqgZz2LMMZqxuG6djS2a5tpcXp86A7sJRTtnJa2Lg+8Pj8MCchMhHIE9saJJmjJTjfCZNDB7fWjweFCaW56TOdqjWIKcDxsFgPSjHp0e3yosztRF2h3FkFWqGUzi/Dpjy+HzaLtW+SFU/JxxcwifHFuiabnGUm4YSIRUQRn25QR/mOzewctQHB+iFZEdkMnKa3G/clJN6n72LRoMBXXHsUeSIIkSRE7daIVbR1PrCRJClsi6i/TAij32tcmlYlitRjx9M0LsHzO4IqMRxMGLUREEfSXaQGgeaYl2O5sgm6A2Sh6naQup2ixRBTL8hAwuA4idXkoI/EFsGIqbr3DGewcYqtxSmHQQkQUQc/BcoLoNGkYxJj6aKibJUYZKIglIi3anmOZ0wIE59nEU4zbGhKsJVpoMFUTYRouDX8MWoiIIhjyTEt3dPsOCVoOmIs1aBlMpqVNLcTVINMSsjwkri1STQsNXwxaiIh68Pj8aj3GuF6ZluQELdGO8BfyMrTbfyjm5aFBjPIXy2KJ7h4CwtuxgzUtXB5KJQxaiIh6qLM74ZcBk16nDpQTkpdpia2LRsu2Z0eMQctgRvlr1T0EBIOWw7XtcHn9AIDCLA41TSUMWoiIejgTWBoqybb0KoIVmZZ2lxfdbp9m19AWQ8cOAORqNGDO55fR7oq+5RlIVKYl8ctDBYGg5URTJwAgP9MU8xwZGloMWoiIelCLcHN6Lx1kmg2wGJU/nVpmW9qinIYriOWhRGda2p0e9etYu4fqHS7Icmx7NGmaaelRdNvzexr+GLQQEfVQGwhaSiLUO0iSlJQOophrWjJFTUtigxZRz5Ju0kc9Tl90D7m9fjVzEi1NMy1WM0JHrxTZWM+Sahi0EBH10BQoZhVvvj0lo64l1poWrTZNjLUIFwDMBr16PbEsEbm9fnQElqK0KMQ16nXqPk0A251TEYMWIqIemgJLLKFvcKHGZGo/FVetaYl6eUi5pkQvD6ntzjHudlwYx1RcEahJUvTt1bEqCim85fJQ6mHQQkTUgxjQJpZcehIZGE0zLTG2/qr7D3Ur+w8lSjyZFgAoEgPmYpjVElp8rB9gCnC8QueylGQzaEk1DFqIiHoQSywDZ1q0q2mJdSJuTroRkgTIcnCqbCI4upXlmlgzH/F0ELV2arPDc6jCkKCFNS2ph0ELEQ07fr+MvWfaEpoxiIVYYhmqTIvb60dnoJ062u4hg16nBjiJXCKKN9MSz6yW4Ah/bZaGgPBMC2taUg+DFiIadl775Cyu+cO/8OSGY0k/t88vB4OWjMhBi9Y7PYtAQZKUnYCjNdhiXFmWe7UoDzZoiWWUf3CEv4aZlpBAhTUtqYdBCxENO/vOtAEA1u6tTfq527rc8Afet3P6CFpEy7NWmRZ7oCDVZomttmMwxbgHauyY9uC7eHrTibDHjzd2AAgGatFS9x9yRP87SmamJSfdCIuRg+VSDYMWIhp2GgMtxyeaOlHd0pXUc4s3/Ox0Y59zScQbeFOHCz5/bMPTotEW55v3YGa1bDraCJfXj//56IS6LNft9uGjY40AgIunjonp9aJZHrJ3e3Dbczvw/yrPAEhOpmVeWTYm5mfg2nljNTsHaYdBCxENOw0h/zrfdLQxqeduCrzh5/aRZQGUZSNJAvyyNnv9tMU4WE4YzE7PosunudONbSdaACi/e6fHj3E5aZhebI3p9cTSS0unGy5v5O0O/rm3Fh8eacQv1x2GLMvqNFwtBssJNosRG3/wefzkmpmanYO0w6CFiIad0FqRzUkOWkQ9SH4fnUOAUvQq6l0Gu0T00bHGXjszixH+WTFmHIKj/GO/ptqQ2pN/7qsBALx3oA4AsGxmESQpthbknHQjTPr+tzvYd7YNgDLu/3hjZ8jykHaZFkptDFqIaFiRZTmslXjL8WZ4kthFNFDnkDAmAaP8d51qwc3P7sBXn9kGtzd4j7G2Owu5g9h/KHQZ5539dXB6fNhwuAGAErTESpKkAQuWP622q19vOd6UlOUhSm0MWohoWOlweeH0KG/gNosBHS4vdp9uTdr5o1keAhIzyl8UuX7W0IE1W04CAJweH17aUQUAKM9Lj+n18jJFrU3sQYvItEiSsjz1xPqjsHd7kJdhwoLynJhfDwDy+/kdOT0+HKlvV7//+FiTmmnRcnmIUhuDFiIaVsS/yjPNBlwyrQAAsPlY8paIxFKNCAD6UpCAtufQ4OJ37x9Dg8OJX607ghONnSiwmnH7hRNier14d3r2+Pxq8fOyGUpW5c8fKV1ES6cXxj2dtr/f0YEaB3x+GeKlt51oDimCZqaFImPQQkTDiijCLbCacdEUpWNl89GmpJ1fvHHmD7g8NPhMS2iXT6fbh2++UIln/6VkXB5dMTvmN+/czPiClsZ2F2QZMOgk3HJBOQCobd/LZhXG9FqhRNDSGKGDSLS1f27KGFgtBjicXvW6czKYaaHIGLQQ0bAiakTGWM343NR8AMC+s3Z152WtNUe5PFSQgKBF3NMX55ZAkoBPqtogy8BXFo7DpdNiDxbENbd2uWNqxRaj9gttFiyekKfeW4ZJjwsm5cd8HUKBWvfT+3e094xSzzK/LBvnT8wLe441LdQXBi1ENKyIIKDAZkGB1YLpxTYASs1DMgy075CQkExL4FyXThuDry4sBQCUZFnwwNUz4nq93MCbvbL/UPTZFjG1tijLAr1OwlWziwEAn59WMKgBbP39jj4NZFrmjsvGhZODgZHFqOPQN+qTYagvgIgolHiDE5sSVkzMw6FaB/adteO6+doPBGuOcnmoIAHdQyKrk5dhxn8tn44CqxlXzSmGLYbR/aEMeh1yM0xo6XSjweFC/gB1OUJtSNACAPd8YSqy0oy48byyuK5D6Kumpd3pwYmmTgDA7HFZKM0NblzILAv1h5kWIhpWGtRMi/KGNyFf6aA53az9ZFyPz68OdktG95AoxM3LNMFqMeLey8/BtCJb3K8HhI7P7476Z0S7s/jZrDQj7vnC1EHvzSP+G/YM7PafdUCWgbHZacjPNGPSmEwUBo5lES71h0ELEQ0r4g1O/Cu9NFcJWpIxzl8sqeikgd88xfV1un3odHljPpffL6tD4KLNiESjJFsJNGraos8AiUxLonc9Ftmopo7wGpu9gaWhOeOyACgzXZYEamdinU1DowuDFiIaVtSalsAbXnleBgCgqqWr1w7EiRZahDtQm2+G2YB0k1J7EU+2pa3bE9yYMYHZheIsZaml1h450+L2+vHsxyex42SL+pgY4S/2C0qUvExluwOfXw6rsRFFuHPGZauPXR4YYDe5IDOh10AjC2taiGhYEctDYvllbHYadBLQ7fGhsd2FggS/sYaKtnNIKLCacaq5Cw3tLozPz4jxXMp9ZqUZYTIk7t+PxYFMS22ETEtLpxvfeqESO062oDjLgi3/eSkkSUJtYCkp0ZkWo16H3HQTmnvU2OwNjO8XmRYAWDazEGu/cyGmFDJoob4x00JEw4bL61NrSsTyi8mgU7MHVRovEUXbOSQMpq4ltJ4lkUoCv6uaHpmWzxo68KU//kvNsNTanai1OyHLMurtyvUnOtMCIGSUvxJEtXS6Ud2iXNusscGgRZIkzBqbBbOBnUPUNwYtRDRsiDd/o15CdsgodzHOXuti3OYYA4nBdBBFszFjPES2pC5kA8Qutxc3PLMNp5u7MC4nDeNylMBmT3UbWjrdcAf2dtIiaBGZMfHf9kCNsjQ0Pi8dWaxfoRgxaCGiYSO03Tl0V2E1aNE406Julhjl8tBgMi2xBkjRKskWNS1OtQboUK0DTR0u5GWY8MaqJbhoqjJpeE91mzpYLj/TlNBlKkG0rotlvyN1yn5Dg+2SotGJQQsRDRtqPUuPf/Enq4NIXR6KsptnoF2M+z2XusdRYoOWQpsFkgS4vH41CDveoMxEmV5sQ36mGfNKswEAe6rawgbLaUG0PYvA7nAgaDmnyKrJ+WhkY9BCRMOGOqPFGh40lOcqRa6nmzs1PX+sdSaDqmnpDA6WSySTQacWvIpW5uNNym7SE8cov8dzy7IBKNsjnG1T6kuKNCpwLuhR0xLMtDBoodgxaCGiYUNsrNczaCkLZFqqWqIfmBaPWJeHBrPTs8i05FsTG7QAylYAAFATCEhONCrB3sRAh9PE/ExYLQZ0e3zYfFTZQVuzTIs1WNPi88s41sBMC8WPQQsRDRuNHeHtzkJZoKalqcMV1yC3aAWXbLTvHhI1LflRBkixEAGIyLScaFQyLZMCM1B0OglzAzNSNgf2dNIq0xK6hFbV0gWnxw+LUafO3yGKBYMWIho2Ghzhg+WErDSj2k2kZdtzrHNaxBtyc6cL3kAHTtTnElmdBE7DFYpD2p69Pr/6O5s4JjgDRdS1uL3KdRdlpUELajbK4cKROgcAYEqBdcDhfUSRMGghomGjr5oWIHSJSJugxeX1oT2QxYm2DTkvwwydpOyqLJaWotWkUSEuEBzlX2d3orq1Gx6fDItRh+KQbIoIWoRED5YTRCFut8eHytOtALg0RPFj0EJEw4a675Ctn6BFo1ktIugw6CTY0qIbFq7XSWqmJJa6FpfXh3ZnbAFSLNRR/m1OHG9QloYm5GdCF5LdmBcoxhW0mNECAOkmAzLNyu/zo8BSFItwKV4MWohoWPD7ZbV7p2dNCxA6q0WbDqLQpaHQGTEDKYijriWeACkW6qaJ9m6c6NE5JORnmtUhc4B2hbhA8L8n251psBi0ENGw0NKl7AQsSZF3Pda6gyjeGpOeY+qjOldIa3UsAVK0RKal3uHEZ4FMy6QIeyOJJSKrOZgN0ULPIPScQgYtFB8GLUQ0LIgi3Nx0E4z63n+aygKzWqoSMKtl4+F6HKtvD3vscK1SJJofY41JPJkWtZ5Fg6UhcU06CfD4ZOw8pdSRhBbhCiJo0TLLIq5HyEk3RsykEUWDQQsRDQsiU9HXG5poez7T2h1zp06oI3Xt+PqaXVj++4/x5p6zAID3D9bjl+uOAAAqJuXF9HrRTsVt7XSjI1Doq9UIf8Gg16k1KiebAjNaxvTOtCybWYTcDBOWzSzS5DqE0G6wc4qsmmSXaHTQLh9IRBQDdd+hPoKWIpsFJr0Obp8ftXanOto/VmK4mdvrx/de3oOPjzXhzU9r4PXL+NL8sfjWRZNier3Q4Wl9OdPahat+9xEKbRasu/ui4GaJGrQ7C8VZFnVOCxA501Kam47KB5ZqHkSE/jflnkM0GMy0ENGwUB+YhttXF4teJ2FcrlKrMZi2ZzElNicw9+XVyjNwe/24fEYhfvlvc8I6bKIRTabld+8fg8PpxbGGDuw63RrMtGgwWE4oDpm7Umgz91mzkoysR+jyEItwaTAYtBDRsCB2G+5vMqsoxj09iLbnmjblPF9dVIbHV8yBxajD0ukF+P2/z4chQi3NQAaqafmsoQN/331G/X7t3pqQPY60zbQIE/N7Z1mSKbSFnUELDQaXh4hoWKizK2/6hf0UhYqg5Uxr/EGL2CBwbLYFX1lUimvnl8Bs0Mf9eqHdQ7Is98pc/Gb9EfhlYGx2Gs62dePtfXWYXqy8cWtV0wIAxdnBTEukepZkCq1pmcrOIRoEZlqIaFiojyLTIuaKnGmNv+35bOBnxwZeazABCxAMWpwev1poK+w7Y8fb++ogScCfbl6ArDQjmjpc2H6iBUDsnUqxKAnNtESoZ0mmSWMycN6EXHxl4ThNW6tp5OP/eohoWIguaBl8pqXGrgQtJdmJ2WtHTHztcHnR0O6C1WJUn/vVe0pH0nXzxmLW2CxcMbMIr+yqhjvQ/aRVyzMwvDItBr0Of/tmxZBeA40MMWVannrqKcyZMwc2mw02mw0VFRV455131OedTidWrVqFvLw8ZGZmYsWKFaivrw97jaqqKixfvhzp6ekoKCjAfffdB69Xu11biWj48/r86uySwqy+38hLA0FLdZyZlk6XF21dHgCJC1qAYM1GXUi3jr3Lg01HGwEAdy+dAgBYPqc47Oe0XB4KzbRMGuKaFqJEiSloGTduHB599FFUVlZi165duPTSS3HttdfiwIEDAIB77rkHb731Fl599VVs2rQJNTU1uP7669Wf9/l8WL58OdxuN7Zs2YLnn38ea9aswUMPPZTYuyKiuJxt64bfLyf9vI0dLvhlZax9f3vxiOWhxnYXnB5fzOepDWRZrBYDbCEZkcEStTbVIV1NYruB/EwzyvOUTMcFk/LUriVA20zLGKsZ503IxaLxOWHj+olSWUxByxe/+EVcddVVmDJlCqZOnYr//u//RmZmJrZt2wa73Y5nn30Wv/nNb3DppZdiwYIFeO6557BlyxZs27YNAPDee+/h4MGDeOGFFzBv3jxceeWV+NnPfobVq1fD7Y5th1QiSqwtnzVhyaMbcf9r+5J+bpGhKLCa+205zk43IsOk1KCIgtpYiFqYsQnMsgAhXU2hQUugw0nsmQQoyyRXzFKyLRkmPdJMg6un6Y8kSXjljvPxt29WxNzGTTRcxV2I6/P58PLLL6OzsxMVFRWorKyEx+PB0qVL1WOmTZuGsrIybN26FQCwdetWzJ49G4WFheoxy5Ytg8PhULM1kbhcLjgcjrAPIkosMe79lV3VOFiT3P+PqTNaBhgnL0mSOlSuOo5ZLaLdOZFLQ0DkHajFLJnyHkPwrptXojyep32diSRJnD5LI0rMQcu+ffuQmZkJs9mMb33rW3j99dcxY8YM1NXVwWQyITs7O+z4wsJC1NXVAQDq6urCAhbxvHiuL4888giysrLUj9LS0lgvm4gGEFrcKgpIk0VkWvorwhUG00FU06ZtpiV06J0IYHpO7l08MQ/P3bYIT944L6HXQDQaxBy0nHPOOdizZw+2b9+OO++8E7feeisOHjyoxbWp7r//ftjtdvWjurpa0/MRjUahQcDGww3YdaolaeeuC2yW2Nc03FDBDqLYgxaxpJToTIvImpwO2cxRzbTk9d5u4JJpBZhcwHklRLGKOWgxmUyYPHkyFixYgEceeQRz587F7373OxQVFcHtdqOtrS3s+Pr6ehQVKZtxFRUV9eomEt+LYyIxm81qx5L4IKLEOtOmvMlOL1b+//X4uiOQ5eQU5artzlHsNiwyLdVxtD0Hg5bE7mosMi0OpxdtXUp9Xn9BCxHFZ9DD5fx+P1wuFxYsWACj0YgNGzaozx05cgRVVVWoqFD68ysqKrBv3z40NDSox6xfvx42mw0zZswY7KUQUZy8Pj9qA/Uev/jSLJgMOuw42YLNx5qScn6xPFRoG7ibZjCZFrE8lOhumjSTXh0yV9XSBZfXp86DiXdjRyLqLabhcvfffz+uvPJKlJWVob29HS+99BI+/PBDrFu3DllZWbj99ttx7733Ijc3FzabDd/5zndQUVGB888/HwBw+eWXY8aMGbj55pvx+OOPo66uDg888ABWrVoFs1m71j8i6l99uwtevwyjXsLccdn49/PKsGbLKbz1aQ0unjpG+/MPsFliKBFwnI0x0+Lzy2pwlOjlIUApuG1sd+F0cxcyzQbIMpBu0mOMhvsLEY02MQUtDQ0NuOWWW1BbW4usrCzMmTMH69atwxe+8AUAwBNPPAGdTocVK1bA5XJh2bJl+OMf/6j+vF6vx9q1a3HnnXeioqICGRkZuPXWW/Hwww8n9q6IKCZnAksZJdlp0OkkLCjPwZotp8JqNLQiy3JUmyUKInPR1OFGt9sXddtwQ7sTXr8Mg04K2wsnUcry0rHrdCuqWrqQaVH+tJblprN7hyiBYgpann322X6ft1gsWL16NVavXt3nMeXl5Xj77bdjOS0RaUwstYgshqjDGMxuytFqd3nR5VYGxUVT05KVZoTVYkC704szrV2YEuUGfGJpqCjLAr0Gc0tC256tgaCFS0NEicUNE4lILVAdl628yZbnKt0wDe0udLm13WajPrBkY7UYkG6K7t9R8dS1nNVoRougBnotncHBcgxaiBKKQQsRqTNaRKYlK92ojpvXOttSH2h3jmZpSChVZ7X0f22dLi86Azsvn9VoGq5QFgj0qlu6I07DJaLBY9BCRMHlodzgG3pZhNkjWqiLod1ZGBfFxok1bd249Ncf4tJff4jGdpdmg+UEsTxUY+/G8cYOAFweIko0Bi1EFFLTEnyTHZ+kupZYOoeEcQNkWpweH+58oRL1DhfqHS781+v7NBssJ+RnmpBu0kOWgZNNSqCXjFH9RKNJTIW4RDTy+PxyxPkloh7jlMZBSywj/AWRweirpuWnbx3Ap2fssFkM6Pb48N7Bepj0yr/REj1YTpAkCWW56Thc1w4A0EnaZXWIRitmWohGuXqHU53REtoKHGk0vRbqotwsMZQ6FTfCpomv7KzCX3dUQ5KA3//7ufjupVMAAG6fP+xntVAWshxUnJUGk4F/YokSif+PIhrlRLaiOCstrBV4fH5yl4diybSIwKO1y4MOV7C7SZZlPPaustnj978wFRdPHYM7Pz8Jc8ZlqccUZ2kXtIQW3rIIlyjxGLQQjXI9O4cE0Q1TY++Gy+vT7PzxLA9ZLUZkB7qbzoYsETmcXrR0Knv/3H7hRACAQa/Dr788F5lmA6YVWZFh1m5VvCykhoVBC1HisaaFaJTrOVhOyM80IcOkR6fbh+qWbkwuyEz4ub0+P5o6Ajs8Z8U27n5cThraujyobunCOUXKgLnawH4/OenGsEm5Uwqt2HTf52ExRjc9N16hy0PsHCJKPGZaiIaJs23d+PaLlfjXZ8nZpFA9b4TOISBQWBrIHFS1aFPX0tjhgl8GDDoJ+RkxBi3Zohg3uHxV00+HUF6mWdMsCxA+TE4M6COixGGmhWgYkGUZ97+2D5uPNqLd6cWSyflJO/eZtsjLQ4DS9nyo1oFTTYmta5FlGbV2J97ZXwcAKLCaoYtxtH5prmh7Di4Piam3Wtat9GdsThp0EuCXuTxEpAUGLUTDwPqD9dh8tBFAcvb7CRVpRouQ6A6ipg4XXtlZjZe2V6lzU4D4llKCA+aCv69adYCcNm3NAzHqdbilYjyON3aoS1ZElDgMWoiGmNPjw8NrD6rfn23rhtfnh0Gv/eptXzNahOB+OoMLpGRZxo//cQAv76hWW4/1OgnTiqyYMy4bt10wPubXDA6YCwY/4l6Kh3A+yk+umTlk5yYa6Ri0EA2xP206gTOt3SjOsqC50w2314+aNifKkrC80NDuhMcnw6CTIk6kTdRuz8cbO/CXracBAHNLs3FrRTmunFUcViwbq0gD5mrs2m6KSERDi4W4REOo1t6NP374GQDg/7tqutp9clqjwteexBt+SXb4jBZhfJ7YBLAL3kCGJB4nAzUxM4pteHPVElx/7rhBBSxAcNqsvdsDh9MDACH7Cw3N8hARaYtBC9EQev9QA1xeP+aWZuPqOcVq0FI1yOWYaJ0K7JFTmhs5M1Fks8Bk0MHrVwpn4yVqYibkJ66jJsNsQG6GCQBwpqUbPr+sznwZqkJcItIWgxaiIbT7dCsA4PNTx6h71wBAVZKKcY83KsHEpDGRZ7DodMFrOjWIYlyxvJTojprSkI0Tmzpc8Ppl6HUSCqyxtU8TUWpg0EI0hHZXKUHLgvIcAImrIYnWZw0dANDv4LhEbJwoCnkTHbSIDqIzrd1qN1Kh1ZyUImYiSj4W4hINkcZ2F043d0GSgHll2QCQ9OWhE41K0NJXpgUAxgeWdE42DibTovxseV5iB66pGye2dqmFxCzCJRq5+M8RoiEisixTC6ywWZR9dEQmoqqlC7Isa3p+t9evZkD6y7SIgOZ4IMCJlcfnVwt+E55pCekgGg7tzkSkLQYtRENE1LOcG1gaAoLLHR2u4MZ/Wjnd3AmfX0am2dBvDcikMUp2JN6gpaZNKZI1G3QotCa2qyd0VkuNXXRCsXOIaKRi0EI0RHrWswCAxahXdzvWeonouLo0lAFJ6nuEvsjCnG3rRrc79t2eT4UU4cY6qn8gaiFuS5e6h1IJO4eIRiwGLURDwO3149MzdgDAuYF6FqEsLzl1LaIId9IAuzfnZpiQnW6ELAMnmmLPtoh6ljINNhAUmal2lxeH69oBsKaFaCRj0EI0BA7U2OH2+pGTbuw1uyRZbc8DtTsLkiRhslrXEnsxruiEGq/BhF+LUY/8TGVpSwR5XB4iGrkYtBANgcrTwaWhnksz5bmJ2e9nING0OwsisBE/Ewu1cyiBg+VC9dwzictDRCMXgxaiIfBJVRuA8CJcQV0e0jDTIstySE3LwEGLCGziKcZVB8vFsZNzNEJ3iE4z6pGdbtTkPEQ09Bi0ECWZLMvYdboFAHBuWYSgJQmzWmrtTnS5fTDopKjakCcVBDqIYsy0+P2ymjEan+AZLUJopqU429JvUTERpTYGLTTq7aluQ6vG7cWhzrZ1o97hgl4nYe647F7PiwFsdQ4nnJ7Yu3WiITIm5XnpMEYxPVZkY040KW3S/alu6cKhWgcA5R7cXj8MOkmzWpPQoGUsi3CJRjQGLTSqfXC4Adet/hd++Pe9STvnhkMNAIC547Ii7nSck26E1awMq67WKNsiMibRLA0BSpeOyaCD2+tXW4sjcXv9+Lent+CLv/8YB2sc6tLQuJw0zUbrl+YEM0XFWSzCJRrJGLTQqPb81lMAlGxLsqzdWwMAuGp2ccTnJUlS6zS0WiL6rDH6IlwA0OskTAwU0n7W2N7ncR8caUC9Q9m48FfvHdFsfH+o0EwL252JRjYGLTRqnW3rxqajjQCUfYA6XF7Nz1lr78bOU0rn0PI5kYMWQPuNE483RNfuHErMcxE/G8nru8+qX2883IDXPlG+16LdWQgNVBi0EI1sDFpo1PrbzmqEbu9zqin+DQFDvfVpDR54Yx/+uqMKB2rs8Pr86nNv76sDACwsz0FxP625ZWrQMvhrirSHUayZFmDgtmd7lwcbDytLX+dNyAUA7DipFByXaZhpsRj1KLQps1pY00I0snGXZxqVfH4Zr+6qBgAYdBK8fhmnm7swa2zWoF5XlmX86O970RUy7n5qYSZeuaMCORkmdWno6n6yLADUYW5H6vteihmI3y/jK3/aCqfXh799swLpJuX/7vZuDxrbXQCAiWOiDyYGanteu68Gbp8f04qs+N0N83DxLz+E26sEbFpmWgDge5dNxb+ON2Hh+N7dWEQ0cjDTQqPS5qONqLE7kZ1uxLJZRQCAUwnIajR1uNHl9kGSgCWT85Bu0uNofQe++/InqG7pwidVbZAk4Mo+6lmE6cU2AMCh2va4d3tu6nBh1+lW7D/rwOoPPlMfX3dAyfYUZ1lgtUQ/02SgjRNfCywNrTh3HIqz0nDL+eXqc1rWtADAvy8uw+p/PxdmQ+/CZiIaORi00Kj01x1VAIDr54/DOYVWAMDJBCwP1bQpnTWFVgte/I/z8dq3L0CaUY+PjjXh1v/dAQA4b3wuCm39d7lMLsiEXifB3u1BncMZ17U0BLIpAPDnzSdxqqkTtfZu/GztQQDAzRXlff1oRBPzMyFJQGuXB80drrDnTjd3ovJ0K3QScO28EgDAty+ZjLwMEwptZpTmctmGiAaPy0M06jQ4nNgQqL248bxSHApstJeI+hERtIiZJNOKbHjs3+bgu3/9BCcCQdHVc0sGfB2LUY9JYzJwtL4Dh2od/da/9KU+JNhx+/z46VsH4JOBdqcXc0uzccfnJsb0emkmPcZmp+FMazeON3YiL7DnDwC8Hii4XTI5HwWBgCw3w4R191wEnSQxA0JECcFMC406r1aegc8vY0F5DqYUWjEhsHRxsmnwnTpn1aAlGGRcM7cE/3HhBACATgKumFkU1WuFLhHFo96hZEOmFmbCqJfwwZFGbD7aCLNBh19/eW5cc1NEMe6xhvBreidQYHz9uWPDHs/PNCM3wxTP5RMR9cKghUYVv1/GKzuVAtwbFpUCAMrzlSLRpg4X2p2eQb2+CFrG9tjE7z+vnIZvXTwJD187C2Os5kg/2su0IhG0OOK6FpFpWVCei68HgiYAuG/ZOTF1DYVfk7KUdqQuGLQ4PT41iFkyOT+u1yUiigaXh2hU2XqiGVUtXbCaDeqcFJvFiLwME5o73YPuIBLLQz1bbw16Hf7zymkxvdb0YiVAiDdoETUthTYz/uNzE/FJVRsKbRZ8fcmEAX6yb9MiXNORunb4ZSAvw4QxmdEFZERE8WDQQqOKKMC9dn6J2gIMAOPzM9Dc6cap5s5BBi1KdqMkjhqUnsTy0MmmTjg9PliMsdWFNAQyLQVWCzLNBvztmxUJu6bDga4mSZJwuM6hPsfNColIS1weolGjpdON9w7UAwBuWFQW9pzYgXiwA+Yi1bTEq8Cq1IP4ZeBoHPNa6tuVoEUMXkuEiflKfUy7y4szgT2IRM2NyAwREWmFQQuNGq/tPgO3z4/ZY7N6ZVMmBOpaBlOM2+32oSWwW3TPmpZ4SJKkBgKH4yjGFYW4A7VXx8Jk0GFyQeCaAnUtBwNLRaIGh4hIKwxaaFSQZVldGrrhvNJez4vhZ4Npe66xK5mHTLMBNktiVl5FIHAwxroWr8+vzlIpSGCmBQivtZFlGYdrg8tDRERaYtBCo8Lp5i4cb+yEyaDDNRHmpEwI7GA8mKm4Z1uDM1oSVdsRbHuOLWhp7nTDLyu7M+dlJDhoCelqqrE74XB6YdBJmFSg7dRbIiIGLTQqnAwEIxPzMyKOrh8fCFqaOtxxtz331Tk0GKLF+HBdbOP8RbtzfqYJel1ii2PVYty6dhyqUYKpyQWZHCBHRJpj0EKjQnWLUqtSlht5475MswH5gXbd083x1bXUJLAIV5hSmAlDYJx/rT36cf5a1LMIou35VHMndle1AuDSEBElB4MWGhVEINJX0AIEdyKOdw+is6LdOYFBi9mgV6fQitbiaDS0B9udEy0/04wxVjNkGXhzj7JrtcgIERFpiUELjQpVgUxLeV4/QUv+4Nqez7Yp50jk8hAQOtAt+g6iYKZFm2FvIrMiWryZaSGiZGDQQqNCVSDTUtpPpkUU48abaRGD5RLR7hxqSmDk/vGGjqh/RgyW02J5CACm98isTOOMFiJKAgYtNOLJshySaem7w0W08lYG6jRi4ffLqLUnvqYFACYGloeOxxBM1TsSP1guVGhmJT/TpMkyFBFRTzEFLY888ggWLVoEq9WKgoICXHfddThy5EjYMU6nE6tWrUJeXh4yMzOxYsUK1NfXhx1TVVWF5cuXIz09HQUFBbjvvvvg9XoHfzdEETR2uNDt8UEn9b90c96EPBh0Ek43d6mFu7Gcw+OToddJKIxyQ8RoTRyjBFonGjui7iAS+w5pFUyEZlY4VI6IkiWmoGXTpk1YtWoVtm3bhvXr18Pj8eDyyy9HZ2fwX4D33HMP3nrrLbz66qvYtGkTampqcP3116vP+3w+LF++HG63G1u2bMHzzz+PNWvW4KGHHkrcXRGFEEtDxVlpMBn6/p98ptmAuaXZAIAtx5tiOoeo7SiyWWDQJzaBOT4vA5IEtDu9aOpw93r+s4Z23PQ/23HFbzerE3lFTUuiB8sJk8ZkwhS4T47vJ6Jkiemv67vvvovbbrsNM2fOxNy5c7FmzRpUVVWhsrISAGC32/Hss8/iN7/5DS699FIsWLAAzz33HLZs2YJt27YBAN577z0cPHgQL7zwAubNm4crr7wSP/vZz7B69Wq43b3/IBMNVjRFuMKSSXkAgH991hzTOYLtzonPbFiMeowL1MmcaAzWtbi8Pjyx/iiu/N1H+PizJhyua8c/99XC4/OjuVO7lmcAMOp1mFqkLFvNKGGmhYiSY1D/JLTb7QCA3NxcAEBlZSU8Hg+WLl2qHjNt2jSUlZVh69atAICtW7di9uzZKCwsVI9ZtmwZHA4HDhw4EPE8LpcLDocj7IMoWtG0OwtLJucDUDItsQxzC07DTWw9izAxXwkQToTUtfz4zQP43YZj8PhkFGcpwcnGQ/Vo6nBBlgGDTkJuukmT6wGAh66eiW9eNBHLZ/eeMExEpIW4N0jx+/24++67sWTJEsyaNQsAUFdXB5PJhOzs7LBjCwsLUVdXpx4TGrCI58VzkTzyyCP46U9/Gu+l0jDg9vpxy/9ux8HABFVJknDDolLcf9V0zc8tMi1lUWRa5pflIM2oR1OHG0fq26Ou19BisFyoiWMysOloo5pp8ftlvLNf+f/LI9fPxrllOVj228341/FmnAps+lhgNUOX4Gm4oc6bkIvzJuRq9vpERD3FnWlZtWoV9u/fj5dffjmR1xPR/fffD7vdrn5UV1drfk5KrE+qWrHtRAscTi8cTi/s3R48+/FJ2LvjG5kfC3V5KHfgvXFMBh0WBd6IB1oikmUZTR0uNLa7cKpZmxktguggOtGoZFpONHXC3u2BxajDvy0Yh6mFmRibnQa31483PjkLABij0dIQEdFQiStoueuuu7B27Vp88MEHGDdunPp4UVER3G432trawo6vr69HUVGRekzPbiLxvTimJ7PZDJvNFvZBqUW0EV9yzhhs/P7FmFyQCa9fxgeHGzQ/dyzLQwBw4WRR1xK5GNfh9OC5f53EZb/ehIU/fx+L/vt9bDraCEC7oGVSYIaMWB7afVr5fc4Zlw2jXgdJknDZ9AIAwFt7lSm1ie5iIiIaajEFLbIs46677sLrr7+OjRs3YsKECWHPL1iwAEajERs2bFAfO3LkCKqqqlBRUQEAqKiowL59+9DQEHyzWr9+PWw2G2bMmDGYe6FhTLzJLpmcj4ljMnHFTCVAXXcg8pJgrDpcXnWJJlSny4umDqUoNZrlIQC4YJJS17L9RDM8Pn/Yc299WoPzf7EBP33roBpASJLyUZ6XjnPLcgZzG30SmZaqli64vX5UBn6fC8qD57t0mhK0dLl9ALQrwiUiGiox1bSsWrUKL730Et58801YrVa1BiUrKwtpaWnIysrC7bffjnvvvRe5ubmw2Wz4zne+g4qKCpx//vkAgMsvvxwzZszAzTffjMcffxx1dXV44IEHsGrVKpjN/JfhSCTLMnZXtQEAzg28yS6bWYQ/fPAZPjzSCKfHB4txcDsEf+25Hfj0jB3/uGtJWB1KdauSZclONyIrrffuzpHMKLYhJ92I1i4PPq1uw8LxwbqNNVtOocvtw+SCTNx2wXh8af5YZJjjLg2LWqHNjAyTHp1uH6paOtXMVWiQdP7EPKQZ9ej2+NSfISIaSWLKtDz11FOw2+34/Oc/j+LiYvXjlVdeUY954okncPXVV2PFihW46KKLUFRUhNdee019Xq/XY+3atdDr9aioqMBNN92EW265BQ8//HDi7oqGlVPNXWjpdMNk0GFmoD121lgbxmanodvjw8fHYpuJ0tOhWgd2nmqF2+vHC9tOhz0X69IQAOh0kpptCa1r8fj82H9W6Zh75uYFuOn88qQELIBSuDwhMGRud1UbPguM9D+3LFs9xmLUq91PAFDATAsRjTAxLw9F+rjtttvUYywWC1avXo2WlhZ0dnbitdde61WrUl5ejrfffhtdXV1obGzEr371KxgMyfnjT8knljLmjM2C2aBkVCRJwhdmKF1jg10iej1QeAoAb35Sgy53cLqymGwbS9ACABWBeS3bTgSDlsO17XB5/chKM6r7FCWTaHv+e+UZAMpeSXmZ4dkUUdcCKN1DREQjCfceIs2JoOXc8vB6j8tnKkHL+4fq4e1ROxItn19Wu2VMeh3aXV78c2+t+nw8mRZAWWoBgN1VrXAGllv2VCv3Mbc0G5KkXStxX8Q4/+0nWwAA80OyLMIl54QGLcy0ENHIwqCFNPdJhPoLADhvfK5aO7LzVOybFAJKh09Duws56UasumQyAODlncGW+NMxTMMNNWlMBvIzzXB5/fi0uk25j8DneYFR/8k2KVCMKywo7130W5RlwTc+NwFXzirCOUUcr09EIwuDFtKUw+nBkfp2AMC55dlhzxn0Olw2fXBLRGJp6Oo5JbjxvFLodRIqT7fiaOCcweWh2JZzJEnC+ROVAtxtJ5TMxp5A0DJ/iIIWkWkRIgUtAPBfy2fgqZsWQK/hYDkioqHAoIU0taeqDbKsLM9EWq4QdS0f9zETpT+dLi/eDUyF/dK5Y1Fgs+CyQNvvHz/4DA+/dRCnm5W25GjbnUMtDiwRbT/ZDHuXRx3sNneIgpbQOppMswFTCphJIaLRhUELaWq3ujSUHfH5hYFswfHGDjicsU3HfXd/Hbo9PkzIz1CzHzeeVwYAeGNPDf73Xyfhl5VzF8fRSVMRyLRUnm7FzlNKtqU8Lx25Gdrt59OfdJMBJYE9huaXZTOTQkSjDoMW0lSkIWih8jLNKM1NgywDe6vtUb+uLMt4eWcVAOBL88eqhbEXTR2DcwqtkCRl2Nqary3C//vWBXHtwTNpTCbyM01wef14fuspAENXz6JeU4FS16LVEDsiouGMfcYUtyc3HMNfd1Thr984H+MjtADbuz34pMdQuUjmleaguqUbe6pbceGU/D6PC7X5WBN2nmqFyaDDVxaWqo/rdRJe+/YFcHp8vdqBYyVJEhZPzMM/99bio8AsmaEOWr518SSYDTqsXFw2pNdBRDQUmGmhuP2/yjOotTvxyq7eG1j6/TLueWUPOlxelOWm45zCvusvRCAgCl0H4vfL+OW6wwCAW84vR1FW+NJPhtkw6IBFOL/HLsZDHbQsmZyP/7l1EQfHEdGoxKCF4tLt9qkj8iN1/jy58Rg2Hm6A2aDDH1eeC4O+7/+phQYtsiwPeO539tdh/1kHMkx6fDvQ5qwVMa8FUObAzCjhZp1EREOFQQvF5bOGDoj44kRjpzpWHgA2HKrHb98/BgD4xZdmY9bYrH5fa2aJDUa9hKYON8609t70MJTX58ev1x8BAPzH5yZqXhQ7uSATeYFzTC+xqRN9iYgo+Ri0jHAenx9n27rVj3gnz/YkZq8IItvicHrwg1c/BQDcWlGOFQvGDfhaFqMeM4qVDMYnAywRvbKrGicaO5GTbsR/fG5Cv8cmgjKvRcm2DNV8FiIiUrAQdwTz+vxY9tvN6nwRAJg9NgtvrloSVzdNqGOBoCU73Yi2Lg/eO1CHVZdMxv98dBKtXR5MGpOB/1o+I+rXm1eajU/P2LGnqg3XzC2JeMzmo4346T8OAgBWXTIZVkt0uzYP1j1fmAKzQYdvXjwxKecjIqLImGkZwQ7XtasBi8mg/Kfed9aOrSGbAMZLTJy97YLxkCTg0zN27D9rx7MfnQAA/ODyc9RzRmNeYI6L2N+np52nWnDH/+2C2+fH8tnFuO2C8YO6/lhMLrDiN1+dh+KstKSdk4iIemPQMoKJGSkXTR2Doz+/Ejedr7TJ/nVH1aBf+2i9UsNywaR8dWbIHX/ZhU63D3PGZeGKWUX9/Xgv80qV19hf44DbG76EdbjOga8/txNOjx+XnDMGT3x1Xr+FvURENDLxL/8IJqbRLggEFTcsUoKW9w7Uo6XTHffrdri8ONumFMxOLczEssBuzTV2JwDgvmXnxLwL8vi8dGSnG+H2+nG4zhH23J82nUC7y4vzJuTiqZsWxJTBISKikYN//UcwkWkRGxXOGpuF2WOz4Pb58druM3G/rqhnKbCakZ1uwrKZwazK+RNzceHk6AbEhZIkCXPHKdfZc17LjpPKCP3vXjoFFiO7d4iIRisGLSNUg8OJM63dkKTwgWg3nKdMj/3rjqqoZqJEIupZpgYGxpXnZWBheQ6Megk/umJazFkWQVzn7tPBuhbR9aTXSZjfx/5FREQ0OjBoGaHE0tA5hdawLptr5pYgzajH8cZO7Dodueh1IKKeZUphpvrY/35tETZ+//OYP4g9cURr8UfHmuDzKwHVrsBGhTNLbMgws9mNiGg0Y9AyQvW1UaHVYsQX5xYDiL8gt2emBQBsFiNKc9Pjej1h4fgcWC0GNHe68emZNgBQd1deND63n58kIqLRgEHLCKXWs0TIfHw5sMHgB4cb4loiihS0JIJRr8NFU8cAADYeagAA7Dyp3Mei8dzVmIhotGPQMgK5vD7sP6t04PTMtADKgDm9TkJrlwd1DmdMr23v9qDe4QIQvjyUKJdNKwAAbDjcAHuXR528u5CZFiKiUY9Bywi0/6wDbp8feRkmlOf1XrKxGPWYUqAEHAfOOno93x/ROVScZYFNg4m0nz+nAJIEHKp14K29NQCAifkZyE/Qrs1ERJS6GLSMQLvVVuecPjt5xF4/B2tjC1qOaLQ0JORmmNQlrSc3KJsusp6FiIgABi0jkugcilTPIswoUYKWAzX2mF5bLDtN1WBpSLg0sETU0K4sQy2awKCFiIi4YaIm1h2ow4dHGtXvzy3LVotfk6GvzqFQImiJJdPy5p6zeHlnVeC1tQskLp1WgF+uO6J+zyJcIiICGLQknL3Lg+/89ZOw/XP+uqMK55bnYNIY7bITQr3DiYZ2F3QSMGusrc/jZhZnAQCqW7ph7/YgK63/+pT3DtTh3r99ClkGbj6/XB3dr4VpRVaUZFlQY3eiwGpG2SBbqYmIaGTg8lCCrd1XA7fXj7LcdHz/C1Mxe6wSHLyyszop599/VlnumVyQiXRT3zFpVroRY7OVXYsPDZBt+fhYE+566RP4/DKuP3csfnrNzLin3kZDkiRcOl1ZIlo0PlfTcxERUepg0JJgr+8+CwBYubgM37lsCr572RQAwN8rz/TavVgL+wJBy6ySrAGPnanWtfQdtFSebsE3/rILbp8fV8wswuMr5kCn0z6I+M6lU/DVhaW45wtTNT8XERGlBgYtCVTV3IVdp1shScC188YCAC45ZwwKbWY0d7qx/mD9oM/R7fZh/1l7n0PhRKHsrLEDBy1qXUsfQcv+s3bc9txOdHt8uGjqGPzuxnkw6JPzP5lCmwWP/dscTC7QfkmNiIhSA4OWBHr9EyXLsmRSPoqyLAAAg16HLy9QinBFEetg/PStA7j69x/jifePRXxeLA9FFbT00/Zc3dKFW/53B9qdXpw3Phd/umkBzAbusExEREOHQUuCyLKM1z85AwC4/tyxYc99dZEStHx0rAnVLV1xn8Pl9WHt3loAygyT93tkbhrbXahzOCFJwSxKf2YGAptj9e1weX1hz724vQotnW7MLLHh2dsWIs3EgIWIiIYWg5YE+aS6Daeau5Bm1GPZzKKw50pz0/G5KfkABleQu/V4MzpcXvX7e17Zg5NNner3+wMzVybkZyAzih2RS7IsyEozwuuXcSywc7Mgsi8rF5eH7RJNREQ0VBi0JIgowL1iVhEyIgQMNywqAwD8v8oz8Ptj36QQANYdUDIrX11YioXlOWh3efHN/9uFLrcSyBwILA3NjmJpCFC6dGb2UddyOBC0TCvWZvItERFRrBi0JIDH58fawD45X5o/NuIxS2cUIM2oR53DiUN1sY3OBwC/X1YLeZfPKcYfV56LMVYzjtZ34C9bTwOIrXNIiFTX0tzhQkO7C5IEnKPRuH4iIqJYMWiJwuE6B1a9tLtXDYmw9XgzWrs8yMsw4YJJeRGPMRv0qAg8t/loU8zX8El1K5o6XLBaDDh/Yh4KbBb86IppAID/+egknB5fTJ1DwszAALq9Z9rUxw7VKvsLleemR8waERERDQUGLVH4xduH8c+9tfiPv+zCt1+sRIPDGfa8yLJcMauo35bgi6eOAQBsPtrY5zF9EUtDl04rgMmgnOPaeSUYm52Gpg4X/rz5BM62dQMIBiLRWFCmjOPfd9aObrdSjHs4kAmaXhz96xAREWmNQcsAWjrd+NdnSmZEr5Pw9r46XPabTdh3RlmKcXv9eHd/HQDg6jkl/b7WRYGgZdfpFnSGFNQORJZlrDugnCO0yNeo1+Ebn5sAAHhyo9ICPT4vHbYYCmdLc9NQkmWBxyerGy2KpaJpRQxaiIho+GDQMoB1B+rg88uYUWzDW3ddiFljbWh3evH/vb4PPr+Mf33WBIfTizFWM84bYDfi8XnpKM1Ng8cnY+vx5qiv4Wh9B043d8Fk0KnZGuGri8qQl2GCx6cU986MYWkIUIpxF09Ulq22nVCu6XBgeWg6i3CJiGgYYdAyALH0c/XcYswoseG5286D1WLAvrN2vLKzGm8Fnr9qVhH0A4y3lyQpuER0LPolonf2K7NZLpqS36vGJM2kx9cvnKB+H23nUKjzJyrB1rYTzfD4/PisQWl/5vIQERENJwxa+tHY7lIzIlfPVpZ+xljNuGepsh/O4+sOY32g1uTquf0vDQkXTVGClk1R1rV4fH68vEOZ7dLX8tNN55erc1nmjIsnaFEyLXuq27D/rB1unx9WswHjctJifi0iIiKtMGjpx7sH6uCXlUCgLC9dffyWinKcU2hFW5cH7S4vimwWLCjLieo1KyblwaCTcLq5C6ebOwc8ft2BOtQ5nMjPNOPK2UURj8lKM+KZWxbgv66ajoqJkbuX+lOWm47iQF3LS9uVrQamFVu5uzIREQ0rDFr6sfbTwNLQnOKwxw16HX5yzUz1+6tmF0e987HVYsS55UqAE00X0XP/OgVA2TW6v71/LpiUj29cNDGuQEOSJDXb8mbgnlmES0REww2Dlj40OJzYcaoFgBKU9FQxKQ8rF5chw6THjeeVxvTaoq4l0hJRu9Oj7uC890wbKk+3wqiXsPL8slhvISairsXt9QNgPQsREQ0/DFr68H/bTkOWgfll2RiXkx7xmJ9fNwv7frIMU2KcGiuCln991gynJ7hR4ZbjTZj38Hp88Q8fY98ZO9ZsOQVAqWUpsFriu5EoLZ4QvqzEziEiIhpuGLRE8OGRBvzhg88AALddML7P4yRJinpZKNTMEhvGZqeh2+MLWyL6v62n4fPL2H/WgWtXf4x/7KkZ8BoSpTwvHUU2JTCSJOCcIgYtREQ0vDBo6aGquQvfe3kPZBn498VluHZe5L2EBkOSJHxhRiGA4KTbTpcXGw83AAA+NyUffhnw+mXML8vG3NLshF9DpGsSS0Tj8zKQbuL4fiIiGl4YtITodvvwzRcqYe/2YF5pNn78xRmanUtMtt1wuB5enx/vH6qHy+vHhPwM/OXr5+G52xbh6jnF+Pl1szS7hp4um64EUueN739IHhER0VDgP6dDPPbuYRyqdSA/04Snbjq3326dwVo0Pgc56Ua0dnmw42QL/rlXGSC3fHYxJEnCJdMKcMm0As3OH8nVc4qRn2mOae8iIiKiZGGmJcS3L5mECybl4Q//fi6Ks7QdrGbQ69TMxt93n8WHgdqWq+f27lRKFkmSUDEpL6a9i4iIiJKFQUuIAqsFL/7HYnVmidbEEtHfd5+B2+vHpDEZOCfGTiQiIqLRgkFLD8mcAvu5KflINwWXoK6eU8IptERERH2IOWjZvHkzvvjFL6KkRHmDfeONN8Kel2UZDz30EIqLi5GWloalS5fi2LFjYce0tLRg5cqVsNlsyM7Oxu23346Ojo5B3Ugqshj1Ybs295y8S0REREExBy2dnZ2YO3cuVq9eHfH5xx9/HE8++SSefvppbN++HRkZGVi2bBmcTqd6zMqVK3HgwAGsX78ea9euxebNm3HHHXfEfxcp7MrAtN1pRdaYh9QRERGNJpIsZsbH88OShNdffx3XXXcdACXLUlJSgu9///v4wQ9+AACw2+0oLCzEmjVrcMMNN+DQoUOYMWMGdu7ciYULFwIA3n33XVx11VU4c+YMSkoG3i3Z4XAgKysLdrsdNltqd7rIsoxXK89gQXkOJo3JHOrLISIi0sxg378TWtNy8uRJ1NXVYenSpepjWVlZWLx4MbZu3QoA2Lp1K7Kzs9WABQCWLl0KnU6H7du3R3xdl8sFh8MR9jFSSJKErywsZcBCREQ0gIQGLXV1dQCAwsLCsMcLCwvV5+rq6lBQED5/xGAwIDc3Vz2mp0ceeQRZWVnqR2lpbBsUEhERUepLie6h+++/H3a7Xf2orq4e6ksiIiKiJEto0FJUpMwdqa+vD3u8vr5efa6oqAgNDQ1hz3u9XrS0tKjH9GQ2m2Gz2cI+iIiIaHRJaNAyYcIEFBUVYcOGDepjDocD27dvR0VFBQCgoqICbW1tqKysVI/ZuHEj/H4/Fi9enMjLISIiohEk5r2HOjo68Nlnn6nfnzx5Env27EFubi7Kyspw99134+c//zmmTJmCCRMm4MEHH0RJSYnaYTR9+nRcccUV+MY3voGnn34aHo8Hd911F2644YaoOoeIiIhodIo5aNm1axcuueQS9ft7770XAHDrrbdizZo1+OEPf4jOzk7ccccdaGtrw4UXXoh3330XFotF/ZkXX3wRd911Fy677DLodDqsWLECTz75ZAJuh4iIiEaqQc1pGSojaU4LERHRaDGs5rQQERERaYVBCxEREaUEBi1ERESUEhi0EBERUUpg0EJEREQpgUELERERpYSY57QMB6JLeyTt9kxERDTSiffteKetpGTQ0t7eDgDc7ZmIiCgFtbe3IysrK+afS8nhcn6/HzU1NbBarZAkKaGv7XA4UFpaiurq6hE9uI73ObLwPkee0XKvvM+RZaD7lGUZ7e3tKCkpgU4Xe4VKSmZadDodxo0bp+k5Rstu0rzPkYX3OfKMlnvlfY4s/d1nPBkWgYW4RERElBIYtBAREVFKYNDSg9lsxo9//GOYzeahvhRN8T5HFt7nyDNa7pX3ObJofZ8pWYhLREREow8zLURERJQSGLQQERFRSmDQQkRERCmBQQsRERGlBAYtIVavXo3x48fDYrFg8eLF2LFjx1Bf0qA88sgjWLRoEaxWKwoKCnDdddfhyJEjYcc4nU6sWrUKeXl5yMzMxIoVK1BfXz9EV5wYjz76KCRJwt13360+NlLu8+zZs7jpppuQl5eHtLQ0zJ49G7t27VKfl2UZDz30EIqLi5GWloalS5fi2LFjQ3jF8fH5fHjwwQcxYcIEpKWlYdKkSfjZz34Wtl9JKt7r5s2b8cUvfhElJSWQJAlvvPFG2PPR3FNLSwtWrlwJm82G7Oxs3H777ejo6EjiXQysv/v0eDz40Y9+hNmzZyMjIwMlJSW45ZZbUFNTE/YaqX6fPX3rW9+CJEn47W9/G/b4SLnPQ4cO4ZprrkFWVhYyMjKwaNEiVFVVqc8n6m8wg5aAV155Bffeey9+/OMfY/fu3Zg7dy6WLVuGhoaGob60uG3atAmrVq3Ctm3bsH79eng8Hlx++eXo7OxUj7nnnnvw1ltv4dVXX8WmTZtQU1OD66+/fgivenB27tyJP/3pT5gzZ07Y4yPhPltbW7FkyRIYjUa88847OHjwIH79618jJydHPebxxx/Hk08+iaeffhrbt29HRkYGli1bBqfTOYRXHrvHHnsMTz31FP7whz/g0KFDeOyxx/D444/j97//vXpMKt5rZ2cn5s6di9WrV0d8Ppp7WrlyJQ4cOID169dj7dq12Lx5M+64445k3UJU+rvPrq4u7N69Gw8++CB2796N1157DUeOHME111wTdlyq32eo119/Hdu2bUNJSUmv50bCfR4/fhwXXnghpk2bhg8//BB79+7Fgw8+CIvFoh6TsL/BMsmyLMvnnXeevGrVKvV7n88nl5SUyI888sgQXlViNTQ0yADkTZs2ybIsy21tbbLRaJRfffVV9ZhDhw7JAOStW7cO1WXGrb29XZ4yZYq8fv16+eKLL5a/973vybI8cu7zRz/6kXzhhRf2+bzf75eLiorkX/7yl+pjbW1tstlslv/6178m4xITZvny5fLXv/71sMeuv/56eeXKlbIsj4x7BSC//vrr6vfR3NPBgwdlAPLOnTvVY9555x1ZkiT57NmzSbv2WPS8z0h27NghA5BPnz4ty/LIus8zZ87IY8eOlffv3y+Xl5fLTzzxhPrcSLnPr371q/JNN93U588k8m8wMy0A3G43KisrsXTpUvUxnU6HpUuXYuvWrUN4ZYllt9sBALm5uQCAyspKeDyesPueNm0aysrKUvK+V61aheXLl4fdDzBy7vMf//gHFi5ciC9/+csoKCjA/Pnz8ec//1l9/uTJk6irqwu7z6ysLCxevDil7hMALrjgAmzYsAFHjx4FAHz66af4+OOPceWVVwIYWfcqRHNPW7duRXZ2NhYuXKges3TpUuh0Omzfvj3p15wodrsdkiQhOzsbwMi5T7/fj5tvvhn33XcfZs6c2ev5kXCffr8f//znPzF16lQsW7YMBQUFWLx4cdgSUiL/BjNoAdDU1ASfz4fCwsKwxwsLC1FXVzdEV5VYfr8fd999N5YsWYJZs2YBAOrq6mAymdQ/FEIq3vfLL7+M3bt345FHHun13Ei5zxMnTuCpp57ClClTsG7dOtx555347ne/i+effx4A1HsZCf87/s///E/ccMMNmDZtGoxGI+bPn4+7774bK1euBDCy7lWI5p7q6upQUFAQ9rzBYEBubm7K3rfT6cSPfvQj3HjjjeoGeyPlPh977DEYDAZ897vfjfj8SLjPhoYGdHR04NFHH8UVV1yB9957D1/60pdw/fXXY9OmTQAS+zc4JXd5ptitWrUK+/fvx8cffzzUl5Jw1dXV+N73vof169eHraGONH6/HwsXLsQvfvELAMD8+fOxf/9+PP3007j11luH+OoS629/+xtefPFFvPTSS5g5cyb27NmDu+++GyUlJSPuXkczj8eDr3zlK5BlGU899dRQX05CVVZW4ne/+x12794NSZKG+nI04/f7AQDXXnst7rnnHgDAvHnzsGXLFjz99NO4+OKLE3o+ZloA5OfnQ6/X96pkrq+vR1FR0RBdVeLcddddWLt2LT744AOMGzdOfbyoqAhutxttbW1hx6fafVdWVqKhoQHnnnsuDAYDDAYDNm3ahCeffBIGgwGFhYUj4j6Li4sxY8aMsMemT5+uVuiLexkJ/zu+77771GzL7NmzcfPNN+Oee+5RM2kj6V6FaO6pqKioV3OA1+tFS0tLyt23CFhOnz6N9evXq1kWYGTc50cffYSGhgaUlZWpf5dOnz6N73//+xg/fjyAkXGf+fn5MBgMA/5tStTfYAYtAEwmExYsWIANGzaoj/n9fmzYsAEVFRVDeGWDI8sy7rrrLrz++uvYuHEjJkyYEPb8ggULYDQaw+77yJEjqKqqSqn7vuyyy7Bv3z7s2bNH/Vi4cCFWrlypfj0S7nPJkiW9WtaPHj2K8vJyAMCECRNQVFQUdp8OhwPbt29PqfsElA4TnS78z5Ner1f/VTeS7lWI5p4qKirQ1taGyspK9ZiNGzfC7/dj8eLFSb/meImA5dixY3j//feRl5cX9vxIuM+bb74Ze/fuDfu7VFJSgvvuuw/r1q0DMDLu02QyYdGiRf3+bUroe01MZbsj2MsvvyybzWZ5zZo18sGDB+U77rhDzs7Oluvq6ob60uJ25513yllZWfKHH34o19bWqh9dXV3qMd/61rfksrIyeePGjfKuXbvkiooKuaKiYgivOjFCu4dkeWTc544dO2SDwSD/93//t3zs2DH5xRdflNPT0+UXXnhBPebRRx+Vs7Oz5TfffFPeu3evfO2118oTJkyQu7u7h/DKY3frrbfKY8eOldeuXSufPHlSfu211+T8/Hz5hz/8oXpMKt5re3u7/Mknn8iffPKJDED+zW9+I3/yySdq10w093TFFVfI8+fPl7dv3y5//PHH8pQpU+Qbb7xxqG4pov7u0+12y9dcc408btw4ec+ePWF/m1wul/oaqX6fkfTsHpLlkXGfr732mmw0GuVnnnlGPnbsmPz73/9e1uv18kcffaS+RqL+BjNoCfH73/9eLisrk00mk3zeeefJ27ZtG+pLGhQAET+ee+459Zju7m7529/+tpyTkyOnp6fLX/rSl+Ta2tqhu+gE6Rm0jJT7fOutt+RZs2bJZrNZnjZtmvzMM8+EPe/3++UHH3xQLiwslM1ms3zZZZfJR44cGaKrjZ/D4ZC/973vyWVlZbLFYpEnTpwo/9d//VfYm1oq3usHH3wQ8f+Tt956qyzL0d1Tc3OzfOONN8qZmZmyzWaTv/a1r8nt7e1DcDd96+8+T5482effpg8++EB9jVS/z0giBS0j5T6fffZZefLkybLFYpHnzp0rv/HGG2Gvkai/wZIsh4yYJCIiIhqmWNNCREREKYFBCxEREaUEBi1ERESUEhi0EBERUUpg0EJEREQpgUELERERpQQGLURERJQSGLQQERFRSmDQQkRERCmBQQsRERGlBAYtRERElBIYtBAREVFK+P8BiEdnR62QZAkAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Darts**"
      ],
      "metadata": {
        "id": "OqNl2R3gpHlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Darts is a Python library intended for the facile manipulation and prediction of time series, which was created by Unit8. The proposition aimed to achieve a degree of user-friendliness in the handling of darts for time-series analysis on par with that of sklearn. The primary objective of Darts is to streamline the holistic methodology of leveraging time series in the context of machine learning. The game of darts is characterized by two primary models that are widely utilized in the prediction of its outcomes, namely the regression models, which predict the output based on input time, and the forecasting models, which predict future results based on past readings.\n",
        "\n",
        "Darts boasts various intriguing attributes, such as -\n",
        "\n",
        "The library provides assistance in performing analysis and modeling of both univariate and multivariate time series.\n",
        "The process of testing models, amalgamating multiple predictions, and taking into account external data is a facile task.\n",
        "\n",
        "Furthermore, it offers flexibility in terms of customization and optimization, making it suitable for a wide range of applications. It possesses a capacity for efficient processing of sizable datasets and features an array of models that span from traditional ARIMA frameworks to more complex deep neural networks. Additionally, its malleability and potential for optimization render it suitable for various applications with diverse requirements.\n",
        "\n",
        "Networks can be employed in a similar fashion as the sklearn library, thereby utilizing the fit() and predict() functions."
      ],
      "metadata": {
        "id": "w2WLu62QOHPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the package\n",
        "from darts import TimeSeries\n",
        "from darts.models import ExponentialSmoothing\n",
        "\n",
        "# Create a TimeSeries, specifying the time and value columns\n",
        "series = TimeSeries.from_dataframe(data, 'month', '#Passengers')\n",
        "\n",
        "# Set aside the last 36 months as a validation series\n",
        "train, val = series[:-36], series[-36:]"
      ],
      "metadata": {
        "id": "trST7FXzpHlQ",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:41:11.334107Z",
          "iopub.execute_input": "2022-05-05T08:41:11.334322Z",
          "iopub.status.idle": "2022-05-05T08:41:13.076076Z",
          "shell.execute_reply.started": "2022-05-05T08:41:11.334296Z",
          "shell.execute_reply": "2022-05-05T08:41:13.075026Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from darts.models import ExponentialSmoothing\n",
        "\n",
        "model = ExponentialSmoothing()\n",
        "model.fit(train)\n",
        "prediction = model.predict(len(val), num_samples=1000)"
      ],
      "metadata": {
        "id": "VJsHsNAvpHlR",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:41:13.077686Z",
          "iopub.execute_input": "2022-05-05T08:41:13.077930Z",
          "iopub.status.idle": "2022-05-05T08:41:13.219694Z",
          "shell.execute_reply.started": "2022-05-05T08:41:13.077897Z",
          "shell.execute_reply": "2022-05-05T08:41:13.219085Z"
        },
        "trusted": true
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series.plot()\n",
        "prediction.plot(label='forecast', low_quantile=0.05, high_quantile=0.95)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "nbsM233upHlS",
        "outputId": "613c5277-b720-402a-d8b9-5061c7de908d",
        "execution": {
          "iopub.status.busy": "2022-05-05T08:41:13.220823Z",
          "iopub.execute_input": "2022-05-05T08:41:13.223146Z",
          "iopub.status.idle": "2022-05-05T08:41:13.754784Z",
          "shell.execute_reply.started": "2022-05-05T08:41:13.223110Z",
          "shell.execute_reply": "2022-05-05T08:41:13.753932Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f589952b0a0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}